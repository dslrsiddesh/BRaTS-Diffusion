{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wandb connect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/siddesh/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs21b2019\u001b[0m (\u001b[33mcs21b2019-iiitdm-kancheepuram\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.init(project=\"brats-diffusion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJzfe3HOz4KD"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.339659Z",
          "iopub.status.busy": "2025-02-09T13:57:43.339310Z",
          "iopub.status.idle": "2025-02-09T13:57:43.344047Z",
          "shell.execute_reply": "2025-02-09T13:57:43.343161Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.339611Z"
        },
        "id": "8C2-H7ExJtlG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange #pip install einops\n",
        "from typing import List\n",
        "import random\n",
        "import math\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from timm.utils import ModelEmaV3 #pip install timm\n",
        "from tqdm import tqdm #pip install tqdm\n",
        "import matplotlib.pyplot as plt #pip install matplotlib\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_log(message):\n",
        "    print(f\"[Log] {message}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Normalize images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_images(images):\n",
        "    return (images - 0.5) / 0.5\n",
        "\n",
        "# def normalize_images(images): # Normalize images to [-1, 1] using min-max scaling\n",
        "#     min_val = images.min()\n",
        "#     max_val = images.max()\n",
        "#     return 2 * (images - min_val) / (max_val - min_val) - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print_log(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_checkpoint(model, optimizer, ema, filename, folder='../checkpoints'):\n",
        "    checkpoint_path = os.path.join(folder, filename)\n",
        "\n",
        "    checkpoint = {\n",
        "        'weights': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'ema': ema.state_dict()\n",
        "    }\n",
        "\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    print(f\"[INFO] Checkpoint saved at: {checkpoint_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Dice Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dice_score(pred, target):\n",
        "    \"\"\"Compute Dice score between prediction and target.\"\"\"\n",
        "    # Ensure both inputs are binary and on the same device\n",
        "    pred = pred.to(target.device)\n",
        "    \n",
        "    # Calculate dice score\n",
        "    intersection = (pred * target).sum()\n",
        "    union = pred.sum() + target.sum()\n",
        "    \n",
        "    if union == 0:\n",
        "        return torch.tensor(1.0)  # Both pred and target are empty\n",
        "    \n",
        "    return 2 * intersection / union"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### OTSU's Thresholding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_otsu_thresholding(image_tensor):\n",
        "    \"\"\"\n",
        "    Apply Otsu's thresholding to tensor images - robust implementation\n",
        "    that handles different image shapes and dimensions.\n",
        "    \"\"\"\n",
        "    # Make sure we have a valid input tensor\n",
        "    if image_tensor.dim() < 3:\n",
        "        raise ValueError(\"Input tensor must have at least 3 dimensions (batch, channel, height, width)\")\n",
        "    \n",
        "    # Get tensor shape\n",
        "    orig_shape = image_tensor.shape\n",
        "    \n",
        "    # Move to CPU for numpy processing\n",
        "    image_np = image_tensor.detach().cpu().numpy()\n",
        "    \n",
        "    # Initialize result with the same shape as input\n",
        "    result = np.zeros_like(image_np)\n",
        "    \n",
        "    # Process each image in the batch\n",
        "    for b in range(image_np.shape[0]):\n",
        "        for c in range(image_np.shape[1]):\n",
        "            # Get current slice and make sure it's 2D\n",
        "            img_slice = image_np[b, c]\n",
        "            \n",
        "            # Rescale to 0-255 for OpenCV\n",
        "            img_scaled = (img_slice * 255).astype(np.uint8)\n",
        "            \n",
        "            # Apply Otsu thresholding\n",
        "            _, binary = cv2.threshold(img_scaled, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "            \n",
        "            # Check binary shape and reshape if needed\n",
        "            if binary.shape != img_slice.shape:\n",
        "                # Reshape binary to match the original slice shape\n",
        "                binary = binary.reshape(img_slice.shape)\n",
        "            \n",
        "            # Store back in result array\n",
        "            result[b, c] = binary / 255.0\n",
        "    \n",
        "    # Convert back to tensor on the original device\n",
        "    return torch.from_numpy(result).float().to(image_tensor.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLtAHV-arapv"
      },
      "source": [
        "### Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "eQKp1NCQrdfS"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=1e-4, model_path=\"best_model.pth\"):\n",
        "        self.patience = patience\n",
        "        self.delta = delta  # Minimum improvement threshold\n",
        "        self.best_score = None\n",
        "        self.counter = 0\n",
        "        self.model_path = model_path  # Save the best model\n",
        "\n",
        "    def step(self, val_loss, model):\n",
        "        if self.best_score is None:\n",
        "            self.best_score = val_loss\n",
        "            self.save_checkpoint(model)\n",
        "            return False\n",
        "\n",
        "        elif val_loss < self.best_score - self.delta:  # Require significant improvement\n",
        "            self.best_score = val_loss\n",
        "            self.counter = 0\n",
        "            self.save_checkpoint(model)  # Save best model\n",
        "            return False\n",
        "\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                print(\"Early Stopping Triggered.\")\n",
        "                return True  # Stop training\n",
        "            return False\n",
        "\n",
        "    def save_checkpoint(self, model):\n",
        "        \"\"\"Save the model when validation loss improves.\"\"\"\n",
        "        torch.save(model.state_dict(), self.model_path)\n",
        "        print(f\"Model saved with val_loss: {self.best_score:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in_gaQkXZVty"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9ORVCc1z7DR"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "-ZgT72xcWtRP"
      },
      "outputs": [],
      "source": [
        "class BRATSDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, directory, test_flag=False, resize=False):\n",
        "        super().__init__()\n",
        "        self.directory = os.path.expanduser(directory)\n",
        "        self.test_flag = test_flag\n",
        "        self.seqtypes = ['t1', 't1ce', 't2', 'flair']\n",
        "        self.seqtypes_set = set(self.seqtypes)\n",
        "        self.resize = resize\n",
        "        self.database = []\n",
        "\n",
        "        for root, dirs, files in os.walk(self.directory):\n",
        "            if not dirs:  # Leaf directory\n",
        "                datapoint = {}\n",
        "                seg_path = None  # For segmentation mask\n",
        "                \n",
        "                for f in sorted(files):\n",
        "                    parts = f.split('_')\n",
        "                    seqtype = parts[3] if len(parts) > 3 else None\n",
        "                    \n",
        "                    if seqtype in self.seqtypes_set:\n",
        "                        datapoint[seqtype] = os.path.join(root, f)\n",
        "                    elif 'seg' in f.lower():  # Identify segmentation file\n",
        "                        seg_path = os.path.join(root, f)\n",
        "\n",
        "                if set(datapoint.keys()) == self.seqtypes_set and (not self.test_flag or seg_path):\n",
        "                    datapoint['seg'] = seg_path  # Add segmentation path if test_flag=True\n",
        "                    self.database.append(datapoint)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filedict = self.database[index]\n",
        "        images = []\n",
        "\n",
        "        for seqtype in self.seqtypes:\n",
        "            img = nib.load(filedict[seqtype]).get_fdata()\n",
        "            img = torch.tensor(img, dtype=torch.float32)\n",
        "\n",
        "            if self.resize:\n",
        "                img = F.interpolate(img.unsqueeze(0).unsqueeze(0), size=(128, 128), mode=\"bilinear\", align_corners=False)\n",
        "                img = img.squeeze()\n",
        "\n",
        "            images.append(img)\n",
        "\n",
        "        images = torch.stack(images)  # Shape: (4, H, W)\n",
        "\n",
        "        if self.test_flag:\n",
        "            seg_img = nib.load(filedict['seg']).get_fdata()\n",
        "            seg_img = torch.tensor(seg_img, dtype=torch.float32)\n",
        "\n",
        "            if self.resize:\n",
        "                seg_img = F.interpolate(seg_img.unsqueeze(0).unsqueeze(0), size=(128, 128), mode=\"nearest\")\n",
        "                seg_img = seg_img.squeeze()\n",
        "\n",
        "            return images, seg_img  # Return segmentation image instead of path\n",
        "\n",
        "        return images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.database)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxpENE6MJtlI"
      },
      "source": [
        "### Timestep embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.363668Z",
          "iopub.status.busy": "2025-02-09T13:57:43.363421Z",
          "iopub.status.idle": "2025-02-09T13:57:43.375185Z",
          "shell.execute_reply": "2025-02-09T13:57:43.374373Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.363631Z"
        },
        "id": "P0G2b-ZuJtlJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class SinusoidalEmbeddings(nn.Module):\n",
        "    def __init__(self, time_steps: int, embed_dim: int):\n",
        "        super().__init__()\n",
        "        position = torch.arange(time_steps, dtype=torch.float32).unsqueeze(1)\n",
        "        div = torch.exp(torch.arange(0, embed_dim, 2, dtype=torch.float32) * -(math.log(10000.0) / embed_dim))\n",
        "        embeddings = torch.zeros(time_steps, embed_dim, requires_grad=False)\n",
        "        embeddings[:, 0::2] = torch.sin(position * div)\n",
        "        embeddings[:, 1::2] = torch.cos(position * div)\n",
        "        self.register_buffer('embeddings', embeddings)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        return self.embeddings[t].to(x.device)[:, :, None, None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQFnsdN9JtlJ"
      },
      "source": [
        "### Residual Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.376253Z",
          "iopub.status.busy": "2025-02-09T13:57:43.376071Z",
          "iopub.status.idle": "2025-02-09T13:57:43.383973Z",
          "shell.execute_reply": "2025-02-09T13:57:43.383316Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.376238Z"
        },
        "id": "vlBMnHudJtlJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Residual Blocks\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, C: int, num_groups: int, dropout_prob: float):\n",
        "        super().__init__()\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.gnorm1 = nn.GroupNorm(num_groups=num_groups, num_channels=C)\n",
        "        self.gnorm2 = nn.GroupNorm(num_groups=num_groups, num_channels=C)\n",
        "        self.conv1 = nn.Conv2d(C, C, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(C, C, kernel_size=3, padding=1)\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "\n",
        "    def forward(self, x, embeddings):\n",
        "        x = x + embeddings[:, :x.shape[1], :, :]\n",
        "        r = self.conv1(self.relu(self.gnorm1(x)))\n",
        "        r = self.dropout(r)\n",
        "        r = self.conv2(self.relu(self.gnorm2(r)))\n",
        "        return r + x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIMWqvt-JtlJ"
      },
      "source": [
        "### Self Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.384966Z",
          "iopub.status.busy": "2025-02-09T13:57:43.384740Z",
          "iopub.status.idle": "2025-02-09T13:57:43.396549Z",
          "shell.execute_reply": "2025-02-09T13:57:43.395878Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.384937Z"
        },
        "id": "JlkW322cJtlK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, C: int, num_heads: int, dropout_prob: float):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.proj1 = nn.Linear(C, C * 3)\n",
        "        self.proj2 = nn.Linear(C, C)\n",
        "        self.dropout_prob = dropout_prob\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, w = x.shape[2:]\n",
        "        x = rearrange(x, 'b c h w -> b (h w) c')\n",
        "        x = self.proj1(x)\n",
        "        x = rearrange(x, 'b L (C H K) -> K b H L C', K=3, H=self.num_heads)\n",
        "        q, k, v = x[0], x[1], x[2]\n",
        "        x = F.scaled_dot_product_attention(q, k, v, is_causal=False, dropout_p=self.dropout_prob)\n",
        "        x = rearrange(x, 'b H (h w) C -> b h w (C H)', h=h, w=w)\n",
        "        x = self.proj2(x)\n",
        "        return rearrange(x, 'b h w C -> b C h w')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfFBhAhgJtlK"
      },
      "source": [
        "### UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.397562Z",
          "iopub.status.busy": "2025-02-09T13:57:43.397293Z",
          "iopub.status.idle": "2025-02-09T13:57:43.414334Z",
          "shell.execute_reply": "2025-02-09T13:57:43.413695Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.397533Z"
        },
        "id": "w09_Fld4JtlK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class UnetLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "            upscale: bool,\n",
        "            attention: bool,\n",
        "            num_groups: int,\n",
        "            dropout_prob: float,\n",
        "            num_heads: int,\n",
        "            C: int):\n",
        "        super().__init__()\n",
        "        self.ResBlock1 = ResBlock(C, num_groups, dropout_prob)\n",
        "        self.ResBlock2 = ResBlock(C, num_groups, dropout_prob)\n",
        "        if upscale:\n",
        "            self.conv = nn.ConvTranspose2d(C, C//2, kernel_size=4, stride=2, padding=1)\n",
        "        else:\n",
        "            self.conv = nn.Conv2d(C, C*2, kernel_size=3, stride=2, padding=1)\n",
        "        self.attention_layer = Attention(C, num_heads, dropout_prob) if attention else None\n",
        "\n",
        "    def forward(self, x, embeddings):\n",
        "        x = self.ResBlock1(x, embeddings)\n",
        "        if self.attention_layer:\n",
        "            x = self.attention_layer(x)\n",
        "        x = self.ResBlock2(x, embeddings)\n",
        "        return self.conv(x), x\n",
        "\n",
        "class UNET(nn.Module):\n",
        "    def __init__(self,\n",
        "            Channels: List = [64, 128, 256, 512, 512, 384],\n",
        "            Attentions: List = [False, True, False, False, False, True],\n",
        "            Upscales: List = [False, False, False, True, True, True],\n",
        "            num_groups: int = 32,\n",
        "            dropout_prob: float = 0.1,\n",
        "            num_heads: int = 2,\n",
        "            input_channels: int = 4,\n",
        "            output_channels: int = 4,\n",
        "            time_steps: int = 500):\n",
        "\n",
        "        super().__init__()\n",
        "        self.num_layers = len(Channels)\n",
        "        self.shallow_conv = nn.Conv2d(input_channels, Channels[0], kernel_size=3, padding=1)\n",
        "        self.embeddings = SinusoidalEmbeddings(time_steps=time_steps, embed_dim=max(Channels))\n",
        "\n",
        "        out_channels = (Channels[-1] // 2) + Channels[0]\n",
        "        self.late_conv = nn.Conv2d(out_channels, out_channels // 2, kernel_size=3, padding=1)\n",
        "        self.output_conv = nn.Conv2d(out_channels // 2, output_channels, kernel_size=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Initialize UNet layers\n",
        "        for i in range(self.num_layers):\n",
        "            layer = UnetLayer(\n",
        "                upscale=Upscales[i],\n",
        "                attention=Attentions[i],\n",
        "                num_groups=num_groups,\n",
        "                dropout_prob=dropout_prob,\n",
        "                C=Channels[i],\n",
        "                num_heads=num_heads\n",
        "            )\n",
        "            setattr(self, f'Layer{i+1}', layer)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        x = self.shallow_conv(x)\n",
        "        embeddings = self.embeddings(x, t)\n",
        "        residuals = []\n",
        "\n",
        "        for i in range(self.num_layers // 2):\n",
        "            layer = getattr(self, f'Layer{i+1}')\n",
        "            x, res = layer(x, embeddings)\n",
        "            residuals.append(res)\n",
        "\n",
        "        for i in range(self.num_layers//2, self.num_layers):\n",
        "            layer = getattr(self, f'Layer{i+1}')\n",
        "            x = torch.concat((layer(x, embeddings)[0], residuals[self.num_layers-i-1]), dim=1)\n",
        "        return self.output_conv(self.relu(self.late_conv(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8fn_3uy0Ffv"
      },
      "source": [
        "### Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.415329Z",
          "iopub.status.busy": "2025-02-09T13:57:43.415016Z",
          "iopub.status.idle": "2025-02-09T13:57:43.431272Z",
          "shell.execute_reply": "2025-02-09T13:57:43.430569Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.415298Z"
        },
        "id": "yw96YZOGJtlK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class DDPM_Scheduler(nn.Module):\n",
        "    def __init__(self, num_time_steps=1000):\n",
        "        super().__init__()\n",
        "        print_log(f\"Using {num_time_steps} time steps.\")\n",
        "        self.beta = torch.linspace(1e-4, 0.02, num_time_steps, requires_grad=False)\n",
        "        alpha = 1 - self.beta\n",
        "        self.register_buffer('alpha', torch.cumprod(alpha, dim=0))\n",
        "\n",
        "    def forward(self, t):\n",
        "        return self.alpha[t]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.488594Z",
          "iopub.status.busy": "2025-02-09T13:57:43.488353Z",
          "iopub.status.idle": "2025-02-09T13:57:43.492610Z",
          "shell.execute_reply": "2025-02-09T13:57:43.491863Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.488575Z"
        },
        "id": "SHcGhW6OJtlK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vTKVJJu0KTU"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.494010Z",
          "iopub.status.busy": "2025-02-09T13:57:43.493740Z",
          "iopub.status.idle": "2025-02-09T13:57:43.509529Z",
          "shell.execute_reply": "2025-02-09T13:57:43.508809Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.493991Z"
        },
        "id": "YJaJywOLJtlK",
        "outputId": "cb81f22f-75a7-4d53-eb4c-7bf5ac69c841",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train(batch_size: int=16,\n",
        "          num_time_steps: int=500,\n",
        "          num_epochs: int=15,\n",
        "          seed: int=-1,\n",
        "          ema_decay: float=0.9999,\n",
        "          lr=2e-5,\n",
        "          data_dir: str='/healthy',\n",
        "          checkpoint_path: str=None):\n",
        "\n",
        "    # Set random seed\n",
        "    seed = random.randint(0, 2**32-1) if seed == -1 else seed\n",
        "    print_log(f\"Random seed set to: {seed}\")\n",
        "    set_seed(seed)\n",
        "\n",
        "    # Load dataset\n",
        "    print_log(\"Loading dataset...\")\n",
        "\n",
        "    train_dataset = BRATSDataset(directory=data_dir)\n",
        "    print_log(f\"Dataset length: {len(train_dataset)}\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=16, pin_memory=True)\n",
        "\n",
        "    try:\n",
        "        sample_batch = next(iter(train_loader))\n",
        "        print_log(f\"First batch shape: {sample_batch.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] DataLoader issue: {e}\")\n",
        "        return\n",
        "\n",
        "    _, H, W = sample_batch.shape[1:]\n",
        "\n",
        "    # Initialize model\n",
        "    scheduler = DDPM_Scheduler(num_time_steps=num_time_steps)\n",
        "    model = UNET(\n",
        "        input_channels=4,\n",
        "        output_channels=4,\n",
        "        Channels=[64, 128, 256, 512, 512, 384] if max(H, W) <= 256 else [32, 64, 128, 256, 256, 192]\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    ema = ModelEmaV3(model, decay=ema_decay)\n",
        "\n",
        "    # Load checkpoint\n",
        "    if checkpoint_path is not None and os.path.exists(checkpoint_path):\n",
        "        print_log(\"Loading checkpoint...\")\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
        "        model.load_state_dict(checkpoint['weights'])\n",
        "        ema.load_state_dict(checkpoint['ema'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "    criterion = nn.MSELoss(reduction='mean')\n",
        "    try:\n",
        "        iteration = 0\n",
        "        print_log(f\"Starting training for {num_epochs} epochs...\")\n",
        "\n",
        "        for i in range(num_epochs):\n",
        "            print_log(f\"Starting epoch {i+1}/{num_epochs}...\")\n",
        "            total_loss = 0\n",
        "\n",
        "            for bidx, x in enumerate(tqdm(train_loader, desc=f\"----------------------------------------------------------------\\nEpoch {i+1}/{num_epochs}\\n\")):\n",
        "                print(\"\")\n",
        "                print_log(f\"Processing batch {bidx+1}/{len(train_loader)}...\")\n",
        "\n",
        "                x = x.to(device)\n",
        "                print_log(f\"Batch shape: {x.shape}\")\n",
        "\n",
        "                # Normalize to [-1, 1]\n",
        "                x = normalize_images(x)\n",
        "\n",
        "                # Resize if necessary\n",
        "                if max(H, W) > 256:\n",
        "                    x = F.interpolate(x, size=(256, 256), mode='bilinear', align_corners=False)\n",
        "\n",
        "                t = torch.randint(0, num_time_steps, (x.shape[0],)).to(device)\n",
        "                e = torch.randn_like(x, requires_grad=False).to(device)\n",
        "                a = scheduler.alpha.to(device)[t].view(x.shape[0], 1, 1, 1)\n",
        "\n",
        "                x = (torch.sqrt(a) * x) + (torch.sqrt(1 - a) * e)\n",
        "\n",
        "                # Apply diffusion\n",
        "                output = model(x, t)\n",
        "                optimizer.zero_grad()\n",
        "                loss = criterion(output, e)\n",
        "\n",
        "                wandb.log(\n",
        "                    {\n",
        "                        \"iteration\": iteration,\n",
        "                        \"loss\": loss.item(),\n",
        "                        \"batch\": bidx+1,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                iteration += 1\n",
        "                total_loss += loss.item()\n",
        "                print_log(f\"Loss: {loss.item()}\")\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                ema.update(model)\n",
        "\n",
        "            print_log(f\"Epoch {i+1} | Loss {total_loss / len(train_loader):.5f}\")\n",
        "\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"epoch\": i+1,\n",
        "                    \"loss\": total_loss / len(train_loader),\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # Save checkpoint every 5 epochs\n",
        "            if (i + 1) % 5 == 0:\n",
        "                save_checkpoint(model, optimizer, ema, f'brats_ddpm_checkpoint_epoch_{i+1}.pth')\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n[WARNING] Training interrupted. Saving last checkpoint...\")\n",
        "        save_checkpoint(model, optimizer, ema, 'brats_ddpm_interrupted_checkpoint.pth')\n",
        "\n",
        "    print_log(\"Training complete.\")\n",
        "    save_checkpoint(model, optimizer, ema, 'brats_ddpm_final_checkpoint.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.511395Z",
          "iopub.status.busy": "2025-02-09T13:57:43.511152Z",
          "iopub.status.idle": "2025-02-09T13:57:43.530977Z",
          "shell.execute_reply": "2025-02-09T13:57:43.530192Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.511376Z"
        },
        "id": "gF-N6JqbJtlL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def display_reverse(images: List):\n",
        "    fig, axes = plt.subplots(1, 10, figsize=(10,1))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        x = images[i].squeeze(0)\n",
        "        x = rearrange(x, 'c h w -> h w c')\n",
        "        x = x.numpy()\n",
        "        ax.imshow(x)\n",
        "        ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def inference(checkpoint_path: str=None,\n",
        "              num_time_steps: int=1000,\n",
        "              ema_decay: float=0.9999, ):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model = UNET().cpu()\n",
        "    model.load_state_dict(checkpoint['weights'])\n",
        "    ema = ModelEmaV3(model, decay=ema_decay)\n",
        "    ema.load_state_dict(checkpoint['ema'])\n",
        "    scheduler = DDPM_Scheduler(num_time_steps=num_time_steps)\n",
        "    times = [0,15,50,100,200,300,400,550,700,999]\n",
        "    images = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model = ema.module.eval()\n",
        "        for i in range(10):\n",
        "            z = torch.randn(1, 1, 32, 32)\n",
        "            for t in reversed(range(1, num_time_steps)):\n",
        "                t = [t]\n",
        "                temp = (scheduler.beta[t]/( (torch.sqrt(1-scheduler.alpha[t]))*(torch.sqrt(1-scheduler.beta[t])) ))\n",
        "                z = (1/(torch.sqrt(1-scheduler.beta[t])))*z - (temp*model(z.cpu(),t).cpu())\n",
        "                if t[0] in times:\n",
        "                    images.append(z)\n",
        "                e = torch.randn(1, 1, 32, 32)\n",
        "                z = z + (e*torch.sqrt(scheduler.beta[t]))\n",
        "            temp = scheduler.beta[0]/( (torch.sqrt(1-scheduler.alpha[0]))*(torch.sqrt(1-scheduler.beta[0])) )\n",
        "            x = (1/(torch.sqrt(1-scheduler.beta[0])))*z - (temp*model(z.cpu(),[0]).cpu())\n",
        "\n",
        "            images.append(x)\n",
        "            x = rearrange(x.squeeze(0), 'c h w -> h w c').detach()\n",
        "            x = x.numpy()\n",
        "            plt.imshow(x)\n",
        "            plt.show()\n",
        "            display_reverse(images)\n",
        "            images = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eroMMFH0R9c"
      },
      "source": [
        "### Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.532110Z",
          "iopub.status.busy": "2025-02-09T13:57:43.531840Z",
          "iopub.status.idle": "2025-02-09T13:57:43.967209Z",
          "shell.execute_reply": "2025-02-09T13:57:43.966070Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.532083Z"
        },
        "id": "-YU-_H59JtlL",
        "outputId": "44080e18-26df-4983-e98c-3f439eaa28d9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for only 1 epochs!\n",
            "[Log] Random seed set to: 3828849926\n",
            "[Log] Loading dataset...\n",
            "[Log] Dataset length: 5680\n",
            "[Log] First batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Starting training for 1 epochs...\n",
            "[Log] Starting epoch 1/1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 0/5680 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 1/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0152230262756348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 1/5680 [00:23<36:54:05, 23.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 2/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0551211833953857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 2/5680 [00:44<35:11:46, 22.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 3/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0135560035705566\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 3/5680 [01:07<35:17:17, 22.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 4/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0555808544158936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 4/5680 [01:30<35:36:42, 22.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 5/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.011859655380249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 5/5680 [01:51<34:41:32, 22.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 6/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0159296989440918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 6/5680 [02:13<34:48:57, 22.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 7/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0046781301498413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 7/5680 [02:34<34:10:28, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 8/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9948047995567322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 8/5680 [02:56<34:23:31, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 9/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0093085765838623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 9/5680 [03:17<33:50:51, 21.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 10/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9903345704078674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 10/5680 [03:43<36:11:34, 22.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 11/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.013751745223999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 11/5680 [04:05<35:54:30, 22.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 12/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0103548765182495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 12/5680 [04:27<35:06:30, 22.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 13/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0081123113632202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 13/5680 [04:49<35:18:42, 22.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 14/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0194768905639648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 14/5680 [05:10<34:34:10, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 15/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9930764436721802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 15/5680 [05:32<34:40:35, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 16/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9765567779541016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 16/5680 [05:54<34:15:40, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 17/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0171525478363037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 17/5680 [06:16<34:30:55, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 18/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9849004149436951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 18/5680 [06:37<33:58:40, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 19/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9857592582702637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 19/5680 [06:59<34:19:30, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 20/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.999238908290863\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 20/5680 [07:20<33:59:32, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 21/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9821340441703796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 21/5680 [07:42<34:04:40, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 22/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9797205328941345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 22/5680 [08:04<34:17:24, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 23/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9724532961845398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 23/5680 [08:25<33:53:23, 21.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 24/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.000063180923462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 24/5680 [08:47<34:08:34, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 25/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9530729651451111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 25/5680 [09:08<33:45:51, 21.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 26/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9896901249885559\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 26/5680 [09:31<34:08:12, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 27/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9801082015037537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 27/5680 [09:51<33:44:25, 21.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 28/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9975807666778564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 28/5680 [10:14<34:10:19, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 29/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0008317232131958\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 29/5680 [10:35<33:53:23, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 30/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9667218923568726\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 30/5680 [10:57<34:10:35, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 31/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9521063566207886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 31/5680 [11:18<33:51:24, 21.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 32/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9653090834617615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 32/5680 [11:41<34:10:11, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 33/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9507534503936768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 33/5680 [12:02<34:02:55, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 34/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9551435112953186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 34/5680 [12:24<34:01:17, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 35/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.035882830619812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 35/5680 [12:45<33:57:54, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 36/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9482079744338989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 36/5680 [13:07<33:44:58, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 37/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9597234725952148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 37/5680 [13:29<34:06:06, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 38/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9485320448875427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 38/5680 [13:50<33:44:55, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 39/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9943030476570129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 39/5680 [14:12<34:04:50, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 40/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9880566000938416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 40/5680 [14:33<33:40:08, 21.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 41/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9780979752540588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 41/5680 [14:55<34:01:45, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 42/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9692570567131042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 42/5680 [15:16<33:39:21, 21.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 43/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9552075266838074\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 43/5680 [15:38<33:57:30, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 44/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9264540672302246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 44/5680 [16:00<33:44:26, 21.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 45/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9471526741981506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 45/5680 [16:22<34:09:26, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 46/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0003350973129272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 46/5680 [16:43<33:54:40, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 47/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9324210286140442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 47/5680 [17:05<33:57:11, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 48/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.952163577079773\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 48/5680 [17:27<33:55:29, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 49/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.980903685092926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 49/5680 [17:48<33:37:46, 21.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 50/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9487895369529724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 50/5680 [18:10<34:03:33, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 51/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9228098392486572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 51/5680 [18:31<33:38:40, 21.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 52/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9178342223167419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 52/5680 [18:54<33:58:34, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 53/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9891015291213989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 53/5680 [19:14<33:33:05, 21.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 54/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9198601841926575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 54/5680 [19:37<33:52:42, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 55/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9261701107025146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 55/5680 [19:58<33:42:04, 21.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 56/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9346335530281067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 56/5680 [20:20<34:02:34, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 57/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9444065093994141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 57/5680 [20:41<33:45:46, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 58/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9203993082046509\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 58/5680 [21:04<34:07:22, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 59/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0080493688583374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 59/5680 [21:25<33:55:10, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 60/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0330564975738525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 60/5680 [21:47<33:57:04, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 61/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9508023262023926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 61/5680 [22:09<34:12:24, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 62/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9420185089111328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 62/5680 [22:30<33:50:32, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 63/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9948996305465698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 63/5680 [22:53<34:07:32, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 64/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.032515287399292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 64/5680 [23:14<33:43:56, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 65/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9296214580535889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 65/5680 [23:36<34:00:59, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 66/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9095075130462646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 66/5680 [23:57<33:49:49, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 67/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9495982527732849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 67/5680 [24:20<34:10:36, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 68/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9024916291236877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 68/5680 [24:41<33:46:19, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 69/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9918668866157532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 69/5680 [25:03<34:02:34, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 70/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9099285006523132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 70/5680 [25:25<33:56:40, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 71/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9338691830635071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 71/5680 [25:46<33:49:14, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 72/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.883647084236145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 72/5680 [26:09<34:11:21, 21.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 73/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9137545228004456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 73/5680 [26:30<33:44:27, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 74/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9334558248519897\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 74/5680 [26:52<34:06:17, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 75/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9071978330612183\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 75/5680 [27:13<33:41:12, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 76/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9032378792762756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 76/5680 [27:36<33:57:07, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 77/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.874416172504425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 77/5680 [27:57<33:44:58, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 78/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9364174604415894\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 78/5680 [28:19<34:04:51, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 79/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9980915784835815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 79/5680 [28:41<33:51:33, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 80/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8950353264808655\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 80/5680 [29:03<33:57:06, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 81/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8571258187294006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 81/5680 [29:25<33:57:18, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 82/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9651418328285217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 82/5680 [29:46<33:40:03, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 83/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8732959628105164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 83/5680 [30:08<34:03:49, 21.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 84/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9033029079437256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 84/5680 [30:29<33:36:28, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 85/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9490482807159424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 85/5680 [30:52<33:58:51, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 86/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8420613408088684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 86/5680 [31:13<33:34:09, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 87/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8566706776618958\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 87/5680 [31:35<33:53:54, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 88/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9911085367202759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 88/5680 [31:56<33:33:46, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 89/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8820538520812988\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 89/5680 [32:18<33:49:07, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 90/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8682439923286438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 90/5680 [32:40<33:32:25, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 91/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8748950362205505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 91/5680 [33:02<33:47:52, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 92/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8526207804679871\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 92/5680 [33:23<33:40:25, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 93/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8817650079727173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 93/5680 [33:45<33:32:58, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 94/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8432872891426086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 94/5680 [34:07<33:47:35, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 95/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8918802738189697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 95/5680 [34:28<33:26:46, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 96/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8432487845420837\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 96/5680 [34:50<33:45:05, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 97/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8327198624610901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 97/5680 [35:11<33:23:14, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 98/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8722348213195801\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 98/5680 [35:33<33:42:59, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 99/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9873930811882019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 99/5680 [35:54<33:23:13, 21.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 100/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8301800489425659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 100/5680 [36:17<33:39:41, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 101/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8273051977157593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 101/5680 [36:38<33:18:07, 21.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 102/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8401370048522949\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 102/5680 [37:00<33:43:12, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 103/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9729903936386108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 103/5680 [37:21<33:17:14, 21.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 104/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8433173894882202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 104/5680 [37:43<33:28:44, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 105/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8448005318641663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 105/5680 [38:04<33:25:53, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 106/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8703160285949707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 106/5680 [38:26<33:25:29, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 107/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8453643918037415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 107/5680 [38:48<33:32:01, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 108/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9140517115592957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 108/5680 [39:09<33:14:05, 21.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 109/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8106304407119751\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 109/5680 [39:31<33:38:40, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 110/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.827776312828064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 110/5680 [39:52<33:17:34, 21.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 111/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7999908328056335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 111/5680 [40:14<33:40:18, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 112/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8712761998176575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 112/5680 [40:35<33:18:26, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 113/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8058862686157227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 113/5680 [40:58<33:39:15, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 114/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8311898112297058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 114/5680 [41:19<33:20:14, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 115/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8321754932403564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 115/5680 [41:41<33:42:46, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 116/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7988194227218628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 116/5680 [42:02<33:23:24, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 117/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8125925660133362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 117/5680 [42:24<33:37:12, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 118/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7827553153038025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 118/5680 [42:46<33:26:22, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 119/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7780492305755615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 119/5680 [43:07<33:21:21, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 120/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7754107713699341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 120/5680 [43:29<33:35:27, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 121/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8477756381034851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 121/5680 [43:50<33:11:51, 21.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 122/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8055909872055054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 122/5680 [44:12<33:29:50, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 123/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8521647453308105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 123/5680 [44:33<33:09:14, 21.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 124/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8087751269340515\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 124/5680 [44:55<33:26:51, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 125/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7622804641723633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 125/5680 [45:17<33:11:01, 21.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 126/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.864057183265686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 126/5680 [45:39<33:29:13, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 127/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8834661841392517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 127/5680 [46:00<33:16:16, 21.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 128/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8791274428367615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 128/5680 [46:22<33:35:12, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 129/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7612830996513367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 129/5680 [46:44<33:26:14, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 130/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8146936297416687\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 130/5680 [47:06<33:27:28, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 131/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.755581259727478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 131/5680 [47:28<33:37:35, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 132/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7611016631126404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 132/5680 [47:49<33:18:21, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 133/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9169661998748779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 133/5680 [48:11<33:36:02, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 134/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.727563738822937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 134/5680 [48:32<33:09:29, 21.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 135/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7779136300086975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 135/5680 [48:54<33:29:06, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 136/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7987850904464722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 136/5680 [49:15<33:04:58, 21.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 137/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8089743852615356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 137/5680 [49:37<33:26:50, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 138/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8465964198112488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 138/5680 [49:58<33:12:00, 21.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 139/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.828044593334198\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 139/5680 [50:21<33:28:14, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 140/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8071304559707642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 140/5680 [50:42<33:07:48, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 141/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8197280168533325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 141/5680 [51:04<33:32:31, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 142/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.00152587890625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 142/5680 [51:25<33:11:51, 21.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 143/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7426822781562805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 143/5680 [51:47<33:23:07, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 144/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.922909140586853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 144/5680 [52:09<33:32:40, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 145/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.718802809715271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 145/5680 [52:30<33:13:48, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 146/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7147679328918457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 146/5680 [52:53<33:28:47, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 147/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9338834881782532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 147/5680 [53:13<33:04:15, 21.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 148/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7010403871536255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 148/5680 [53:36<33:21:50, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 149/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0256319046020508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 149/5680 [53:57<33:05:35, 21.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 150/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7259597778320312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 150/5680 [54:19<33:25:44, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 151/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7101733684539795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 151/5680 [54:40<33:10:18, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 152/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7067279815673828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 152/5680 [55:02<33:23:54, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 153/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.699510395526886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 153/5680 [55:23<33:04:24, 21.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 154/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7055210471153259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 154/5680 [55:46<33:24:30, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 155/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6799590587615967\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 155/5680 [56:07<33:09:11, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 156/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7122490406036377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 156/5680 [56:29<33:20:11, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 157/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.949158787727356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 157/5680 [56:51<33:28:29, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 158/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6904449462890625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 158/5680 [57:12<33:03:57, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 159/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8932921290397644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 159/5680 [57:34<33:27:32, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 160/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9115382432937622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 160/5680 [57:55<33:06:26, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 161/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.897833526134491\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 161/5680 [58:18<33:26:10, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 162/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7397810220718384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 162/5680 [58:39<33:07:23, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 163/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9438093900680542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 163/5680 [59:01<33:27:51, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 164/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6607493162155151\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 164/5680 [59:22<33:06:58, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 165/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.902549147605896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 165/5680 [59:45<33:28:38, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 166/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6562877893447876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 166/5680 [1:00:06<33:19:57, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 167/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6767470240592957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 167/5680 [1:00:28<33:22:35, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 168/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7813467383384705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 168/5680 [1:00:50<33:24:51, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 169/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6572627425193787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 169/5680 [1:01:11<33:05:56, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 170/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6715947389602661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 170/5680 [1:01:34<33:25:54, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 171/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6740336418151855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 171/5680 [1:01:55<33:02:21, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 172/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6897129416465759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 172/5680 [1:02:17<33:23:51, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 173/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6252249479293823\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 173/5680 [1:02:38<33:02:04, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 174/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8789944648742676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 174/5680 [1:03:00<33:20:32, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 175/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6382516026496887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 175/5680 [1:03:21<33:02:42, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 176/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6386626958847046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 176/5680 [1:03:44<33:22:27, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 177/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.791951060295105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 177/5680 [1:04:05<33:05:50, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 178/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6212067604064941\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 178/5680 [1:04:27<33:23:13, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 179/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6437190175056458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 179/5680 [1:04:49<33:21:21, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 180/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8273017406463623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 180/5680 [1:05:10<33:06:29, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 181/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9080275893211365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 181/5680 [1:05:33<33:25:27, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 182/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8300772309303284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 182/5680 [1:05:54<33:03:22, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 183/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0107088088989258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 183/5680 [1:06:16<33:22:56, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 184/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9056440591812134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 184/5680 [1:06:37<32:59:44, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 185/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9500229954719543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 185/5680 [1:07:00<33:20:36, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 186/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6423363089561462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 186/5680 [1:07:21<33:04:45, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 187/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.932767927646637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 187/5680 [1:07:43<33:23:53, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 188/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6366046667098999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 188/5680 [1:08:05<33:08:05, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 189/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6893437504768372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 189/5680 [1:08:27<33:20:45, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 190/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6453093886375427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 190/5680 [1:08:49<33:15:38, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 191/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6170741319656372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 191/5680 [1:09:10<33:04:27, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 192/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7219305634498596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 192/5680 [1:09:32<33:26:01, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 193/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.961249828338623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 193/5680 [1:09:54<33:02:10, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 194/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7011813521385193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 194/5680 [1:10:16<33:22:23, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 195/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7602555751800537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 195/5680 [1:10:37<33:03:55, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 196/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6606771349906921\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 196/5680 [1:10:59<33:20:34, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 197/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6481676697731018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 197/5680 [1:11:21<32:59:52, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 198/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6377983093261719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 198/5680 [1:11:43<33:20:49, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 199/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6666826009750366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 199/5680 [1:12:05<33:14:17, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 200/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.703864336013794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 200/5680 [1:12:27<33:14:50, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 201/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6030898094177246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 201/5680 [1:12:49<33:23:32, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 202/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5921798348426819\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 202/5680 [1:13:10<32:57:54, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 203/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6083749532699585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 203/5680 [1:13:32<33:16:27, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 204/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8030290007591248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 204/5680 [1:13:53<32:56:32, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 205/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6288220286369324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 205/5680 [1:14:16<33:11:45, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 206/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5960052609443665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 206/5680 [1:14:37<32:55:41, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 207/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8373295068740845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 207/5680 [1:14:59<33:13:13, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 208/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5801689028739929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 208/5680 [1:15:20<32:56:58, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 209/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5923794507980347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 209/5680 [1:15:43<33:17:17, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 210/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6720933318138123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 210/5680 [1:16:04<33:08:20, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 211/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6761579513549805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 211/5680 [1:16:26<33:06:09, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 212/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7472823858261108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 212/5680 [1:16:48<33:10:28, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 213/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5825192332267761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 213/5680 [1:17:09<32:45:32, 21.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 214/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6054588556289673\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 214/5680 [1:17:31<33:06:00, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 215/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6782596707344055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 215/5680 [1:17:52<32:40:08, 21.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 216/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8826178312301636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 216/5680 [1:18:15<33:01:42, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 217/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8759638071060181\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 217/5680 [1:18:36<32:47:18, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 218/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6745875477790833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 218/5680 [1:18:58<33:08:28, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 219/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.557746171951294\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 219/5680 [1:19:19<32:50:12, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 220/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8534396290779114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 220/5680 [1:19:42<33:08:42, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 221/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6980065107345581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 221/5680 [1:20:03<32:52:43, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 222/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.631144106388092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 222/5680 [1:20:25<33:01:05, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 223/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.540234386920929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 223/5680 [1:20:47<33:05:30, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 224/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5472036004066467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 224/5680 [1:21:08<32:48:22, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 225/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5646430850028992\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 225/5680 [1:21:31<33:07:45, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 226/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6136066913604736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 226/5680 [1:21:52<32:43:08, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 227/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7329639196395874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 227/5680 [1:22:14<33:04:14, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 228/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5338618159294128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 228/5680 [1:22:35<32:44:54, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 229/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6039988398551941\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 229/5680 [1:22:57<33:03:10, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 230/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5355167388916016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 230/5680 [1:23:19<32:43:58, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 231/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5839695334434509\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 231/5680 [1:23:41<33:03:08, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 232/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5787850618362427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 232/5680 [1:24:02<32:53:24, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 233/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6847694516181946\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 233/5680 [1:24:24<32:57:18, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 234/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7331389784812927\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 234/5680 [1:24:46<32:59:57, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 235/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5287871956825256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 235/5680 [1:25:07<32:43:32, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 236/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5241568088531494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 236/5680 [1:25:30<33:04:16, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 237/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5445302128791809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 237/5680 [1:25:51<32:33:45, 21.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 238/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5804065465927124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 238/5680 [1:26:13<32:57:36, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 239/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8555901646614075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 239/5680 [1:26:34<32:37:46, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 240/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5349752902984619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 240/5680 [1:26:56<32:57:32, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 241/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5560889840126038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 241/5680 [1:27:17<32:37:23, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 242/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5231744050979614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 242/5680 [1:27:40<32:56:12, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 243/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7459129095077515\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 243/5680 [1:28:01<32:38:24, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 244/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5191289186477661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 244/5680 [1:28:23<32:57:19, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 245/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6979650259017944\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 245/5680 [1:28:45<32:49:53, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 246/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5749766826629639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 246/5680 [1:29:06<32:44:47, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 247/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5270084142684937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 247/5680 [1:29:28<32:48:34, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 248/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6098309755325317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 248/5680 [1:29:49<32:33:34, 21.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 249/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4793994724750519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 249/5680 [1:30:12<32:52:53, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 250/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5179524421691895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 250/5680 [1:30:33<32:30:17, 21.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 251/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4907151758670807\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 251/5680 [1:30:55<32:50:06, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 252/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5090770721435547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 252/5680 [1:31:16<32:29:05, 21.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 253/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5863445401191711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 253/5680 [1:31:38<32:50:14, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 254/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5917221307754517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 254/5680 [1:32:00<32:38:10, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 255/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6807495355606079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 255/5680 [1:32:22<32:58:40, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 256/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5264755487442017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 256/5680 [1:32:43<32:31:21, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 257/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5936943292617798\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 257/5680 [1:33:05<32:46:06, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 258/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4637826979160309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 258/5680 [1:33:27<32:43:15, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 259/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.48262614011764526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 259/5680 [1:33:48<32:36:46, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 260/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7732040286064148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 260/5680 [1:34:11<32:56:03, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 261/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6447793841362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 261/5680 [1:34:31<32:24:56, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 262/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.48704105615615845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 262/5680 [1:34:54<32:50:06, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 263/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9835833311080933\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 263/5680 [1:35:15<32:26:24, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 264/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4943973422050476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 264/5680 [1:35:37<32:44:15, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 265/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8502985239028931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 265/5680 [1:35:58<32:31:32, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 266/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5154467225074768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 266/5680 [1:36:21<32:51:10, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 267/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4485778212547302\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 267/5680 [1:36:42<32:27:46, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 268/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8208436369895935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 268/5680 [1:37:04<32:46:48, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 269/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5036846995353699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 269/5680 [1:37:26<32:37:10, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 270/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7272104024887085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 270/5680 [1:37:47<32:34:16, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 271/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8485208749771118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 271/5680 [1:38:09<32:46:35, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 272/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.524206280708313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 272/5680 [1:38:30<32:26:47, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 273/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4438004493713379\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 273/5680 [1:38:53<32:42:44, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 274/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6623488664627075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 274/5680 [1:39:14<32:20:12, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 275/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.47747042775154114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 275/5680 [1:39:36<32:40:35, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 276/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9464658498764038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 276/5680 [1:39:57<32:24:06, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 277/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0001221895217896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 277/5680 [1:40:19<32:41:27, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 278/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4369836449623108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 278/5680 [1:40:40<32:23:18, 21.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 279/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.45248374342918396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 279/5680 [1:41:03<32:45:17, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 280/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4789738655090332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 280/5680 [1:41:24<32:28:04, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 281/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6064603328704834\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 281/5680 [1:41:46<32:37:54, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 282/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5042999982833862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 282/5680 [1:42:08<32:41:47, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 283/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6570360064506531\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 283/5680 [1:42:29<32:24:50, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 284/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4599565267562866\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 284/5680 [1:42:51<32:43:20, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 285/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.49002572894096375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 285/5680 [1:43:12<32:16:37, 21.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 286/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6712660193443298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 286/5680 [1:43:35<32:38:39, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 287/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6458577513694763\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 287/5680 [1:43:56<32:18:22, 21.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 288/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6781820058822632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 288/5680 [1:44:18<32:37:40, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 289/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4300200343132019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 289/5680 [1:44:39<32:21:21, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 290/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4190353453159332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 290/5680 [1:45:02<32:42:26, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 291/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.46247121691703796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 291/5680 [1:45:23<32:23:17, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 292/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4785846769809723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 292/5680 [1:45:45<32:37:02, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 293/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.43102654814720154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 293/5680 [1:46:07<32:37:54, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 294/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3989282250404358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 294/5680 [1:46:28<32:28:11, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 295/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4679056704044342\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 295/5680 [1:46:50<32:43:46, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 296/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4815010130405426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 296/5680 [1:47:11<32:19:10, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 297/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4544936418533325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 297/5680 [1:47:34<32:38:11, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 298/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.46879810094833374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 298/5680 [1:47:55<32:18:56, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 299/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5850716233253479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 299/5680 [1:48:17<32:37:13, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 300/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5923325419425964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 300/5680 [1:48:38<32:19:57, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 301/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6211153864860535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 301/5680 [1:49:01<32:34:24, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 302/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5324507355690002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 302/5680 [1:49:21<32:07:06, 21.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 303/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4059312045574188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 303/5680 [1:49:44<32:30:49, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 304/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.407583087682724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 304/5680 [1:50:05<32:26:26, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 305/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4565689265727997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 305/5680 [1:50:27<32:26:16, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 306/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5199109315872192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 306/5680 [1:50:49<32:28:18, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 307/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5721908807754517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 307/5680 [1:51:10<32:14:42, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 308/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.40285226702690125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 308/5680 [1:51:33<32:38:13, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 309/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5573896765708923\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 309/5680 [1:51:54<32:17:48, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 310/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5865753293037415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 310/5680 [1:52:16<32:34:44, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 311/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.40457290410995483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 311/5680 [1:52:38<32:21:41, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 312/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.42635002732276917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 312/5680 [1:53:00<32:46:44, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 313/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5233358144760132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 313/5680 [1:53:22<32:32:34, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 314/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.40076297521591187\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 314/5680 [1:53:44<32:44:54, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 315/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7761018872261047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 315/5680 [1:54:06<32:52:33, 22.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 316/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5378651022911072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 316/5680 [1:54:28<32:35:08, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 317/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3582572638988495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 317/5680 [1:54:50<32:54:08, 22.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 318/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4969632029533386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 318/5680 [1:55:11<32:27:20, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 319/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.460647851228714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 319/5680 [1:55:34<32:43:48, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 320/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7206172943115234\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 320/5680 [1:55:55<32:28:59, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 321/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.43886905908584595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 321/5680 [1:56:18<32:47:03, 22.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 322/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5945945382118225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 322/5680 [1:56:39<32:24:55, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 323/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5074833631515503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 323/5680 [1:57:01<32:41:19, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 324/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8805930614471436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 324/5680 [1:57:23<32:43:10, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 325/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3835906982421875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 325/5680 [1:57:45<32:23:43, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 326/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4082581400871277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 326/5680 [1:58:07<32:47:21, 22.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 327/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.37793102860450745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 327/5680 [1:58:29<32:24:48, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 328/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6316237449645996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 328/5680 [1:58:51<32:36:23, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 329/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.37862011790275574\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 329/5680 [1:59:12<32:16:22, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 330/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5907600522041321\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 330/5680 [1:59:34<32:36:19, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 331/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3595849275588989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 331/5680 [1:59:56<32:20:23, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 332/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5835270881652832\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 332/5680 [2:00:18<32:41:53, 22.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 333/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5316725969314575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 333/5680 [2:00:40<32:43:02, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 334/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9778770208358765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 334/5680 [2:01:02<32:26:55, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 335/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7237182259559631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 335/5680 [2:01:24<32:39:29, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 336/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.41389888525009155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 336/5680 [2:01:45<32:16:49, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 337/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6710547208786011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 337/5680 [2:02:08<32:41:23, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 338/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4087144136428833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 338/5680 [2:02:29<32:22:18, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 339/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7515076398849487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 339/5680 [2:02:52<32:39:13, 22.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 340/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.556664228439331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 340/5680 [2:03:13<32:18:26, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 341/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.35056009888648987\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 341/5680 [2:03:36<32:36:48, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 342/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.428803414106369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 342/5680 [2:03:57<32:29:58, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 343/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4545172452926636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 343/5680 [2:04:19<32:19:09, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 344/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.35969245433807373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 344/5680 [2:04:41<32:38:53, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 345/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7402709126472473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 345/5680 [2:05:03<32:13:57, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 346/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3288927972316742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 346/5680 [2:05:25<32:31:37, 21.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 347/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5668787956237793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 347/5680 [2:05:46<32:10:28, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 348/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.36851394176483154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 348/5680 [2:06:09<32:29:00, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 349/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4002871513366699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 349/5680 [2:06:30<32:11:54, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 350/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.35678809881210327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 350/5680 [2:06:52<32:30:03, 21.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 351/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.320437490940094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 351/5680 [2:07:13<32:10:15, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 352/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3706008791923523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 352/5680 [2:07:36<32:22:59, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 353/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4980817437171936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 353/5680 [2:07:58<32:20:59, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 354/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5512747168540955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 354/5680 [2:08:19<32:07:09, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 355/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3136175572872162\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 355/5680 [2:08:41<32:29:52, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 356/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.43275195360183716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 356/5680 [2:09:03<32:08:52, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 357/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6081244945526123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 357/5680 [2:09:25<32:22:39, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 358/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5579610466957092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 358/5680 [2:09:46<32:00:55, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 359/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3339606523513794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 359/5680 [2:10:09<32:26:46, 21.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 360/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.33327335119247437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 360/5680 [2:10:30<32:10:39, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 361/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3994961977005005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 361/5680 [2:10:52<32:26:23, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 362/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3832632303237915\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 362/5680 [2:11:14<32:20:36, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 363/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3282968997955322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 363/5680 [2:11:36<32:15:42, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 364/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.30214637517929077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 364/5680 [2:11:58<32:24:09, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 365/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.347521036863327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 365/5680 [2:12:19<32:04:00, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 366/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3074777126312256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 366/5680 [2:12:42<32:27:19, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 367/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.36915814876556396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 367/5680 [2:13:03<32:02:22, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 368/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.43919312953948975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 368/5680 [2:13:25<32:17:56, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 369/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5300917625427246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 369/5680 [2:13:47<32:03:26, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 370/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.35501933097839355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 370/5680 [2:14:09<32:24:29, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 371/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.43497228622436523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 371/5680 [2:14:31<32:10:04, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 372/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.35436028242111206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 372/5680 [2:14:53<32:20:23, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 373/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3369831442832947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 373/5680 [2:15:15<32:22:10, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 374/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.34126758575439453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 374/5680 [2:15:36<32:09:37, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 375/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9002498388290405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 375/5680 [2:15:59<32:31:46, 22.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 376/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3843235671520233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 376/5680 [2:16:20<32:10:36, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 377/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.364808052778244\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 377/5680 [2:16:43<32:27:28, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 378/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2862616777420044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 378/5680 [2:17:04<32:06:09, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 379/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2904300093650818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 379/5680 [2:17:27<32:25:14, 22.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 380/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4975922107696533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 380/5680 [2:17:48<32:09:08, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 381/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2870476245880127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 381/5680 [2:18:11<32:30:31, 22.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 382/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7143220901489258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 382/5680 [2:18:33<32:28:46, 22.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 383/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.48671621084213257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 383/5680 [2:18:54<32:09:10, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 384/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3020954728126526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 384/5680 [2:19:16<32:20:10, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 385/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.33241674304008484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 385/5680 [2:19:37<31:54:28, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 386/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.33841848373413086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 386/5680 [2:20:00<32:14:40, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 387/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.30571451783180237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 387/5680 [2:20:21<31:52:32, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 388/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5848740339279175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 388/5680 [2:20:43<32:06:48, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 389/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2924026548862457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 389/5680 [2:21:04<31:48:58, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 390/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3306640684604645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 390/5680 [2:21:27<32:10:19, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 391/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.624183177947998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 391/5680 [2:21:48<31:56:28, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 392/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3539128601551056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 392/5680 [2:22:10<32:09:17, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 393/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.29028183221817017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 393/5680 [2:22:32<32:11:44, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 394/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6992501020431519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 394/5680 [2:22:54<31:53:35, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 395/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5693199634552002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 395/5680 [2:23:16<32:08:46, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 396/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.38306891918182373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 396/5680 [2:23:37<31:45:04, 21.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 397/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.27371707558631897\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 397/5680 [2:23:59<32:05:30, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 398/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6903332471847534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 398/5680 [2:24:20<31:44:55, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 399/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4543309807777405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 399/5680 [2:24:43<32:04:57, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 400/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.35180628299713135\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 400/5680 [2:25:04<31:44:26, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 401/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.40533366799354553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 401/5680 [2:25:26<32:03:54, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 402/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2659929096698761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 402/5680 [2:25:48<31:50:30, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 403/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.29552626609802246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 403/5680 [2:26:10<31:58:27, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 404/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2910727560520172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 404/5680 [2:26:32<31:57:27, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 405/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.367715448141098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 405/5680 [2:26:53<31:38:50, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 406/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3000560998916626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 406/5680 [2:27:15<31:59:06, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 407/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.777368426322937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 407/5680 [2:27:36<31:36:15, 21.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 408/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2572760283946991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 408/5680 [2:27:59<32:01:38, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 409/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5752502083778381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 409/5680 [2:28:20<31:39:17, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 410/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4387357532978058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 410/5680 [2:28:42<31:58:38, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 411/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.24721436202526093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 411/5680 [2:29:03<31:43:25, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 412/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.24951282143592834\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 412/5680 [2:29:26<31:58:49, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 413/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.26872754096984863\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 413/5680 [2:29:47<31:42:07, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 414/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6089677810668945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 414/5680 [2:30:09<31:54:43, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 415/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8875277042388916\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 415/5680 [2:30:31<31:56:33, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 416/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.313766211271286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 416/5680 [2:30:52<31:37:36, 21.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 417/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.46387171745300293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 417/5680 [2:31:14<31:54:34, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 418/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2663150429725647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 418/5680 [2:31:35<31:28:05, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 419/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4298485815525055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 419/5680 [2:31:58<31:52:55, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 420/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.31851157546043396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 420/5680 [2:32:19<31:33:06, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 421/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.25731220841407776\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 421/5680 [2:32:41<31:52:07, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 422/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.49344903230667114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 422/5680 [2:33:02<31:38:24, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 423/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2844461500644684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 423/5680 [2:33:25<31:59:00, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 424/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2440957874059677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 424/5680 [2:33:46<31:40:04, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 425/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8273128271102905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 425/5680 [2:34:08<31:51:51, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 426/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8762698173522949\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 426/5680 [2:34:30<31:51:19, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 427/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2547606825828552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 427/5680 [2:34:51<31:35:14, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 428/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.26074111461639404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 428/5680 [2:35:13<31:50:45, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 429/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3233414888381958\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 429/5680 [2:35:34<31:26:39, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 430/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23975780606269836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 430/5680 [2:35:57<31:46:05, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 431/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4071466624736786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 431/5680 [2:36:18<31:25:19, 21.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 432/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4155983030796051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 432/5680 [2:36:40<31:41:16, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 433/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3020339608192444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 433/5680 [2:37:01<31:21:16, 21.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 434/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7255657911300659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 434/5680 [2:37:23<31:39:07, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 435/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22985565662384033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 435/5680 [2:37:44<31:21:49, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 436/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6363674998283386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 436/5680 [2:38:06<31:42:34, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 437/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3051716685295105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 437/5680 [2:38:28<31:24:23, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 438/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.30245286226272583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 438/5680 [2:38:49<31:34:18, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 439/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23461830615997314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 439/5680 [2:39:11<31:36:53, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 440/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.371694952249527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 440/5680 [2:39:33<31:25:31, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 441/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6948171257972717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 441/5680 [2:39:55<31:44:23, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 442/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6280380487442017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 442/5680 [2:40:16<31:17:01, 21.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 443/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2340071052312851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 443/5680 [2:40:38<31:37:09, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 444/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8881476521492004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 444/5680 [2:40:59<31:16:32, 21.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 445/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.38405442237854004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 445/5680 [2:41:21<31:33:17, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 446/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.010310173034668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 446/5680 [2:41:42<31:16:53, 21.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 447/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2497256100177765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 447/5680 [2:42:05<31:41:49, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 448/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2618277072906494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 448/5680 [2:42:26<31:24:13, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 449/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.21518872678279877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 449/5680 [2:42:48<31:36:22, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 450/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7737061381340027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 450/5680 [2:43:09<31:29:36, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 451/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22368378937244415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 451/5680 [2:43:31<31:19:58, 21.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 452/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2662004828453064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 452/5680 [2:43:53<31:37:27, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 453/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3000568449497223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 453/5680 [2:44:14<31:14:50, 21.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 454/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4970596432685852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 454/5680 [2:44:36<31:33:53, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 455/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2254011332988739\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 455/5680 [2:44:57<31:14:49, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 456/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.25375673174858093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 456/5680 [2:45:19<31:33:15, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 457/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2277582287788391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 457/5680 [2:45:41<31:16:41, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 458/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3499366044998169\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 458/5680 [2:46:03<31:39:28, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 459/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9554305076599121\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 459/5680 [2:46:24<31:13:33, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 460/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22256618738174438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 460/5680 [2:46:46<31:32:54, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 461/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2513541281223297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 461/5680 [2:47:08<31:29:36, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 462/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2334827333688736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 462/5680 [2:47:29<31:21:15, 21.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 463/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4236045479774475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 463/5680 [2:47:51<31:30:54, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 464/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23765617609024048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 464/5680 [2:48:12<31:10:21, 21.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 465/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.28766682744026184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 465/5680 [2:48:34<31:29:21, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 466/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3131321668624878\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 466/5680 [2:48:55<31:09:30, 21.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 467/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2417023926973343\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 467/5680 [2:49:18<31:24:36, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 468/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.24376243352890015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 468/5680 [2:49:39<31:10:38, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 469/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3252319097518921\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 469/5680 [2:50:01<31:32:32, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 470/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3265816271305084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 470/5680 [2:50:22<31:12:05, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 471/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.25882768630981445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 471/5680 [2:50:44<31:31:46, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 472/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4590805172920227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 472/5680 [2:51:06<31:27:35, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 473/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2746070921421051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 473/5680 [2:51:27<31:17:56, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 474/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3079874515533447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 474/5680 [2:51:50<31:37:51, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 475/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2060677409172058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 475/5680 [2:52:11<31:15:53, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 476/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.20742031931877136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 476/5680 [2:52:33<31:34:16, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 477/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3732653856277466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 477/5680 [2:52:54<31:11:21, 21.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 478/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.20365111529827118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 478/5680 [2:53:16<31:23:12, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 479/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2525768280029297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 479/5680 [2:53:38<31:08:58, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 480/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19244489073753357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 480/5680 [2:54:00<31:29:19, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 481/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22728124260902405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 481/5680 [2:54:21<31:17:47, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 482/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22552791237831116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 482/5680 [2:54:43<31:25:47, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 483/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.261929988861084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 483/5680 [2:55:05<31:27:12, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 484/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3318736255168915\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 484/5680 [2:55:26<31:11:05, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 485/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4603784680366516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 485/5680 [2:55:49<31:30:06, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 486/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22706292569637299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 486/5680 [2:56:10<31:10:43, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 487/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2675849199295044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 487/5680 [2:56:32<31:29:28, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 488/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.35171234607696533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 488/5680 [2:56:53<31:09:53, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 489/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22091630101203918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 489/5680 [2:57:15<31:26:01, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 490/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1894005388021469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 490/5680 [2:57:37<31:09:01, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 491/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3358651101589203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 491/5680 [2:57:59<31:29:27, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 492/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18627122044563293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 492/5680 [2:58:21<31:23:36, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 493/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3682253062725067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 493/5680 [2:58:42<31:18:49, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 494/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1921669989824295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 494/5680 [2:59:04<31:29:43, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 495/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.39179226756095886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 495/5680 [2:59:25<31:07:35, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 496/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22109150886535645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 496/5680 [2:59:48<31:23:34, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 497/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2125719040632248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 497/5680 [3:00:10<31:40:12, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 498/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22268718481063843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 498/5680 [3:00:33<32:08:59, 22.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 499/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8928933143615723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 499/5680 [3:00:54<31:39:43, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 500/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.24361634254455566\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 500/5680 [3:01:17<31:51:08, 22.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 501/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.467180997133255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 501/5680 [3:01:39<31:42:36, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 502/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18927444517612457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 502/5680 [3:02:00<31:27:19, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 503/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3859238624572754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 503/5680 [3:02:22<31:36:38, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 504/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4876096546649933\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 504/5680 [3:02:43<31:10:03, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 505/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18221570551395416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 505/5680 [3:03:06<31:28:56, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 506/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19185695052146912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 506/5680 [3:03:27<31:07:39, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 507/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1788402944803238\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 507/5680 [3:03:49<31:24:32, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 508/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2973729074001312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 508/5680 [3:04:10<31:08:42, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 509/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2389647513628006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 509/5680 [3:04:33<31:29:36, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 510/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8550016283988953\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 510/5680 [3:04:55<31:22:02, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 511/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22993555665016174\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 511/5680 [3:05:16<31:18:47, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 512/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17429932951927185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 512/5680 [3:05:39<31:32:15, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 513/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.25802066922187805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 513/5680 [3:06:00<31:11:20, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 514/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.21980728209018707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 514/5680 [3:06:22<31:29:18, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 515/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2604660987854004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 515/5680 [3:06:44<31:10:43, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 516/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2995128035545349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 516/5680 [3:07:06<31:32:31, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 517/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2873654365539551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 517/5680 [3:07:28<31:17:23, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 518/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17708249390125275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 518/5680 [3:07:50<31:39:03, 22.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 519/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2600919008255005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 519/5680 [3:08:12<31:34:33, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 520/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.21527604758739471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 520/5680 [3:08:34<31:19:23, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 521/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17443212866783142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 521/5680 [3:08:56<31:33:15, 22.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 522/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.32341820001602173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 522/5680 [3:09:17<31:11:25, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 523/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2038600593805313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 523/5680 [3:09:40<31:29:25, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 524/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2909198999404907\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 524/5680 [3:10:01<31:10:58, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 525/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17444641888141632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 525/5680 [3:10:23<31:28:53, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 526/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19062933325767517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 526/5680 [3:10:45<31:10:19, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 527/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5315525531768799\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 527/5680 [3:11:07<31:27:41, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 528/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17219150066375732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 528/5680 [3:11:29<31:15:25, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 529/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19722217321395874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 529/5680 [3:11:50<31:09:44, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 530/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3953562378883362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 530/5680 [3:12:13<31:24:19, 21.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 531/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.20505475997924805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 531/5680 [3:12:34<30:57:38, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 532/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18230792880058289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 532/5680 [3:12:56<31:14:28, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 533/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.44330739974975586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 533/5680 [3:13:17<30:58:25, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 534/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16701048612594604\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 534/5680 [3:13:40<31:18:26, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 535/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4887866675853729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 535/5680 [3:14:01<31:04:26, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 536/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.27640393376350403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 536/5680 [3:14:24<31:23:37, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 537/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.24725370109081268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 537/5680 [3:14:45<31:14:30, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 538/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3654002845287323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 538/5680 [3:15:07<31:10:33, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 539/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1966555118560791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 539/5680 [3:15:29<31:21:41, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 540/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5546685457229614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 540/5680 [3:15:50<30:57:29, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 541/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.21681173145771027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 541/5680 [3:16:13<31:19:02, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 542/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18130692839622498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 542/5680 [3:16:34<30:58:34, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 543/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15027526021003723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 543/5680 [3:16:56<31:17:12, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 544/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.330743670463562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 544/5680 [3:17:18<31:00:45, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 545/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2487439662218094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 545/5680 [3:17:40<31:23:47, 22.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 546/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17796210944652557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 546/5680 [3:18:02<31:20:15, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 547/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19910961389541626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 547/5680 [3:18:24<31:18:17, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 548/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.21023662388324738\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 548/5680 [3:18:47<31:34:04, 22.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 549/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2889360189437866\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 549/5680 [3:19:08<31:05:29, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 550/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19615055620670319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 550/5680 [3:19:30<31:24:00, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 551/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17727968096733093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 551/5680 [3:19:52<31:07:25, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 552/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.44548720121383667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 552/5680 [3:20:14<31:24:45, 22.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 553/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23161153495311737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 553/5680 [3:20:35<31:03:56, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 554/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9845749139785767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 554/5680 [3:20:58<31:22:24, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 555/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9427202343940735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 555/5680 [3:21:20<31:19:59, 22.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 556/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4270079731941223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 556/5680 [3:21:42<31:09:48, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 557/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.723092794418335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 557/5680 [3:22:04<31:27:40, 22.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 558/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2927395701408386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 558/5680 [3:22:25<31:01:36, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 559/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.27796846628189087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 559/5680 [3:22:48<31:15:22, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 560/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18167836964130402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 560/5680 [3:23:09<30:58:05, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 561/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9513945579528809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 561/5680 [3:23:31<31:16:25, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 562/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16186437010765076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 562/5680 [3:23:53<30:59:17, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 563/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16159892082214355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 563/5680 [3:24:15<31:20:04, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 564/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16277414560317993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 564/5680 [3:24:37<31:18:22, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 565/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18465971946716309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 565/5680 [3:24:59<31:03:16, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 566/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17730110883712769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 566/5680 [3:25:21<31:14:46, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 567/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2563045024871826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 567/5680 [3:25:42<30:52:50, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 568/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17151892185211182\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 568/5680 [3:26:05<31:11:18, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 569/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18074661493301392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 569/5680 [3:26:26<30:52:57, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 570/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6731767058372498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 570/5680 [3:26:49<31:10:40, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 571/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1604304164648056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 571/5680 [3:27:10<30:52:16, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 572/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14959651231765747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 572/5680 [3:27:32<31:12:08, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 573/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.37688446044921875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 573/5680 [3:27:54<31:05:45, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 574/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3362923860549927\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 574/5680 [3:28:16<31:02:48, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 575/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18008220195770264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 575/5680 [3:28:39<31:20:56, 22.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 576/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15851126611232758\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 576/5680 [3:29:00<30:53:41, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 577/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15857148170471191\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 577/5680 [3:29:22<31:12:42, 22.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 578/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14119933545589447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 578/5680 [3:29:43<30:54:17, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 579/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0157266855239868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 579/5680 [3:30:06<31:13:23, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 580/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13933709263801575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 580/5680 [3:30:27<30:55:54, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 581/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.28985080122947693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 581/5680 [3:30:50<31:14:41, 22.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 582/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1945870816707611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 582/5680 [3:31:12<31:11:21, 22.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 583/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2509210705757141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 583/5680 [3:31:33<30:57:04, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 584/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.182430237531662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 584/5680 [3:31:56<31:17:14, 22.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 585/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17171019315719604\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 585/5680 [3:32:17<30:52:20, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 586/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7811892032623291\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 586/5680 [3:32:40<31:10:37, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 587/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1487913578748703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 587/5680 [3:33:01<30:53:25, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 588/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23177386820316315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 588/5680 [3:33:24<31:09:34, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 589/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.20888301730155945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 589/5680 [3:33:45<30:54:44, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 590/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1544104963541031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 590/5680 [3:34:08<31:10:34, 22.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 591/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1539684683084488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 591/5680 [3:34:30<31:14:39, 22.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 592/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15119627118110657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 592/5680 [3:34:51<30:56:41, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 593/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14541354775428772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 593/5680 [3:35:14<31:15:03, 22.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 594/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.25387445092201233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 594/5680 [3:35:35<30:51:12, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 595/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17235928773880005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 595/5680 [3:35:58<31:09:54, 22.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 596/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14008499681949615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 596/5680 [3:36:19<30:54:13, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 597/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.38273540139198303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 597/5680 [3:36:42<31:11:45, 22.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 598/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4614243507385254\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 598/5680 [3:37:03<30:56:20, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 599/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2995842397212982\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 599/5680 [3:37:25<30:58:16, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 600/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.345483660697937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 600/5680 [3:37:47<31:06:09, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 601/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15672072768211365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 601/5680 [3:38:09<30:43:17, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 602/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1379702240228653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 602/5680 [3:38:31<30:59:02, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 603/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5292666554450989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 603/5680 [3:38:52<30:41:21, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 604/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14699000120162964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 604/5680 [3:39:15<30:58:13, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 605/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14908157289028168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 605/5680 [3:39:36<30:42:42, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 606/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16985686123371124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 606/5680 [3:39:59<31:04:06, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 607/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.486299991607666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 607/5680 [3:40:20<30:53:59, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 608/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17256426811218262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 608/5680 [3:40:42<30:54:34, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 609/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13707435131072998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 609/5680 [3:41:04<30:58:13, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 610/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1581580489873886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 610/5680 [3:41:26<30:41:02, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 611/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4257473349571228\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 611/5680 [3:41:48<31:01:42, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 612/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19371607899665833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 612/5680 [3:42:10<30:38:34, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 613/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16549208760261536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 613/5680 [3:42:32<30:56:50, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 614/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15059229731559753\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 614/5680 [3:42:53<30:37:20, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 615/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13292160630226135\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 615/5680 [3:43:16<30:56:56, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 616/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4910249412059784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 616/5680 [3:43:37<30:40:22, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 617/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12822799384593964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 617/5680 [3:44:00<30:54:20, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 618/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22667717933654785\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 618/5680 [3:44:22<31:00:45, 22.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 619/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.715648889541626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 619/5680 [3:44:43<30:39:18, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 620/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13146236538887024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 620/5680 [3:45:06<30:58:03, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 621/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7188636660575867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 621/5680 [3:45:27<30:37:20, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 622/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1392149031162262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 622/5680 [3:45:49<30:52:52, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 623/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3841266334056854\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 623/5680 [3:46:11<30:41:54, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 624/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12415385991334915\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 624/5680 [3:46:33<31:00:24, 22.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 625/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1303173005580902\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 625/5680 [3:46:55<30:43:44, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 626/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12585429847240448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 626/5680 [3:47:17<30:52:35, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 627/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23712512850761414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 627/5680 [3:47:39<30:49:15, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 628/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12574982643127441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 628/5680 [3:48:00<30:37:29, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 629/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14988696575164795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 629/5680 [3:48:23<30:54:09, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 630/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5659611821174622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 630/5680 [3:48:44<30:33:27, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 631/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14982226490974426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 631/5680 [3:49:06<30:46:12, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 632/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14254824817180634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 632/5680 [3:49:28<30:25:07, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 633/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22013694047927856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 633/5680 [3:49:50<30:48:46, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 634/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1423492282629013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 634/5680 [3:50:11<30:30:18, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 635/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3622840940952301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 635/5680 [3:50:34<30:50:18, 22.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 636/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1396675854921341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 636/5680 [3:50:56<30:45:34, 21.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 637/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2155936062335968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 637/5680 [3:51:18<30:37:24, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 638/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17219173908233643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 638/5680 [3:51:40<30:47:05, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 639/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1551673710346222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 639/5680 [3:52:01<30:30:07, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 640/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12336932122707367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 640/5680 [3:52:24<30:49:30, 22.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 641/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12912273406982422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 641/5680 [3:52:45<30:25:29, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 642/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8464815020561218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 642/5680 [3:53:07<30:40:18, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 643/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17829880118370056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 643/5680 [3:53:29<30:28:32, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 644/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12583020329475403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 644/5680 [3:53:51<30:46:46, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 645/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1688726842403412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 645/5680 [3:54:13<30:38:39, 21.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 646/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19668523967266083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 646/5680 [3:54:35<30:41:58, 21.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 647/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19167256355285645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 647/5680 [3:54:57<30:58:23, 22.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 648/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.21629296243190765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 648/5680 [3:55:19<30:33:36, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 649/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16661052405834198\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 649/5680 [3:55:41<30:49:26, 22.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 650/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.24274513125419617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 650/5680 [3:56:03<30:32:53, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 651/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.139885812997818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 651/5680 [3:56:25<30:50:02, 22.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 652/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23638305068016052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 652/5680 [3:56:46<30:30:44, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 653/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12763944268226624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 653/5680 [3:57:09<30:46:19, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 654/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9452928900718689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 654/5680 [3:57:31<30:41:19, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 655/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12202463299036026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 655/5680 [3:57:52<30:32:10, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 656/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1242133378982544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 656/5680 [3:58:15<30:47:53, 22.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 657/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12281782925128937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 657/5680 [3:58:36<30:22:00, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 658/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.160654217004776\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 658/5680 [3:58:58<30:35:49, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 659/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15375278890132904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 659/5680 [3:59:19<30:15:06, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 660/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1669178009033203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 660/5680 [3:59:42<30:31:41, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 661/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1373743712902069\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 661/5680 [4:00:03<30:20:18, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 662/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1435905396938324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 662/5680 [4:00:26<30:39:57, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 663/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7957813739776611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 663/5680 [4:00:47<30:25:46, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 664/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.11658986657857895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 664/5680 [4:01:09<30:31:11, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 665/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12298166006803513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 665/5680 [4:01:31<30:36:21, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 666/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12847240269184113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 666/5680 [4:01:53<30:19:20, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 667/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15182103216648102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 667/5680 [4:02:15<30:36:51, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 668/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23238614201545715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 668/5680 [4:02:36<30:15:57, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 669/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13853004574775696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 669/5680 [4:03:00<31:00:19, 22.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 670/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14247269928455353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 670/5680 [4:03:21<30:29:58, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 671/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13663867115974426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 671/5680 [4:03:43<30:41:16, 22.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 672/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1332777738571167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 672/5680 [4:04:05<30:22:44, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 673/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12366253137588501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 673/5680 [4:04:27<30:41:27, 22.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 674/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12211020290851593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 674/5680 [4:04:49<30:19:47, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 675/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1543760597705841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 675/5680 [4:05:11<30:29:15, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 676/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16122642159461975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 676/5680 [4:05:33<30:28:39, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 677/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.27305346727371216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 677/5680 [4:05:54<30:11:48, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 678/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1317920982837677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 678/5680 [4:06:16<30:27:07, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 679/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1392725110054016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 679/5680 [4:06:37<30:03:54, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 680/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13239696621894836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 680/5680 [4:06:59<30:17:54, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 681/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12608584761619568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 681/5680 [4:07:21<30:05:10, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 682/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12268943339586258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 682/5680 [4:07:43<30:20:35, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 683/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2511084973812103\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 683/5680 [4:08:05<30:09:30, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 684/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13704723119735718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 684/5680 [4:08:27<30:28:20, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 685/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14620497822761536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 685/5680 [4:08:49<30:22:50, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 686/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8352418541908264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 686/5680 [4:09:10<30:08:21, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 687/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9965914487838745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 687/5680 [4:09:33<30:27:27, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 688/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2518707513809204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 688/5680 [4:09:54<30:09:44, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 689/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12357264757156372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 689/5680 [4:10:16<30:28:29, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 690/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18529285490512848\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 690/5680 [4:10:38<30:11:18, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 691/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "# Define paths\n",
        "CHECKPOINT_DIR = \"../checkpoints\"\n",
        "# os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "num_epochs = 100\n",
        "\n",
        "print(f\"Training for only {num_epochs} epochs!\")\n",
        "\n",
        "def main():\n",
        "    train(\n",
        "        data_dir=\"../healthy\",\n",
        "        batch_size=2,\n",
        "        checkpoint_path=None,\n",
        "        lr=1e-4,\n",
        "        num_epochs=num_epochs\n",
        "    )\n",
        "    # inference(os.path.join(CHECKPOINT_DIR, \"ddpm_checkpoint\"))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9jjrVaS0UCm"
      },
      "source": [
        "### Debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FdlH2yWJtlL",
        "outputId": "4c06b0f6-5a2c-4649-87bf-7454751dc5c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Dataset length: 5680\n",
            "[DEBUG] First batch loaded: torch.Size([2, 4, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "# Debug dataset loading\n",
        "train_dataset = BRATSDataset(directory=\"/content/data/healthy\")\n",
        "print(\"[DEBUG] Dataset length:\", len(train_dataset))\n",
        "\n",
        "# Try loading a single batch\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True, num_workers=0)  # Reduce num_workers\n",
        "x = next(iter(train_loader))  # Try fetching one batch\n",
        "x = x.to(device).float()  # Move batch to GPU\n",
        "print(\"[DEBUG] First batch loaded:\", x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyJd5_HD_oI4",
        "outputId": "e33158e8-1c9a-4bd3-e115-1cdfafaa8502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Model initialized successfully.\n"
          ]
        }
      ],
      "source": [
        "scheduler = DDPM_Scheduler(num_time_steps=1000)\n",
        "\n",
        "# Move model to GPU\n",
        "model = UNET(\n",
        "          input_channels=4,\n",
        "          output_channels=4,\n",
        "          Channels=[64, 128, 256, 512, 512, 384]\n",
        "      ).to(device)  # Move model to GPU\n",
        "\n",
        "print(\"[DEBUG] Model initialized successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev3ogbisbvlo",
        "outputId": "4aea0cb4-9ca1-45c1-80f9-8ffcd490b5c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Running model forward pass...\n",
            "[DEBUG] Forward pass successful, output shape: torch.Size([2, 4, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "# Load a batch and move to GPU\n",
        "x = next(iter(train_loader)).to(device).float()\n",
        "t = torch.randint(0, 500, (x.shape[0],)).to(device)\n",
        "\n",
        "print(\"[DEBUG] Running model forward pass...\")\n",
        "# output = model(x, t)  # Forward pass\n",
        "print(\"[DEBUG] Forward pass successful, output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Forward Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forward_process(image, t, scheduler, device):\n",
        "    \"\"\"Applies forward diffusion to an image at time step t.\"\"\"\n",
        "    image = normalize_images(image).to(device)\n",
        "    a = scheduler.alpha[t-1].view(1, 1, 1, 1).to(device)\n",
        "    e = torch.randn_like(image, device=device)  # Sample noise\n",
        "    noisy_image = torch.sqrt(a) * image + torch.sqrt(1 - a) * e\n",
        "    return noisy_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reverse Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reverse_process(x_noisy, start_t, scheduler, model, device):\n",
        "    \"\"\"Performs reverse diffusion (denoising) from a noisy image.\"\"\"\n",
        "    x = x_noisy.clone().to(device)\n",
        "    \n",
        "    # Perform reverse diffusion process\n",
        "    for t in reversed(range(0, start_t)):\n",
        "        t_tensor = torch.tensor([t], device=device)\n",
        "        noise_pred = model(x, t_tensor)\n",
        "\n",
        "        a = scheduler.alpha[t-1].view(1, 1, 1, 1).to(device)\n",
        "        beta_t = scheduler.beta[t-1].view(1, 1, 1, 1).to(device)\n",
        "\n",
        "        # reverse step\n",
        "        x = (x - (beta_t / torch.sqrt(1 - a)) * noise_pred) / torch.sqrt(1 - beta_t)\n",
        "\n",
        "        # Add noise for stochasticity\n",
        "        if t > 0:  \n",
        "            noise = torch.randn_like(x, device=device)\n",
        "            x = x + noise * torch.sqrt(beta_t)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sample and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, scheduler, num_time_steps):\n",
        "    dice_scores, auroc_scores = [], []\n",
        "    all_results = []  # Store results for each data item\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (images, seg_img) in enumerate(tqdm(dataloader, desc=\"Evaluating\")):\n",
        "            try:\n",
        "                images = images.to(device)\n",
        "                \n",
        "                # Ensure segmentation ground truth is binary\n",
        "                seg_img = seg_img.to(device)\n",
        "                \n",
        "                # Apply Otsu's thresholding to seg_img if it's not already binary\n",
        "                if not ((seg_img == 0) | (seg_img == 1)).all():\n",
        "                    seg_img = apply_otsu_thresholding(seg_img)\n",
        "                \n",
        "                # Forward diffusion\n",
        "                noisy_images = forward_process(images, t=num_time_steps, scheduler=scheduler, device=device)\n",
        "                \n",
        "                # Reverse diffusion (denoising)\n",
        "                output = reverse_process(noisy_images, start_t=num_time_steps, scheduler=scheduler, model=model, device=device)\n",
        "\n",
        "                # Compute Difference: |Input - Output|\n",
        "                diff = torch.abs(images - output).mean(dim=1, keepdim=True)  # Convert to single-channel\n",
        "                \n",
        "                # Apply Otsu's thresholding for binarization\n",
        "                diff_binary = apply_otsu_thresholding(diff)\n",
        "\n",
        "                # Compute Dice score\n",
        "                dice = dice_score(diff_binary, seg_img).item()\n",
        "                \n",
        "                # For AUROC, prepare the data carefully\n",
        "                y_true = seg_img.cpu().numpy().flatten()\n",
        "                y_score = diff.cpu().numpy().flatten()\n",
        "                \n",
        "                # Calculate AUROC score\n",
        "                # Handle binary classification correctly\n",
        "                try:\n",
        "                    auroc = roc_auc_score(y_true, y_score)\n",
        "                except ValueError:\n",
        "                    # Check if we have both positive and negative samples\n",
        "                    unique_values = np.unique(y_true)\n",
        "                    if len(unique_values) <= 1:\n",
        "                        # All samples are the same class\n",
        "                        auroc = 1.0 if y_true[0] == 1 else 0.0\n",
        "                    else:\n",
        "                        # Try with ovr mode as fallback\n",
        "                        auroc = roc_auc_score(y_true, y_score, multi_class='ovr')\n",
        "\n",
        "                # Save individual result\n",
        "                all_results.append({\n",
        "                    \"sample_idx\": idx,\n",
        "                    \"dice\": dice,\n",
        "                    \"auroc\": auroc\n",
        "                })\n",
        "                \n",
        "                dice_scores.append(dice)\n",
        "                auroc_scores.append(auroc)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing batch {idx}: {e}\")\n",
        "                # Continue with next batch instead of failing the entire evaluation\n",
        "                continue\n",
        "\n",
        "    if not dice_scores:\n",
        "        return 0.0, 0.0, []  # Return default values if all batches failed\n",
        "        \n",
        "    return np.mean(dice_scores), np.mean(auroc_scores), all_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validate Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "model = UNET(\n",
        "    output_channels=4,\n",
        "    input_channels=4,\n",
        "    Channels=[64, 128, 256, 512, 512, 384],\n",
        "    time_steps=500\n",
        ").to(device)\n",
        "\n",
        "def test_checkpoints(val_data_path, checkpoint_dir, batch_numbers, scheduler, num_time_steps):\n",
        "    val_dataset = BRATSDataset(directory=val_data_path, test_flag=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "    \n",
        "    log_file = open(\"checkpoint_scores.log\", \"w\")\n",
        "    detailed_log_file = open(\"detailed_checkpoint_scores.log\", \"w\")\n",
        "    best_checkpoint, best_dice = None, 0\n",
        "\n",
        "    try:\n",
        "        for batch_number in batch_numbers:\n",
        "            for checkpoint in sorted(os.listdir(checkpoint_dir)):\n",
        "                if f\"batch_{batch_number}\" in checkpoint:\n",
        "                    print(f\"\\nTesting {checkpoint}\")\n",
        "\n",
        "                    checkpoint_path = os.path.join(checkpoint_dir, checkpoint)\n",
        "                    checkpoint_data = torch.load(checkpoint_path, map_location=device)\n",
        "                    model.load_state_dict(checkpoint_data[\"weights\"])\n",
        "                    model.eval()\n",
        "\n",
        "                    avg_dice, avg_auroc, all_results = evaluate(model, val_loader, scheduler, num_time_steps=num_time_steps)\n",
        "\n",
        "                    # Log summary stats\n",
        "                    log_entry = f\"Checkpoint: {checkpoint} | Dice: {avg_dice:.4f} | AUROC: {avg_auroc:.4f}\\n\"\n",
        "                    print(log_entry)\n",
        "                    log_file.write(log_entry)\n",
        "                    \n",
        "                    # Log detailed results\n",
        "                    detailed_log_file.write(f\"\\n========== Checkpoint: {checkpoint} ==========\\n\")\n",
        "                    detailed_log_file.write(\"Sample_idx, Dice, AUROC\\n\")\n",
        "                    for result in all_results:\n",
        "                        detailed_log_file.write(f\"{result['sample_idx']}, {result['dice']:.4f}, {result['auroc']:.4f}\\n\")\n",
        "                    detailed_log_file.write(f\"AVERAGE, {avg_dice:.4f}, {avg_auroc:.4f}\\n\")\n",
        "                    detailed_log_file.write(\"=========================================\\n\")\n",
        "\n",
        "                    if avg_dice > best_dice:\n",
        "                        best_dice = avg_dice\n",
        "                        best_checkpoint = checkpoint\n",
        "\n",
        "                    torch.cuda.empty_cache()\n",
        "    finally:\n",
        "        log_file.close()\n",
        "        detailed_log_file.close()\n",
        "        print(f\"\\nBest Checkpoint: {best_checkpoint} with Dice: {best_dice:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] Using 100 time steps.\n",
            "\n",
            "Testing brats_ddpm_checkpoint_epoch_1_batch_5.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 1/1 [18:58<00:00, 1138.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint: brats_ddpm_checkpoint_epoch_1_batch_5.pth | Dice: 0.0526 | AUROC: 0.4530\n",
            "\n",
            "\n",
            "Best Checkpoint: brats_ddpm_checkpoint_epoch_1_batch_5.pth with Dice: 0.0526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "num_time_steps = 100\n",
        "val_data_path = \"val-test/val\"\n",
        "checkpoint_dir = \"checkpoints\"\n",
        "scheduler = DDPM_Scheduler(num_time_steps=num_time_steps).to(device)\n",
        "batch_numbers = [5]\n",
        "test_checkpoints(val_data_path, checkpoint_dir, batch_numbers, scheduler, num_time_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_nii(nii_path, slice_idx=None):\n",
        "    \"\"\"\n",
        "    Plots a given slice of a single-channel NIfTI (.nii or .nii.gz) image.\n",
        "\n",
        "    Args:\n",
        "        nii_path (str): Path to the .nii or .nii.gz file.\n",
        "        slice_idx (int, optional): Index of the slice to display. Defaults to the middle slice.\n",
        "    \"\"\"\n",
        "    nii_img = nib.load(nii_path)\n",
        "    img_data = nii_img.get_fdata()  # Convert to numpy array\n",
        "\n",
        "    # Get slice index\n",
        "    if slice_idx is None:\n",
        "        slice_idx = img_data.shape[-1] // 2  # Use last axis for slicing\n",
        "\n",
        "    # Plot the selected slice\n",
        "    plt.imshow(img_data[:, :], cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Slice {slice_idx}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_nii(\"val-test/val/000077/BraTS20_Training_321_t1_107.nii\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "gJzfe3HOz4KD",
        "_9ORVCc1z7DR",
        "VGXiQiWnz_Po",
        "SxpENE6MJtlI",
        "zQFnsdN9JtlJ",
        "NIMWqvt-JtlJ",
        "kfFBhAhgJtlK",
        "r8fn_3uy0Ffv",
        "bViuRDbY0PFk",
        "-eroMMFH0R9c"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30887,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "fyp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
