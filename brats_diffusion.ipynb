{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wandb connect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/siddesh/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs21b2019\u001b[0m (\u001b[33mcs21b2019-iiitdm-kancheepuram\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.init(project=\"brats-diffusion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJzfe3HOz4KD"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.339659Z",
          "iopub.status.busy": "2025-02-09T13:57:43.339310Z",
          "iopub.status.idle": "2025-02-09T13:57:43.344047Z",
          "shell.execute_reply": "2025-02-09T13:57:43.343161Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.339611Z"
        },
        "id": "8C2-H7ExJtlG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange #pip install einops\n",
        "from typing import List\n",
        "import random\n",
        "import math\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from timm.utils import ModelEmaV3 #pip install timm\n",
        "from tqdm import tqdm #pip install tqdm\n",
        "import matplotlib.pyplot as plt #pip install matplotlib\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from skimage.filters import threshold_otsu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_log(message):\n",
        "    print(f\"[Log] {message}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Normalize images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_images(images):\n",
        "    return (images - 0.5) / 0.5\n",
        "\n",
        "# def normalize_images(images): # Normalize images to [-1, 1] using min-max scaling\n",
        "#     min_val = images.min()\n",
        "#     max_val = images.max()\n",
        "#     return 2 * (images - min_val) / (max_val - min_val) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_image(image):\n",
        "    min_val = image.min()\n",
        "    max_val = image.max()\n",
        "    normalize_image = (image - min_val) / (max_val - min_val)\n",
        "    return normalize_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print_log(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_checkpoint(model, optimizer, ema, filename, folder='../checkpoints'):\n",
        "    checkpoint_path = os.path.join(folder, filename)\n",
        "\n",
        "    checkpoint = {\n",
        "        'weights': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'ema': ema.state_dict()\n",
        "    }\n",
        "\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    print(f\"[INFO] Checkpoint saved at: {checkpoint_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Dice Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dice_score(pred, target, eps=1e-6):\n",
        "    \"\"\"Compute Dice score between a single prediction and target.\"\"\"\n",
        "    # Ensure both are tensors\n",
        "    pred = torch.as_tensor(pred, dtype=torch.float32)\n",
        "    target = torch.as_tensor(target, dtype=torch.float32)\n",
        "\n",
        "    intersection = (pred * target).sum()\n",
        "    union = pred.sum() + target.sum()\n",
        "    \n",
        "    dice = (2. * intersection + eps) / (union + eps)\n",
        "    \n",
        "    return dice.item()  # Ensure a scalar is returned\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### OTSU's Thresholding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_otsu_thresholding(image):\n",
        "    # Convert image to numpy array if it's not already\n",
        "    image = np.asarray(image)\n",
        "\n",
        "    # Compute Otsu's threshold\n",
        "    thresh = threshold_otsu(image)\n",
        "\n",
        "    # Apply thresholding\n",
        "    binary_image = (image > thresh).astype(np.uint8)\n",
        "\n",
        "    return binary_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLtAHV-arapv"
      },
      "source": [
        "### Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "eQKp1NCQrdfS"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=1e-4, model_path=\"best_model.pth\"):\n",
        "        self.patience = patience\n",
        "        self.delta = delta  # Minimum improvement threshold\n",
        "        self.best_score = None\n",
        "        self.counter = 0\n",
        "        self.model_path = model_path  # Save the best model\n",
        "\n",
        "    def step(self, val_loss, model):\n",
        "        if self.best_score is None:\n",
        "            self.best_score = val_loss\n",
        "            self.save_checkpoint(model)\n",
        "            return False\n",
        "\n",
        "        elif val_loss < self.best_score - self.delta:  # Require significant improvement\n",
        "            self.best_score = val_loss\n",
        "            self.counter = 0\n",
        "            self.save_checkpoint(model)  # Save best model\n",
        "            return False\n",
        "\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                print(\"Early Stopping Triggered.\")\n",
        "                return True  # Stop training\n",
        "            return False\n",
        "\n",
        "    def save_checkpoint(self, model):\n",
        "        \"\"\"Save the model when validation loss improves.\"\"\"\n",
        "        torch.save(model.state_dict(), self.model_path)\n",
        "        print(f\"Model saved with val_loss: {self.best_score:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in_gaQkXZVty"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9ORVCc1z7DR"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "-ZgT72xcWtRP"
      },
      "outputs": [],
      "source": [
        "class BRATSDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, directory, test_flag=False, resize=False):\n",
        "        super().__init__()\n",
        "        self.directory = os.path.expanduser(directory)\n",
        "        self.test_flag = test_flag\n",
        "        self.seqtypes = ['t1', 't1ce', 't2', 'flair']\n",
        "        self.seqtypes_set = set(self.seqtypes)\n",
        "        self.resize = resize\n",
        "        self.database = []\n",
        "\n",
        "        for root, dirs, files in os.walk(self.directory):\n",
        "            if not dirs:  # Leaf directory\n",
        "                datapoint = {}\n",
        "                seg_path = None  # For segmentation mask\n",
        "                \n",
        "                for f in sorted(files):\n",
        "                    parts = f.split('_')\n",
        "                    seqtype = parts[3] if len(parts) > 3 else None\n",
        "                    \n",
        "                    if seqtype in self.seqtypes_set:\n",
        "                        datapoint[seqtype] = os.path.join(root, f)\n",
        "                    elif 'seg' in f.lower():  # Identify segmentation file\n",
        "                        seg_path = os.path.join(root, f)\n",
        "\n",
        "                if set(datapoint.keys()) == self.seqtypes_set and (not self.test_flag or seg_path):\n",
        "                    datapoint['seg'] = seg_path  # Add segmentation path if test_flag=True\n",
        "                    self.database.append(datapoint)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filedict = self.database[index]\n",
        "        images = []\n",
        "\n",
        "        for seqtype in self.seqtypes:\n",
        "            img = nib.load(filedict[seqtype]).get_fdata()\n",
        "            img = torch.tensor(img, dtype=torch.float32)\n",
        "\n",
        "            if self.resize:\n",
        "                img = F.interpolate(img.unsqueeze(0).unsqueeze(0), size=(128, 128), mode=\"bilinear\", align_corners=False)\n",
        "                img = img.squeeze()\n",
        "\n",
        "            images.append(img)\n",
        "\n",
        "        images = torch.stack(images)  # Shape: (4, H, W)\n",
        "\n",
        "        if self.test_flag:\n",
        "            seg_img = nib.load(filedict['seg']).get_fdata()\n",
        "            seg_img = torch.tensor(seg_img, dtype=torch.float32)\n",
        "\n",
        "            if self.resize:\n",
        "                seg_img = F.interpolate(seg_img.unsqueeze(0).unsqueeze(0), size=(128, 128), mode=\"nearest\")\n",
        "                seg_img = seg_img.squeeze()\n",
        "\n",
        "            return images, seg_img  # Return segmentation image instead of path\n",
        "\n",
        "        return images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.database)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxpENE6MJtlI"
      },
      "source": [
        "### Timestep embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.363668Z",
          "iopub.status.busy": "2025-02-09T13:57:43.363421Z",
          "iopub.status.idle": "2025-02-09T13:57:43.375185Z",
          "shell.execute_reply": "2025-02-09T13:57:43.374373Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.363631Z"
        },
        "id": "P0G2b-ZuJtlJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class SinusoidalEmbeddings(nn.Module):\n",
        "    def __init__(self, time_steps: int, embed_dim: int):\n",
        "        super().__init__()\n",
        "        position = torch.arange(time_steps, dtype=torch.float32).unsqueeze(1)\n",
        "        div = torch.exp(torch.arange(0, embed_dim, 2, dtype=torch.float32) * -(math.log(10000.0) / embed_dim))\n",
        "        embeddings = torch.zeros(time_steps, embed_dim, requires_grad=False)\n",
        "        embeddings[:, 0::2] = torch.sin(position * div)\n",
        "        embeddings[:, 1::2] = torch.cos(position * div)\n",
        "        self.register_buffer('embeddings', embeddings)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        return self.embeddings[t].to(x.device)[:, :, None, None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQFnsdN9JtlJ"
      },
      "source": [
        "### Residual Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.376253Z",
          "iopub.status.busy": "2025-02-09T13:57:43.376071Z",
          "iopub.status.idle": "2025-02-09T13:57:43.383973Z",
          "shell.execute_reply": "2025-02-09T13:57:43.383316Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.376238Z"
        },
        "id": "vlBMnHudJtlJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Residual Blocks\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, C: int, num_groups: int, dropout_prob: float):\n",
        "        super().__init__()\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.gnorm1 = nn.GroupNorm(num_groups=num_groups, num_channels=C)\n",
        "        self.gnorm2 = nn.GroupNorm(num_groups=num_groups, num_channels=C)\n",
        "        self.conv1 = nn.Conv2d(C, C, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(C, C, kernel_size=3, padding=1)\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "\n",
        "    def forward(self, x, embeddings):\n",
        "        x = x + embeddings[:, :x.shape[1], :, :]\n",
        "        r = self.conv1(self.relu(self.gnorm1(x)))\n",
        "        r = self.dropout(r)\n",
        "        r = self.conv2(self.relu(self.gnorm2(r)))\n",
        "        return r + x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIMWqvt-JtlJ"
      },
      "source": [
        "### Self Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.384966Z",
          "iopub.status.busy": "2025-02-09T13:57:43.384740Z",
          "iopub.status.idle": "2025-02-09T13:57:43.396549Z",
          "shell.execute_reply": "2025-02-09T13:57:43.395878Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.384937Z"
        },
        "id": "JlkW322cJtlK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, C: int, num_heads: int, dropout_prob: float):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.proj1 = nn.Linear(C, C * 3)\n",
        "        self.proj2 = nn.Linear(C, C)\n",
        "        self.dropout_prob = dropout_prob\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, w = x.shape[2:]\n",
        "        x = rearrange(x, 'b c h w -> b (h w) c')\n",
        "        x = self.proj1(x)\n",
        "        x = rearrange(x, 'b L (C H K) -> K b H L C', K=3, H=self.num_heads)\n",
        "        q, k, v = x[0], x[1], x[2]\n",
        "        x = F.scaled_dot_product_attention(q, k, v, is_causal=False, dropout_p=self.dropout_prob)\n",
        "        x = rearrange(x, 'b H (h w) C -> b h w (C H)', h=h, w=w)\n",
        "        x = self.proj2(x)\n",
        "        return rearrange(x, 'b h w C -> b C h w')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfFBhAhgJtlK"
      },
      "source": [
        "### UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.397562Z",
          "iopub.status.busy": "2025-02-09T13:57:43.397293Z",
          "iopub.status.idle": "2025-02-09T13:57:43.414334Z",
          "shell.execute_reply": "2025-02-09T13:57:43.413695Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.397533Z"
        },
        "id": "w09_Fld4JtlK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class UnetLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "            upscale: bool,\n",
        "            attention: bool,\n",
        "            num_groups: int,\n",
        "            dropout_prob: float,\n",
        "            num_heads: int,\n",
        "            C: int):\n",
        "        super().__init__()\n",
        "        self.ResBlock1 = ResBlock(C, num_groups, dropout_prob)\n",
        "        self.ResBlock2 = ResBlock(C, num_groups, dropout_prob)\n",
        "        if upscale:\n",
        "            self.conv = nn.ConvTranspose2d(C, C//2, kernel_size=4, stride=2, padding=1)\n",
        "        else:\n",
        "            self.conv = nn.Conv2d(C, C*2, kernel_size=3, stride=2, padding=1)\n",
        "        self.attention_layer = Attention(C, num_heads, dropout_prob) if attention else None\n",
        "\n",
        "    def forward(self, x, embeddings):\n",
        "        x = self.ResBlock1(x, embeddings)\n",
        "        if self.attention_layer:\n",
        "            x = self.attention_layer(x)\n",
        "        x = self.ResBlock2(x, embeddings)\n",
        "        return self.conv(x), x\n",
        "\n",
        "class UNET(nn.Module):\n",
        "    def __init__(self,\n",
        "            Channels: List = [64, 128, 256, 512, 512, 384],\n",
        "            Attentions: List = [False, True, False, False, False, True],\n",
        "            Upscales: List = [False, False, False, True, True, True],\n",
        "            num_groups: int = 32,\n",
        "            dropout_prob: float = 0.1,\n",
        "            num_heads: int = 2,\n",
        "            input_channels: int = 4,\n",
        "            output_channels: int = 4,\n",
        "            time_steps: int = 500):\n",
        "\n",
        "        super().__init__()\n",
        "        self.num_layers = len(Channels)\n",
        "        self.shallow_conv = nn.Conv2d(input_channels, Channels[0], kernel_size=3, padding=1)\n",
        "        self.embeddings = SinusoidalEmbeddings(time_steps=time_steps, embed_dim=max(Channels))\n",
        "\n",
        "        out_channels = (Channels[-1] // 2) + Channels[0]\n",
        "        self.late_conv = nn.Conv2d(out_channels, out_channels // 2, kernel_size=3, padding=1)\n",
        "        self.output_conv = nn.Conv2d(out_channels // 2, output_channels, kernel_size=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Initialize UNet layers\n",
        "        for i in range(self.num_layers):\n",
        "            layer = UnetLayer(\n",
        "                upscale=Upscales[i],\n",
        "                attention=Attentions[i],\n",
        "                num_groups=num_groups,\n",
        "                dropout_prob=dropout_prob,\n",
        "                C=Channels[i],\n",
        "                num_heads=num_heads\n",
        "            )\n",
        "            setattr(self, f'Layer{i+1}', layer)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        x = self.shallow_conv(x)\n",
        "        embeddings = self.embeddings(x, t)\n",
        "        residuals = []\n",
        "\n",
        "        for i in range(self.num_layers // 2):\n",
        "            layer = getattr(self, f'Layer{i+1}')\n",
        "            x, res = layer(x, embeddings)\n",
        "            residuals.append(res)\n",
        "\n",
        "        for i in range(self.num_layers//2, self.num_layers):\n",
        "            layer = getattr(self, f'Layer{i+1}')\n",
        "            x = torch.concat((layer(x, embeddings)[0], residuals[self.num_layers-i-1]), dim=1)\n",
        "        return self.output_conv(self.relu(self.late_conv(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8fn_3uy0Ffv"
      },
      "source": [
        "### Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.415329Z",
          "iopub.status.busy": "2025-02-09T13:57:43.415016Z",
          "iopub.status.idle": "2025-02-09T13:57:43.431272Z",
          "shell.execute_reply": "2025-02-09T13:57:43.430569Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.415298Z"
        },
        "id": "yw96YZOGJtlK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class DDPM_Scheduler(nn.Module):\n",
        "    def __init__(self, num_time_steps=1000):\n",
        "        super().__init__()\n",
        "        print_log(f\"Using {num_time_steps} time steps.\")\n",
        "        self.beta = torch.linspace(1e-4, 0.02, num_time_steps, requires_grad=False)\n",
        "        alpha = 1 - self.beta\n",
        "        self.register_buffer('alpha', torch.cumprod(alpha, dim=0))\n",
        "\n",
        "    def forward(self, t):\n",
        "        return self.alpha[t]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.488594Z",
          "iopub.status.busy": "2025-02-09T13:57:43.488353Z",
          "iopub.status.idle": "2025-02-09T13:57:43.492610Z",
          "shell.execute_reply": "2025-02-09T13:57:43.491863Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.488575Z"
        },
        "id": "SHcGhW6OJtlK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vTKVJJu0KTU"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.494010Z",
          "iopub.status.busy": "2025-02-09T13:57:43.493740Z",
          "iopub.status.idle": "2025-02-09T13:57:43.509529Z",
          "shell.execute_reply": "2025-02-09T13:57:43.508809Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.493991Z"
        },
        "id": "YJaJywOLJtlK",
        "outputId": "cb81f22f-75a7-4d53-eb4c-7bf5ac69c841",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train(batch_size: int=16,\n",
        "          num_time_steps: int=500,\n",
        "          num_epochs: int=15,\n",
        "          seed: int=-1,\n",
        "          ema_decay: float=0.9999,\n",
        "          lr=2e-5,\n",
        "          data_dir: str='/healthy',\n",
        "          checkpoint_path: str=None):\n",
        "\n",
        "    # Set random seed\n",
        "    seed = random.randint(0, 2**32-1) if seed == -1 else seed\n",
        "    print_log(f\"Random seed set to: {seed}\")\n",
        "    set_seed(seed)\n",
        "\n",
        "    # Load dataset\n",
        "    print_log(\"Loading dataset...\")\n",
        "\n",
        "    train_dataset = BRATSDataset(directory=data_dir)\n",
        "    print_log(f\"Dataset length: {len(train_dataset)}\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=16, pin_memory=True)\n",
        "\n",
        "    try:\n",
        "        sample_batch = next(iter(train_loader))\n",
        "        print_log(f\"First batch shape: {sample_batch.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] DataLoader issue: {e}\")\n",
        "        return\n",
        "\n",
        "    _, H, W = sample_batch.shape[1:]\n",
        "\n",
        "    # Initialize model\n",
        "    scheduler = DDPM_Scheduler(num_time_steps=num_time_steps)\n",
        "    model = UNET(\n",
        "        input_channels=4,\n",
        "        output_channels=4,\n",
        "        Channels=[64, 128, 256, 512, 512, 384] if max(H, W) <= 256 else [32, 64, 128, 256, 256, 192]\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    ema = ModelEmaV3(model, decay=ema_decay)\n",
        "\n",
        "    # Load checkpoint\n",
        "    if checkpoint_path is not None and os.path.exists(checkpoint_path):\n",
        "        print_log(\"Loading checkpoint...\")\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
        "        model.load_state_dict(checkpoint['weights'])\n",
        "        ema.load_state_dict(checkpoint['ema'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "    criterion = nn.MSELoss(reduction='mean')\n",
        "    try:\n",
        "        iteration = 0\n",
        "        print_log(f\"Starting training for {num_epochs} epochs...\")\n",
        "\n",
        "        for i in range(num_epochs):\n",
        "            print_log(f\"Starting epoch {i+1}/{num_epochs}...\")\n",
        "            total_loss = 0\n",
        "\n",
        "            for bidx, x in enumerate(tqdm(train_loader, desc=f\"----------------------------------------------------------------\\nEpoch {i+1}/{num_epochs}\\n\")):\n",
        "                print(\"\")\n",
        "                print_log(f\"Processing batch {bidx+1}/{len(train_loader)}...\")\n",
        "\n",
        "                x = x.to(device)\n",
        "                print_log(f\"Batch shape: {x.shape}\")\n",
        "\n",
        "                # Normalize to [-1, 1]\n",
        "                x = normalize_images(x)\n",
        "\n",
        "                # Resize if necessary\n",
        "                if max(H, W) > 256:\n",
        "                    x = F.interpolate(x, size=(256, 256), mode='bilinear', align_corners=False)\n",
        "\n",
        "                t = torch.randint(0, num_time_steps, (x.shape[0],)).to(device)\n",
        "                e = torch.randn_like(x, requires_grad=False).to(device)\n",
        "                a = scheduler.alpha.to(device)[t].view(x.shape[0], 1, 1, 1)\n",
        "\n",
        "                x = (torch.sqrt(a) * x) + (torch.sqrt(1 - a) * e)\n",
        "\n",
        "                # Apply diffusion\n",
        "                output = model(x, t)\n",
        "                optimizer.zero_grad()\n",
        "                loss = criterion(output, e)\n",
        "\n",
        "                wandb.log(\n",
        "                    {\n",
        "                        \"iteration\": iteration,\n",
        "                        \"loss\": loss.item(),\n",
        "                        \"batch\": bidx+1,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                iteration += 1\n",
        "                total_loss += loss.item()\n",
        "                print_log(f\"Loss: {loss.item()}\")\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                ema.update(model)\n",
        "\n",
        "            print_log(f\"Epoch {i+1} | Loss {total_loss / len(train_loader):.5f}\")\n",
        "\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"epoch\": i+1,\n",
        "                    \"loss\": total_loss / len(train_loader),\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # Save checkpoint every 5 epochs\n",
        "            if (i + 1) % 5 == 0:\n",
        "                save_checkpoint(model, optimizer, ema, f'brats_ddpm_checkpoint_epoch_{i+1}.pth')\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n[WARNING] Training interrupted. Saving last checkpoint...\")\n",
        "        save_checkpoint(model, optimizer, ema, 'brats_ddpm_interrupted_checkpoint.pth')\n",
        "\n",
        "    print_log(\"Training complete.\")\n",
        "    save_checkpoint(model, optimizer, ema, 'brats_ddpm_final_checkpoint.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.511395Z",
          "iopub.status.busy": "2025-02-09T13:57:43.511152Z",
          "iopub.status.idle": "2025-02-09T13:57:43.530977Z",
          "shell.execute_reply": "2025-02-09T13:57:43.530192Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.511376Z"
        },
        "id": "gF-N6JqbJtlL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def display_reverse(images: List):\n",
        "    fig, axes = plt.subplots(1, 10, figsize=(10,1))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        x = images[i].squeeze(0)\n",
        "        x = rearrange(x, 'c h w -> h w c')\n",
        "        x = x.numpy()\n",
        "        ax.imshow(x)\n",
        "        ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def inference(checkpoint_path: str=None,\n",
        "              num_time_steps: int=1000,\n",
        "              ema_decay: float=0.9999, ):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model = UNET().cpu()\n",
        "    model.load_state_dict(checkpoint['weights'])\n",
        "    ema = ModelEmaV3(model, decay=ema_decay)\n",
        "    ema.load_state_dict(checkpoint['ema'])\n",
        "    scheduler = DDPM_Scheduler(num_time_steps=num_time_steps)\n",
        "    times = [0,15,50,100,200,300,400,550,700,999]\n",
        "    images = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model = ema.module.eval()\n",
        "        for i in range(10):\n",
        "            z = torch.randn(1, 1, 32, 32)\n",
        "            for t in reversed(range(1, num_time_steps)):\n",
        "                t = [t]\n",
        "                temp = (scheduler.beta[t]/( (torch.sqrt(1-scheduler.alpha[t]))*(torch.sqrt(1-scheduler.beta[t])) ))\n",
        "                z = (1/(torch.sqrt(1-scheduler.beta[t])))*z - (temp*model(z.cpu(),t).cpu())\n",
        "                if t[0] in times:\n",
        "                    images.append(z)\n",
        "                e = torch.randn(1, 1, 32, 32)\n",
        "                z = z + (e*torch.sqrt(scheduler.beta[t]))\n",
        "            temp = scheduler.beta[0]/( (torch.sqrt(1-scheduler.alpha[0]))*(torch.sqrt(1-scheduler.beta[0])) )\n",
        "            x = (1/(torch.sqrt(1-scheduler.beta[0])))*z - (temp*model(z.cpu(),[0]).cpu())\n",
        "\n",
        "            images.append(x)\n",
        "            x = rearrange(x.squeeze(0), 'c h w -> h w c').detach()\n",
        "            x = x.numpy()\n",
        "            plt.imshow(x)\n",
        "            plt.show()\n",
        "            display_reverse(images)\n",
        "            images = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eroMMFH0R9c"
      },
      "source": [
        "### Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.532110Z",
          "iopub.status.busy": "2025-02-09T13:57:43.531840Z",
          "iopub.status.idle": "2025-02-09T13:57:43.967209Z",
          "shell.execute_reply": "2025-02-09T13:57:43.966070Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.532083Z"
        },
        "id": "-YU-_H59JtlL",
        "outputId": "44080e18-26df-4983-e98c-3f439eaa28d9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for only 100 epochs!\n",
            "[Log] Random seed set to: 833225897\n",
            "[Log] Loading dataset...\n",
            "[Log] Dataset length: 0\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# inference(os.path.join(CHECKPOINT_DIR, \"ddpm_checkpoint\"))\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[19], line 9\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../healthy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[17], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(batch_size, num_time_steps, num_epochs, seed, ema_decay, lr, data_dir, checkpoint_path)\u001b[0m\n\u001b[1;32m     18\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m BRATSDataset(directory\u001b[38;5;241m=\u001b[39mdata_dir)\n\u001b[1;32m     19\u001b[0m print_log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     sample_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n",
            "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:383\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 383\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
            "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.11/site-packages/torch/utils/data/sampler.py:165\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ],
      "source": [
        "# Define paths\n",
        "CHECKPOINT_DIR = \"../checkpoints\"\n",
        "# os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "num_epochs = 100\n",
        "\n",
        "print(f\"Training for only {num_epochs} epochs!\")\n",
        "\n",
        "def main():\n",
        "    train(\n",
        "        data_dir=\"../healthy\",\n",
        "        batch_size=2,\n",
        "        checkpoint_path=None,\n",
        "        lr=1e-4,\n",
        "        num_epochs=num_epochs\n",
        "    )\n",
        "    # inference(os.path.join(CHECKPOINT_DIR, \"ddpm_checkpoint\"))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9jjrVaS0UCm"
      },
      "source": [
        "### Debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FdlH2yWJtlL",
        "outputId": "4c06b0f6-5a2c-4649-87bf-7454751dc5c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Dataset length: 5680\n",
            "[DEBUG] First batch loaded: torch.Size([2, 4, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "# Debug dataset loading\n",
        "train_dataset = BRATSDataset(directory=\"/content/data/healthy\")\n",
        "print(\"[DEBUG] Dataset length:\", len(train_dataset))\n",
        "\n",
        "# Try loading a single batch\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True, num_workers=0)  # Reduce num_workers\n",
        "x = next(iter(train_loader))  # Try fetching one batch\n",
        "x = x.to(device).float()  # Move batch to GPU\n",
        "print(\"[DEBUG] First batch loaded:\", x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyJd5_HD_oI4",
        "outputId": "e33158e8-1c9a-4bd3-e115-1cdfafaa8502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Model initialized successfully.\n"
          ]
        }
      ],
      "source": [
        "scheduler = DDPM_Scheduler(num_time_steps=1000)\n",
        "\n",
        "# Move model to GPU\n",
        "model = UNET(\n",
        "          input_channels=4,\n",
        "          output_channels=4,\n",
        "          Channels=[64, 128, 256, 512, 512, 384]\n",
        "      ).to(device)  # Move model to GPU\n",
        "\n",
        "print(\"[DEBUG] Model initialized successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev3ogbisbvlo",
        "outputId": "4aea0cb4-9ca1-45c1-80f9-8ffcd490b5c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Running model forward pass...\n",
            "[DEBUG] Forward pass successful, output shape: torch.Size([2, 4, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "# Load a batch and move to GPU\n",
        "x = next(iter(train_loader)).to(device).float()\n",
        "t = torch.randint(0, 500, (x.shape[0],)).to(device)\n",
        "\n",
        "print(\"[DEBUG] Running model forward pass...\")\n",
        "# output = model(x, t)  # Forward pass\n",
        "print(\"[DEBUG] Forward pass successful, output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Forward Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forward_process(image, t, scheduler, device):\n",
        "    \"\"\"Applies forward diffusion to an image at time step t.\"\"\"\n",
        "    image = normalize_images(image).to(device)\n",
        "    a = scheduler.alpha[t-1].view(1, 1, 1, 1).to(device)\n",
        "    e = torch.randn_like(image, device=device)  # Sample noise\n",
        "    noisy_image = torch.sqrt(a) * image + torch.sqrt(1 - a) * e\n",
        "    return noisy_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reverse Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reverse_process(x_noisy, start_t, scheduler, model, device):\n",
        "    \"\"\"Performs reverse diffusion (denoising) from a noisy image.\"\"\"\n",
        "    x = x_noisy.clone().to(device)\n",
        "    \n",
        "    # Perform reverse diffusion process\n",
        "    for t in range(start_t, 0, -1):\n",
        "        print(f\"Processing time step {t}...\")\n",
        "        t_tensor = torch.tensor([t-1], device=device)\n",
        "        noise_pred = model(x, t_tensor)\n",
        "\n",
        "        a = scheduler.alpha[t-1].view(1, 1, 1, 1).to(device)\n",
        "        beta_t = scheduler.beta[t-1].view(1, 1, 1, 1).to(device)\n",
        "\n",
        "        # reverse step\n",
        "        x = (x - (beta_t / torch.sqrt(1 - a)) * noise_pred) / torch.sqrt(1 - beta_t)\n",
        "\n",
        "        # Add noise for stochasticity\n",
        "        # if t > 0:  \n",
        "        #     noise = torch.randn_like(x, device=device)\n",
        "        #     x = x + noise * torch.sqrt(beta_t)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sample and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def save_image(tensor, path, cmap='gray'):\n",
        "    \"\"\"Save a tensor as an image.\"\"\"\n",
        "    plt.imsave(path, tensor.cpu().numpy(), cmap=cmap)\n",
        "\n",
        "\n",
        "def save_channels(tensor, path_prefix, cmap='gray'):\n",
        "    \"\"\"Save each channel of a multi-channel tensor as a separate image.\"\"\"\n",
        "    try:\n",
        "        tensor = tensor.cpu().numpy()  # Convert to NumPy\n",
        "        num_channels = tensor.shape[0]  # Get the number of channels\n",
        "        \n",
        "        for i in range(num_channels):\n",
        "            plt.imsave(f\"{path_prefix}_channel{i+1}.png\", tensor[i], cmap=cmap)\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving channels: {e}\")\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, scheduler, num_time_steps, output_dir=\"output\"):\n",
        "    dice_scores, auroc_scores = [], []\n",
        "    all_results = []  # Store results for each data item\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (image, ground_truth_seg) in enumerate(tqdm(dataloader, desc=\"Evaluating\")):\n",
        "            try:\n",
        "                image = image.to(device)\n",
        "                ground_truth_seg = ground_truth_seg.squeeze(0).to(device)\n",
        "\n",
        "                # Forward diffusion\n",
        "                noisy_image = forward_process(image=image, t=num_time_steps, scheduler=scheduler, device=device)\n",
        "                \n",
        "                # Reverse diffusion (denoising)\n",
        "                output = reverse_process(x_noisy=noisy_image, start_t=num_time_steps, scheduler=scheduler, model=model, device=device)\n",
        "\n",
        "                save_channels(output, os.path.join(output_dir, f\"model_output_{idx}.png\"))\n",
        "\n",
        "                # Compute anomaly map\n",
        "                image, output = image.squeeze(0), output.squeeze(0)\n",
        "                # print(\"Computing anomaly map...\", image.shape, output.shape)\n",
        "                anomaly_map = torch.abs(visualize_image(image) - visualize_image(output)).sum(dim=0)\n",
        "                # print(\"Anomaly shape:\", anomaly_map.shape)\n",
        "\n",
        "                # Apply Otsu thresholding\n",
        "                binary_mask = apply_otsu_thresholding(anomaly_map)\n",
        "                ground_truth_mask = (ground_truth_seg > 0).float()\n",
        "\n",
        "                # Compute Dice score\n",
        "                # print(\"Computing Dice score...\")\n",
        "                dice = dice_score(binary_mask, ground_truth_mask)\n",
        "\n",
        "                # Flatten anomaly map and ground truth for AUROC calculation\n",
        "                pixel_wise_cls = anomaly_map.flatten().cpu().numpy()\n",
        "                pixel_wise_gt = ground_truth_mask.flatten().cpu().numpy()\n",
        "\n",
        "                # Compute AUROC\n",
        "                # print(\"Computing AUROC...\")\n",
        "                print(pixel_wise_cls.shape, pixel_wise_gt.shape)\n",
        "                auroc = roc_auc_score(pixel_wise_gt, pixel_wise_cls)\n",
        "\n",
        "                # Save images\n",
        "                # print(\"Saving images...\")\n",
        "                # print(\"Ground truth shape:\", ground_truth_seg.shape)\n",
        "                # print(\"Anomaly map shape:\", anomaly_map.shape)\n",
        "                save_image(ground_truth_seg, os.path.join(output_dir, f\"ground_truth_{idx}.png\"), \"gray\")\n",
        "                # save_image(output[0], os.path.join(output_dir, f\"model_output_{idx}.png\"))\n",
        "                save_image(anomaly_map, os.path.join(output_dir, f\"anomaly_map_{idx}.png\"), \"hot\")\n",
        "\n",
        "                # Save individual result\n",
        "                all_results.append({\"sample_idx\": idx, \"dice\": dice, \"auroc\": auroc})\n",
        "                # all_results.append({\"sample_idx\": idx, \"dice\": dice, \"auroc\": 0})\n",
        "                \n",
        "                dice_scores.append(dice)\n",
        "                auroc_scores.append(auroc)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing batch {idx}: {e}\")\n",
        "                continue\n",
        "\n",
        "    if not dice_scores:\n",
        "        print(\"No results found.\")\n",
        "        return 0.0, 0.0, []\n",
        "        \n",
        "    return np.mean(dice_scores), np.mean(auroc_scores), all_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validate Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "model = UNET(\n",
        "    output_channels=4,\n",
        "    input_channels=4,\n",
        "    Channels=[64, 128, 256, 512, 512, 384],\n",
        "    time_steps=500\n",
        ").to(device)\n",
        "\n",
        "def test_checkpoints(val_data_path, checkpoint_dir, batch_numbers, scheduler, num_time_steps):\n",
        "    val_dataset = BRATSDataset(directory=val_data_path, test_flag=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "    \n",
        "    log_file = open(\"checkpoint_scores.log\", \"w\")\n",
        "    detailed_log_file = open(\"detailed_checkpoint_scores.log\", \"w\")\n",
        "    best_checkpoint, best_dice = None, 0\n",
        "\n",
        "    try:\n",
        "        for batch_number in batch_numbers:\n",
        "            for checkpoint in sorted(os.listdir(checkpoint_dir)):\n",
        "                if f\"epoch_{batch_number}\" in checkpoint:\n",
        "                    print(f\"\\nTesting {checkpoint}\")\n",
        "\n",
        "                    checkpoint_path = os.path.join(checkpoint_dir, checkpoint)\n",
        "                    checkpoint_data = torch.load(checkpoint_path, map_location=device)\n",
        "                    model.load_state_dict(checkpoint_data[\"weights\"])\n",
        "                    model.eval()\n",
        "\n",
        "                    avg_dice, avg_auroc, all_results = evaluate(model, val_loader, scheduler, num_time_steps=num_time_steps)\n",
        "\n",
        "                    # Log summary stats\n",
        "                    log_entry = f\"Checkpoint: {checkpoint} | Dice: {avg_dice:.4f} | AUROC: {avg_auroc:.4f}\\n\"\n",
        "                    print(log_entry)\n",
        "                    log_file.write(log_entry)\n",
        "                    \n",
        "                    # Log detailed results\n",
        "                    detailed_log_file.write(f\"\\n========== Checkpoint: {checkpoint} ==========\\n\")\n",
        "                    detailed_log_file.write(\"Sample_idx, Dice, AUROC\\n\")\n",
        "                    for result in all_results:\n",
        "                        detailed_log_file.write(f\"{result['sample_idx']}, {result['dice']:.4f}, {result['auroc']:.4f}\\n\")\n",
        "                    detailed_log_file.write(f\"AVERAGE, {avg_dice:.4f}, {avg_auroc:.4f}\\n\")\n",
        "                    detailed_log_file.write(\"=========================================\\n\")\n",
        "\n",
        "                    if avg_dice > best_dice:\n",
        "                        best_dice = avg_dice\n",
        "                        best_checkpoint = checkpoint\n",
        "\n",
        "                    torch.cuda.empty_cache()\n",
        "    finally:\n",
        "        log_file.close()\n",
        "        detailed_log_file.close()\n",
        "        print(f\"\\nBest Checkpoint: {best_checkpoint} with Dice: {best_dice:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] Using 400 time steps.\n",
            "\n",
            "Testing brats_ddpm_checkpoint_epoch_40.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing time step 400...\n",
            "Processing time step 399...\n",
            "Processing time step 398...\n",
            "Processing time step 397...\n",
            "Processing time step 396...\n",
            "Processing time step 395...\n",
            "Processing time step 394...\n",
            "Processing time step 393...\n",
            "Processing time step 392...\n",
            "Processing time step 391...\n",
            "Processing time step 390...\n",
            "Processing time step 389...\n",
            "Processing time step 388...\n",
            "Processing time step 387...\n",
            "Processing time step 386...\n",
            "Processing time step 385...\n",
            "Processing time step 384...\n",
            "Processing time step 383...\n",
            "Processing time step 382...\n",
            "Processing time step 381...\n",
            "Processing time step 380...\n",
            "Processing time step 379...\n",
            "Processing time step 378...\n",
            "Processing time step 377...\n",
            "Processing time step 376...\n",
            "Processing time step 375...\n",
            "Processing time step 374...\n",
            "Processing time step 373...\n",
            "Processing time step 372...\n",
            "Processing time step 371...\n",
            "Processing time step 370...\n",
            "Processing time step 369...\n",
            "Processing time step 368...\n",
            "Processing time step 367...\n",
            "Processing time step 366...\n",
            "Processing time step 365...\n",
            "Processing time step 364...\n",
            "Processing time step 363...\n",
            "Processing time step 362...\n",
            "Processing time step 361...\n",
            "Processing time step 360...\n",
            "Processing time step 359...\n",
            "Processing time step 358...\n",
            "Processing time step 357...\n",
            "Processing time step 356...\n",
            "Processing time step 355...\n",
            "Processing time step 354...\n",
            "Processing time step 353...\n",
            "Processing time step 352...\n",
            "Processing time step 351...\n",
            "Processing time step 350...\n",
            "Processing time step 349...\n",
            "Processing time step 348...\n",
            "Processing time step 347...\n",
            "Processing time step 346...\n",
            "Processing time step 345...\n",
            "Processing time step 344...\n",
            "Processing time step 343...\n",
            "Processing time step 342...\n",
            "Processing time step 341...\n",
            "Processing time step 340...\n",
            "Processing time step 339...\n",
            "Processing time step 338...\n",
            "Processing time step 337...\n",
            "Processing time step 336...\n",
            "Processing time step 335...\n",
            "Processing time step 334...\n",
            "Processing time step 333...\n",
            "Processing time step 332...\n",
            "Processing time step 331...\n",
            "Processing time step 330...\n",
            "Processing time step 329...\n",
            "Processing time step 328...\n",
            "Processing time step 327...\n",
            "Processing time step 326...\n",
            "Processing time step 325...\n",
            "Processing time step 324...\n",
            "Processing time step 323...\n",
            "Processing time step 322...\n",
            "Processing time step 321...\n",
            "Processing time step 320...\n",
            "Processing time step 319...\n",
            "Processing time step 318...\n",
            "Processing time step 317...\n",
            "Processing time step 316...\n",
            "Processing time step 315...\n",
            "Processing time step 314...\n",
            "Processing time step 313...\n",
            "Processing time step 312...\n",
            "Processing time step 311...\n",
            "Processing time step 310...\n",
            "Processing time step 309...\n",
            "Processing time step 308...\n",
            "Processing time step 307...\n",
            "Processing time step 306...\n",
            "Processing time step 305...\n",
            "Processing time step 304...\n",
            "Processing time step 303...\n",
            "Processing time step 302...\n",
            "Processing time step 301...\n",
            "Processing time step 300...\n",
            "Processing time step 299...\n",
            "Processing time step 298...\n",
            "Processing time step 297...\n",
            "Processing time step 296...\n",
            "Processing time step 295...\n",
            "Processing time step 294...\n",
            "Processing time step 293...\n",
            "Processing time step 292...\n",
            "Processing time step 291...\n",
            "Processing time step 290...\n",
            "Processing time step 289...\n",
            "Processing time step 288...\n",
            "Processing time step 287...\n",
            "Processing time step 286...\n",
            "Processing time step 285...\n",
            "Processing time step 284...\n",
            "Processing time step 283...\n",
            "Processing time step 282...\n",
            "Processing time step 281...\n",
            "Processing time step 280...\n",
            "Processing time step 279...\n",
            "Processing time step 278...\n",
            "Processing time step 277...\n",
            "Processing time step 276...\n",
            "Processing time step 275...\n",
            "Processing time step 274...\n",
            "Processing time step 273...\n",
            "Processing time step 272...\n",
            "Processing time step 271...\n",
            "Processing time step 270...\n",
            "Processing time step 269...\n",
            "Processing time step 268...\n",
            "Processing time step 267...\n",
            "Processing time step 266...\n",
            "Processing time step 265...\n",
            "Processing time step 264...\n",
            "Processing time step 263...\n",
            "Processing time step 262...\n",
            "Processing time step 261...\n",
            "Processing time step 260...\n",
            "Processing time step 259...\n",
            "Processing time step 258...\n",
            "Processing time step 257...\n",
            "Processing time step 256...\n",
            "Processing time step 255...\n",
            "Processing time step 254...\n",
            "Processing time step 253...\n",
            "Processing time step 252...\n",
            "Processing time step 251...\n",
            "Processing time step 250...\n",
            "Processing time step 249...\n",
            "Processing time step 248...\n",
            "Processing time step 247...\n",
            "Processing time step 246...\n",
            "Processing time step 245...\n",
            "Processing time step 244...\n",
            "Processing time step 243...\n",
            "Processing time step 242...\n",
            "Processing time step 241...\n",
            "Processing time step 240...\n",
            "Processing time step 239...\n",
            "Processing time step 238...\n",
            "Processing time step 237...\n",
            "Processing time step 236...\n",
            "Processing time step 235...\n",
            "Processing time step 234...\n",
            "Processing time step 233...\n",
            "Processing time step 232...\n",
            "Processing time step 231...\n",
            "Processing time step 230...\n",
            "Processing time step 229...\n",
            "Processing time step 228...\n",
            "Processing time step 227...\n",
            "Processing time step 226...\n",
            "Processing time step 225...\n",
            "Processing time step 224...\n",
            "Processing time step 223...\n",
            "Processing time step 222...\n",
            "Processing time step 221...\n",
            "Processing time step 220...\n",
            "Processing time step 219...\n",
            "Processing time step 218...\n",
            "Processing time step 217...\n",
            "Processing time step 216...\n",
            "Processing time step 215...\n",
            "Processing time step 214...\n",
            "Processing time step 213...\n",
            "Processing time step 212...\n",
            "Processing time step 211...\n",
            "Processing time step 210...\n",
            "Processing time step 209...\n",
            "Processing time step 208...\n",
            "Processing time step 207...\n",
            "Processing time step 206...\n",
            "Processing time step 205...\n",
            "Processing time step 204...\n",
            "Processing time step 203...\n",
            "Processing time step 202...\n",
            "Processing time step 201...\n",
            "Processing time step 200...\n",
            "Processing time step 199...\n",
            "Processing time step 198...\n",
            "Processing time step 197...\n",
            "Processing time step 196...\n",
            "Processing time step 195...\n",
            "Processing time step 194...\n",
            "Processing time step 193...\n",
            "Processing time step 192...\n",
            "Processing time step 191...\n",
            "Processing time step 190...\n",
            "Processing time step 189...\n",
            "Processing time step 188...\n",
            "Processing time step 187...\n",
            "Processing time step 186...\n",
            "Processing time step 185...\n",
            "Processing time step 184...\n",
            "Processing time step 183...\n",
            "Processing time step 182...\n",
            "Processing time step 181...\n",
            "Processing time step 180...\n",
            "Processing time step 179...\n",
            "Processing time step 178...\n",
            "Processing time step 177...\n",
            "Processing time step 176...\n",
            "Processing time step 175...\n",
            "Processing time step 174...\n",
            "Processing time step 173...\n",
            "Processing time step 172...\n",
            "Processing time step 171...\n",
            "Processing time step 170...\n",
            "Processing time step 169...\n",
            "Processing time step 168...\n",
            "Processing time step 167...\n",
            "Processing time step 166...\n",
            "Processing time step 165...\n",
            "Processing time step 164...\n",
            "Processing time step 163...\n",
            "Processing time step 162...\n",
            "Processing time step 161...\n",
            "Processing time step 160...\n",
            "Processing time step 159...\n",
            "Processing time step 158...\n",
            "Processing time step 157...\n",
            "Processing time step 156...\n",
            "Processing time step 155...\n",
            "Processing time step 154...\n",
            "Processing time step 153...\n",
            "Processing time step 152...\n",
            "Processing time step 151...\n",
            "Processing time step 150...\n",
            "Processing time step 149...\n",
            "Processing time step 148...\n",
            "Processing time step 147...\n",
            "Processing time step 146...\n",
            "Processing time step 145...\n",
            "Processing time step 144...\n",
            "Processing time step 143...\n",
            "Processing time step 142...\n",
            "Processing time step 141...\n",
            "Processing time step 140...\n",
            "Processing time step 139...\n",
            "Processing time step 138...\n",
            "Processing time step 137...\n",
            "Processing time step 136...\n",
            "Processing time step 135...\n",
            "Processing time step 134...\n",
            "Processing time step 133...\n",
            "Processing time step 132...\n",
            "Processing time step 131...\n",
            "Processing time step 130...\n",
            "Processing time step 129...\n",
            "Processing time step 128...\n",
            "Processing time step 127...\n",
            "Processing time step 126...\n",
            "Processing time step 125...\n",
            "Processing time step 124...\n",
            "Processing time step 123...\n",
            "Processing time step 122...\n",
            "Processing time step 121...\n",
            "Processing time step 120...\n",
            "Processing time step 119...\n",
            "Processing time step 118...\n",
            "Processing time step 117...\n",
            "Processing time step 116...\n",
            "Processing time step 115...\n",
            "Processing time step 114...\n",
            "Processing time step 113...\n",
            "Processing time step 112...\n",
            "Processing time step 111...\n",
            "Processing time step 110...\n",
            "Processing time step 109...\n",
            "Processing time step 108...\n",
            "Processing time step 107...\n",
            "Processing time step 106...\n",
            "Processing time step 105...\n",
            "Processing time step 104...\n",
            "Processing time step 103...\n",
            "Processing time step 102...\n",
            "Processing time step 101...\n",
            "Processing time step 100...\n",
            "Processing time step 99...\n",
            "Processing time step 98...\n",
            "Processing time step 97...\n",
            "Processing time step 96...\n",
            "Processing time step 95...\n",
            "Processing time step 94...\n",
            "Processing time step 93...\n",
            "Processing time step 92...\n",
            "Processing time step 91...\n",
            "Processing time step 90...\n",
            "Processing time step 89...\n",
            "Processing time step 88...\n",
            "Processing time step 87...\n",
            "Processing time step 86...\n",
            "Processing time step 85...\n",
            "Processing time step 84...\n",
            "Processing time step 83...\n",
            "Processing time step 82...\n",
            "Processing time step 81...\n",
            "Processing time step 80...\n",
            "Processing time step 79...\n",
            "Processing time step 78...\n",
            "Processing time step 77...\n",
            "Processing time step 76...\n",
            "Processing time step 75...\n",
            "Processing time step 74...\n",
            "Processing time step 73...\n",
            "Processing time step 72...\n",
            "Processing time step 71...\n",
            "Processing time step 70...\n",
            "Processing time step 69...\n",
            "Processing time step 68...\n",
            "Processing time step 67...\n",
            "Processing time step 66...\n",
            "Processing time step 65...\n",
            "Processing time step 64...\n",
            "Processing time step 63...\n",
            "Processing time step 62...\n",
            "Processing time step 61...\n",
            "Processing time step 60...\n",
            "Processing time step 59...\n",
            "Processing time step 58...\n",
            "Processing time step 57...\n",
            "Processing time step 56...\n",
            "Processing time step 55...\n",
            "Processing time step 54...\n",
            "Processing time step 53...\n",
            "Processing time step 52...\n",
            "Processing time step 51...\n",
            "Processing time step 50...\n",
            "Processing time step 49...\n",
            "Processing time step 48...\n",
            "Processing time step 47...\n",
            "Processing time step 46...\n",
            "Processing time step 45...\n",
            "Processing time step 44...\n",
            "Processing time step 43...\n",
            "Processing time step 42...\n",
            "Processing time step 41...\n",
            "Processing time step 40...\n",
            "Processing time step 39...\n",
            "Processing time step 38...\n",
            "Processing time step 37...\n",
            "Processing time step 36...\n",
            "Processing time step 35...\n",
            "Processing time step 34...\n",
            "Processing time step 33...\n",
            "Processing time step 32...\n",
            "Processing time step 31...\n",
            "Processing time step 30...\n",
            "Processing time step 29...\n",
            "Processing time step 28...\n",
            "Processing time step 27...\n",
            "Processing time step 26...\n",
            "Processing time step 25...\n",
            "Processing time step 24...\n",
            "Processing time step 23...\n",
            "Processing time step 22...\n",
            "Processing time step 21...\n",
            "Processing time step 20...\n",
            "Processing time step 19...\n",
            "Processing time step 18...\n",
            "Processing time step 17...\n",
            "Processing time step 16...\n",
            "Processing time step 15...\n",
            "Processing time step 14...\n",
            "Processing time step 13...\n",
            "Processing time step 12...\n",
            "Processing time step 11...\n",
            "Processing time step 10...\n",
            "Processing time step 9...\n",
            "Processing time step 8...\n",
            "Processing time step 7...\n",
            "Processing time step 6...\n",
            "Processing time step 5...\n",
            "Processing time step 4...\n",
            "Processing time step 3...\n",
            "Processing time step 2...\n",
            "Processing time step 1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 1/1 [1:24:27<00:00, 5067.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error saving channels: Third dimension must be 3 or 4\n",
            "(57600,) (57600,)\n",
            "Checkpoint: brats_ddpm_checkpoint_epoch_40.pth | Dice: 0.4284 | AUROC: 0.9082\n",
            "\n",
            "\n",
            "Best Checkpoint: brats_ddpm_checkpoint_epoch_40.pth with Dice: 0.4284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "num_time_steps = 400\n",
        "val_data_path = \"val-test/val\"\n",
        "checkpoint_dir = \"checkpoints\"\n",
        "scheduler = DDPM_Scheduler(num_time_steps=num_time_steps).to(device)\n",
        "batch_numbers = [40]\n",
        "test_checkpoints(val_data_path, checkpoint_dir, batch_numbers, scheduler, num_time_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_nii(nii_path, slice_idx=None):\n",
        "    \"\"\"\n",
        "    Plots a given slice of a single-channel NIfTI (.nii or .nii.gz) image.\n",
        "\n",
        "    Args:\n",
        "        nii_path (str): Path to the .nii or .nii.gz file.\n",
        "        slice_idx (int, optional): Index of the slice to display. Defaults to the middle slice.\n",
        "    \"\"\"\n",
        "    nii_img = nib.load(nii_path)\n",
        "    img_data = nii_img.get_fdata()  # Convert to numpy array\n",
        "\n",
        "    # Get slice index\n",
        "    if slice_idx is None:\n",
        "        slice_idx = img_data.shape[-1] // 2  # Use last axis for slicing\n",
        "\n",
        "    # Plot the selected slice\n",
        "    plt.imshow(img_data[:, :], cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Slice {slice_idx}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_nii(\"val-test/val/000077/BraTS20_Training_321_t2_107.nii\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "gJzfe3HOz4KD",
        "_9ORVCc1z7DR",
        "VGXiQiWnz_Po",
        "SxpENE6MJtlI",
        "zQFnsdN9JtlJ",
        "NIMWqvt-JtlJ",
        "kfFBhAhgJtlK",
        "r8fn_3uy0Ffv",
        "bViuRDbY0PFk",
        "-eroMMFH0R9c"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30887,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "fyp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
