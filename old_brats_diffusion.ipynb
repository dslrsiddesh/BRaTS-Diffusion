{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wandb connect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/siddesh/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs21b2019\u001b[0m (\u001b[33mcs21b2019-iiitdm-kancheepuram\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.init(project=\"refined-brats-diffusion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJzfe3HOz4KD"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.339659Z",
          "iopub.status.busy": "2025-02-09T13:57:43.339310Z",
          "iopub.status.idle": "2025-02-09T13:57:43.344047Z",
          "shell.execute_reply": "2025-02-09T13:57:43.343161Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.339611Z"
        },
        "id": "8C2-H7ExJtlG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange #pip install einops\n",
        "from typing import List\n",
        "import random\n",
        "import math\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from timm.utils import ModelEmaV3 #pip install timm\n",
        "from tqdm import tqdm #pip install tqdm\n",
        "import matplotlib.pyplot as plt #pip install matplotlib\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from skimage.filters import threshold_otsu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_log(message):\n",
        "    print(f\"[Log] {message}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Normalize images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_images(images):\n",
        "    min_val = images.min()\n",
        "    max_val = images.max()\n",
        "    \n",
        "    if max_val == min_val:\n",
        "        return torch.zeros_like(images)\n",
        "\n",
        "    images = 2 * (images - min_val) / (max_val - min_val) - 1\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print_log(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_checkpoint(model, optimizer, ema, filename, folder='../checkpoints'):\n",
        "    checkpoint_path = os.path.join(folder, filename)\n",
        "\n",
        "    checkpoint = {\n",
        "        'weights': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'ema': ema.state_dict()\n",
        "    }\n",
        "\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    print(f\"[INFO] Checkpoint saved at: {checkpoint_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Dice Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dice_score(pred, target, eps=1e-6):\n",
        "    \"\"\"Compute Dice score between a single prediction and target.\"\"\"\n",
        "    intersection = (pred * target).sum()\n",
        "    union = pred.sum() + target.sum()\n",
        "    \n",
        "    dice = (2. * intersection + eps) / (union + eps)\n",
        "    \n",
        "    return dice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### OTSU's Thresholding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_otsu_thresholding(image):\n",
        "    image = np.asarray(image)\n",
        "\n",
        "    thresh = threshold_otsu(image)\n",
        "    binary_image = (image > thresh).astype(np.uint8)\n",
        "\n",
        "    return binary_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLtAHV-arapv"
      },
      "source": [
        "### Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "eQKp1NCQrdfS"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=1e-4, model_path=\"best_model.pth\"):\n",
        "        self.patience = patience\n",
        "        self.delta = delta  # Minimum improvement threshold\n",
        "        self.best_score = None\n",
        "        self.counter = 0\n",
        "        self.model_path = model_path  # Save the best model\n",
        "\n",
        "    def step(self, val_loss, model):\n",
        "        if self.best_score is None:\n",
        "            self.best_score = val_loss\n",
        "            self.save_checkpoint(model)\n",
        "            return False\n",
        "\n",
        "        elif val_loss < self.best_score - self.delta:  # Require significant improvement\n",
        "            self.best_score = val_loss\n",
        "            self.counter = 0\n",
        "            self.save_checkpoint(model)  # Save best model\n",
        "            return False\n",
        "\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                print(\"Early Stopping Triggered.\")\n",
        "                return True  # Stop training\n",
        "            return False\n",
        "\n",
        "    def save_checkpoint(self, model):\n",
        "        \"\"\"Save the model when validation loss improves.\"\"\"\n",
        "        torch.save(model.state_dict(), self.model_path)\n",
        "        print(f\"Model saved with val_loss: {self.best_score:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in_gaQkXZVty"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9ORVCc1z7DR"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZgT72xcWtRP"
      },
      "outputs": [],
      "source": [
        "class BRATSDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, directory, test_flag=False, resize=False):\n",
        "        super().__init__()\n",
        "        self.directory = os.path.expanduser(directory)\n",
        "        self.test_flag = test_flag\n",
        "        self.seqtypes = ['t1', 't1ce', 't2', 'flair']\n",
        "        self.seqtypes_set = set(self.seqtypes)\n",
        "        self.resize = resize\n",
        "        self.database = []\n",
        "\n",
        "        for root, dirs, files in os.walk(self.directory):\n",
        "            if not dirs:  # Leaf directory\n",
        "                datapoint = {}\n",
        "                seg_path = None  # For segmentation mask\n",
        "                \n",
        "                for f in sorted(files):\n",
        "                    parts = f.split('_')\n",
        "                    seqtype = parts[3] if len(parts) > 3 else None\n",
        "                    \n",
        "                    if seqtype in self.seqtypes_set:\n",
        "                        datapoint[seqtype] = os.path.join(root, f)\n",
        "                    elif 'seg' in f.lower():  # Identify segmentation file\n",
        "                        seg_path = os.path.join(root, f)\n",
        "\n",
        "                if set(datapoint.keys()) == self.seqtypes_set and (not self.test_flag or seg_path):\n",
        "                    datapoint['seg'] = seg_path  # Add segmentation path if test_flag=True\n",
        "                    self.database.append(datapoint)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filedict = self.database[index]\n",
        "        images = []\n",
        "\n",
        "        for seqtype in self.seqtypes:\n",
        "            img = nib.load(filedict[seqtype]).get_fdata()\n",
        "            img = torch.tensor(img, dtype=torch.float32)\n",
        "\n",
        "            if self.resize:\n",
        "                img = F.interpolate(img.unsqueeze(0).unsqueeze(0), size=(128, 128), mode=\"bilinear\", align_corners=False)\n",
        "                img = img.squeeze()\n",
        "\n",
        "            images.append(img)\n",
        "\n",
        "        images = torch.stack(images)  # Shape: (4, H, W)\n",
        "\n",
        "        if self.test_flag:\n",
        "            seg_img = nib.load(filedict['seg']).get_fdata()\n",
        "            seg_img = torch.tensor(seg_img, dtype=torch.float32)\n",
        "\n",
        "            if self.resize:\n",
        "                seg_img = F.interpolate(seg_img.unsqueeze(0).unsqueeze(0), size=(128, 128), mode=\"nearest\")\n",
        "                seg_img = seg_img.squeeze()\n",
        "\n",
        "            return images, seg_img\n",
        "\n",
        "        return images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.database)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxpENE6MJtlI"
      },
      "source": [
        "### Timestep embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.363668Z",
          "iopub.status.busy": "2025-02-09T13:57:43.363421Z",
          "iopub.status.idle": "2025-02-09T13:57:43.375185Z",
          "shell.execute_reply": "2025-02-09T13:57:43.374373Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.363631Z"
        },
        "id": "P0G2b-ZuJtlJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class SinusoidalEmbeddings(nn.Module):\n",
        "    def __init__(self, time_steps: int, embed_dim: int):\n",
        "        super().__init__()\n",
        "        position = torch.arange(time_steps, dtype=torch.float32).unsqueeze(1)\n",
        "        div = torch.exp(torch.arange(0, embed_dim, 2, dtype=torch.float32) * -(math.log(10000.0) / embed_dim))\n",
        "        embeddings = torch.zeros(time_steps, embed_dim, requires_grad=False)\n",
        "        embeddings[:, 0::2] = torch.sin(position * div)\n",
        "        embeddings[:, 1::2] = torch.cos(position * div)\n",
        "        self.register_buffer('embeddings', embeddings)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        return self.embeddings[t].to(x.device)[:, :, None, None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQFnsdN9JtlJ"
      },
      "source": [
        "### Residual Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.376253Z",
          "iopub.status.busy": "2025-02-09T13:57:43.376071Z",
          "iopub.status.idle": "2025-02-09T13:57:43.383973Z",
          "shell.execute_reply": "2025-02-09T13:57:43.383316Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.376238Z"
        },
        "id": "vlBMnHudJtlJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Residual Blocks\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, C: int, num_groups: int, dropout_prob: float):\n",
        "        super().__init__()\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.gnorm1 = nn.GroupNorm(num_groups=num_groups, num_channels=C)\n",
        "        self.gnorm2 = nn.GroupNorm(num_groups=num_groups, num_channels=C)\n",
        "        self.conv1 = nn.Conv2d(C, C, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(C, C, kernel_size=3, padding=1)\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "\n",
        "    def forward(self, x, embeddings):\n",
        "        x = x + embeddings[:, :x.shape[1], :, :]\n",
        "        r = self.conv1(self.relu(self.gnorm1(x)))\n",
        "        r = self.dropout(r)\n",
        "        r = self.conv2(self.relu(self.gnorm2(r)))\n",
        "        return r + x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIMWqvt-JtlJ"
      },
      "source": [
        "### Self Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.384966Z",
          "iopub.status.busy": "2025-02-09T13:57:43.384740Z",
          "iopub.status.idle": "2025-02-09T13:57:43.396549Z",
          "shell.execute_reply": "2025-02-09T13:57:43.395878Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.384937Z"
        },
        "id": "JlkW322cJtlK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, C: int, num_heads: int, dropout_prob: float):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.proj1 = nn.Linear(C, C * 3)\n",
        "        self.proj2 = nn.Linear(C, C)\n",
        "        self.dropout_prob = dropout_prob\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, w = x.shape[2:]\n",
        "        x = rearrange(x, 'b c h w -> b (h w) c')\n",
        "        x = self.proj1(x)\n",
        "        x = rearrange(x, 'b L (C H K) -> K b H L C', K=3, H=self.num_heads)\n",
        "        q, k, v = x[0], x[1], x[2]\n",
        "        x = F.scaled_dot_product_attention(q, k, v, is_causal=False, dropout_p=self.dropout_prob)\n",
        "        x = rearrange(x, 'b H (h w) C -> b h w (C H)', h=h, w=w)\n",
        "        x = self.proj2(x)\n",
        "        return rearrange(x, 'b h w C -> b C h w')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfFBhAhgJtlK"
      },
      "source": [
        "### UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.397562Z",
          "iopub.status.busy": "2025-02-09T13:57:43.397293Z",
          "iopub.status.idle": "2025-02-09T13:57:43.414334Z",
          "shell.execute_reply": "2025-02-09T13:57:43.413695Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.397533Z"
        },
        "id": "w09_Fld4JtlK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class UnetLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "            upscale: bool,\n",
        "            attention: bool,\n",
        "            num_groups: int,\n",
        "            dropout_prob: float,\n",
        "            num_heads: int,\n",
        "            C: int):\n",
        "        super().__init__()\n",
        "        self.ResBlock1 = ResBlock(C, num_groups, dropout_prob)\n",
        "        self.ResBlock2 = ResBlock(C, num_groups, dropout_prob)\n",
        "        if upscale:\n",
        "            self.conv = nn.ConvTranspose2d(C, C//2, kernel_size=4, stride=2, padding=1)\n",
        "        else:\n",
        "            self.conv = nn.Conv2d(C, C*2, kernel_size=3, stride=2, padding=1)\n",
        "        self.attention_layer = Attention(C, num_heads, dropout_prob) if attention else None\n",
        "\n",
        "    def forward(self, x, embeddings):\n",
        "        x = self.ResBlock1(x, embeddings)\n",
        "        if self.attention_layer:\n",
        "            x = self.attention_layer(x)\n",
        "        x = self.ResBlock2(x, embeddings)\n",
        "        return self.conv(x), x\n",
        "\n",
        "class UNET(nn.Module):\n",
        "    def __init__(self,\n",
        "            Channels: List = [64, 128, 256, 512, 512, 384],\n",
        "            Attentions: List = [False, True, False, False, False, True],\n",
        "            Upscales: List = [False, False, False, True, True, True],\n",
        "            num_groups: int = 32,\n",
        "            dropout_prob: float = 0.1,\n",
        "            num_heads: int = 2,\n",
        "            input_channels: int = 4,\n",
        "            output_channels: int = 4,\n",
        "            time_steps: int = 1000):\n",
        "\n",
        "        super().__init__()\n",
        "        self.num_layers = len(Channels)\n",
        "        self.shallow_conv = nn.Conv2d(input_channels, Channels[0], kernel_size=3, padding=1)\n",
        "        self.embeddings = SinusoidalEmbeddings(time_steps=time_steps, embed_dim=max(Channels))\n",
        "\n",
        "        out_channels = (Channels[-1] // 2) + Channels[0]\n",
        "        self.late_conv = nn.Conv2d(out_channels, out_channels // 2, kernel_size=3, padding=1)\n",
        "        self.output_conv = nn.Conv2d(out_channels // 2, output_channels, kernel_size=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Initialize UNet layers\n",
        "        for i in range(self.num_layers):\n",
        "            layer = UnetLayer(\n",
        "                upscale=Upscales[i],\n",
        "                attention=Attentions[i],\n",
        "                num_groups=num_groups,\n",
        "                dropout_prob=dropout_prob,\n",
        "                num_heads=num_heads,\n",
        "                C=Channels[i],\n",
        "            )\n",
        "            setattr(self, f'Layer{i+1}', layer)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        x = self.shallow_conv(x)\n",
        "        embeddings = self.embeddings(x, t)\n",
        "        residuals = []\n",
        "\n",
        "        for i in range(self.num_layers // 2):\n",
        "            layer = getattr(self, f'Layer{i+1}')\n",
        "            x, res = layer(x, embeddings)\n",
        "            residuals.append(res)\n",
        "\n",
        "        for i in range(self.num_layers//2, self.num_layers):\n",
        "            layer = getattr(self, f'Layer{i+1}')\n",
        "            x = torch.concat((layer(x, embeddings)[0], residuals[self.num_layers-i-1]), dim=1)\n",
        "        return self.output_conv(self.relu(self.late_conv(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8fn_3uy0Ffv"
      },
      "source": [
        "### Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.415329Z",
          "iopub.status.busy": "2025-02-09T13:57:43.415016Z",
          "iopub.status.idle": "2025-02-09T13:57:43.431272Z",
          "shell.execute_reply": "2025-02-09T13:57:43.430569Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.415298Z"
        },
        "id": "yw96YZOGJtlK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class DDPM_Scheduler(nn.Module):\n",
        "    def __init__(self, num_time_steps=1000):\n",
        "        super().__init__()\n",
        "        print_log(f\"Using {num_time_steps} time steps.\")\n",
        "        \n",
        "        self.num_time_steps = num_time_steps\n",
        "        self.beta = torch.linspace(1e-4, 0.02, num_time_steps, requires_grad=False)\n",
        "        alpha = 1 - self.beta\n",
        "        self.alpha = torch.cumprod(alpha, dim=0)  # Now a regular attribute\n",
        "\n",
        "    def forward(self, t):\n",
        "        return self.alpha[t]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.488594Z",
          "iopub.status.busy": "2025-02-09T13:57:43.488353Z",
          "iopub.status.idle": "2025-02-09T13:57:43.492610Z",
          "shell.execute_reply": "2025-02-09T13:57:43.491863Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.488575Z"
        },
        "id": "SHcGhW6OJtlK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vTKVJJu0KTU"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.494010Z",
          "iopub.status.busy": "2025-02-09T13:57:43.493740Z",
          "iopub.status.idle": "2025-02-09T13:57:43.509529Z",
          "shell.execute_reply": "2025-02-09T13:57:43.508809Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.493991Z"
        },
        "id": "YJaJywOLJtlK",
        "outputId": "cb81f22f-75a7-4d53-eb4c-7bf5ac69c841",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train(batch_size: int=16,\n",
        "          num_time_steps: int=1000,\n",
        "          num_epochs: int=15,\n",
        "          seed: int=-1,\n",
        "          ema_decay: float=0.9999,\n",
        "          lr=2e-5,\n",
        "          data_dir: str='/healthy',\n",
        "          checkpoint_path: str=None):\n",
        "\n",
        "    # Set random seed\n",
        "    seed = random.randint(0, 2**32-1) if seed == -1 else seed\n",
        "    print_log(f\"Random seed set to: {seed}\")\n",
        "    set_seed(seed)\n",
        "\n",
        "    # Load dataset\n",
        "    print_log(\"Loading dataset...\")\n",
        "    train_dataset = BRATSDataset(directory=data_dir)\n",
        "    print_log(f\"Dataset length: {len(train_dataset)}\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=16, pin_memory=True)\n",
        "\n",
        "    try:\n",
        "        sample_batch = next(iter(train_loader))\n",
        "        print_log(f\"First batch shape: {sample_batch.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] DataLoader issue: {e}\")\n",
        "        return\n",
        "\n",
        "    _, H, W = sample_batch.shape[1:]\n",
        "\n",
        "    # Initialize model\n",
        "    scheduler = DDPM_Scheduler(num_time_steps=num_time_steps)\n",
        "    model = UNET(\n",
        "        input_channels=4,\n",
        "        output_channels=4,\n",
        "        Channels=[64, 128, 256, 512, 512, 384] if max(H, W) <= 256 else [32, 64, 128, 256, 256, 192]\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    ema = ModelEmaV3(model, decay=ema_decay)\n",
        "\n",
        "    # Load checkpoint\n",
        "    if checkpoint_path is not None and os.path.exists(checkpoint_path):\n",
        "        print_log(\"Loading checkpoint...\")\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['weights'])\n",
        "        ema.load_state_dict(checkpoint['ema'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "    criterion = nn.MSELoss(reduction='mean')\n",
        "    try:\n",
        "        iteration = 0\n",
        "        print_log(f\"Starting training for {num_epochs} epochs...\")\n",
        "\n",
        "        for i in range(num_epochs):\n",
        "            print_log(f\"Starting epoch {i+1}/{num_epochs}...\")\n",
        "            total_loss = 0\n",
        "\n",
        "            for bidx, x in enumerate(tqdm(train_loader, desc=f\"----------------------------------------------------------------\\nEpoch {i+1}/{num_epochs}\\n\")):\n",
        "                print(\"\")\n",
        "                print_log(f\"Processing batch {bidx+1}/{len(train_loader)}...\")\n",
        "\n",
        "                x = x.to(device)\n",
        "                print_log(f\"Batch shape: {x.shape}\")\n",
        "\n",
        "                # Normalize to [-1, 1]\n",
        "                x = normalize_images(x)\n",
        "\n",
        "                # Resize if necessary\n",
        "                if max(H, W) > 256:\n",
        "                    x = F.interpolate(x, size=(256, 256), mode='bilinear', align_corners=False)\n",
        "\n",
        "                t = torch.randint(0, num_time_steps, (x.shape[0],)).to(device)\n",
        "                e = torch.randn_like(x, requires_grad=False).to(device)\n",
        "                a = scheduler.alpha.to(device)[t].view(x.shape[0], 1, 1, 1)\n",
        "\n",
        "                x = (torch.sqrt(a) * x) + (torch.sqrt(1 - a) * e)\n",
        "\n",
        "                # Apply diffusion\n",
        "                output = model(x, t)\n",
        "                optimizer.zero_grad()\n",
        "                loss = criterion(output, e)\n",
        "\n",
        "                wandb.log(\n",
        "                    {\n",
        "                        \"iteration\": iteration,\n",
        "                        \"loss\": loss.item(),\n",
        "                        \"batch\": bidx+1,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                iteration += 1\n",
        "                total_loss += loss.item()\n",
        "                print_log(f\"Loss: {loss.item()}\")\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                ema.update(model)\n",
        "\n",
        "            print_log(f\"Epoch {i+1} | Loss {total_loss / len(train_loader):.5f}\")\n",
        "\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"epoch\": i+1,\n",
        "                    \"loss\": total_loss / len(train_loader),\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # Save checkpoint every 5 epochs\n",
        "            if (i + 1) % 5 == 0:\n",
        "                save_checkpoint(model, optimizer, ema, f'brats_ddpm_checkpoint_epoch_{i+1}.pth')\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n[WARNING] Training interrupted. Saving last checkpoint...\")\n",
        "        save_checkpoint(model, optimizer, ema, 'brats_ddpm_interrupted_checkpoint.pth')\n",
        "\n",
        "    print_log(\"Training complete.\")\n",
        "    save_checkpoint(model, optimizer, ema, 'brats_ddpm_final_checkpoint.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eroMMFH0R9c"
      },
      "source": [
        "### Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-09T13:57:43.532110Z",
          "iopub.status.busy": "2025-02-09T13:57:43.531840Z",
          "iopub.status.idle": "2025-02-09T13:57:43.967209Z",
          "shell.execute_reply": "2025-02-09T13:57:43.966070Z",
          "shell.execute_reply.started": "2025-02-09T13:57:43.532083Z"
        },
        "id": "-YU-_H59JtlL",
        "outputId": "44080e18-26df-4983-e98c-3f439eaa28d9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for only 1 epochs!\n",
            "[Log] Random seed set to: 3828849926\n",
            "[Log] Loading dataset...\n",
            "[Log] Dataset length: 5680\n",
            "[Log] First batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Starting training for 1 epochs...\n",
            "[Log] Starting epoch 1/1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 0/5680 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 1/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0152230262756348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 1/5680 [00:23<36:54:05, 23.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 2/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0551211833953857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 2/5680 [00:44<35:11:46, 22.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 3/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0135560035705566\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 3/5680 [01:07<35:17:17, 22.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 4/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0555808544158936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 4/5680 [01:30<35:36:42, 22.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 5/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.011859655380249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 5/5680 [01:51<34:41:32, 22.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 6/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0159296989440918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 6/5680 [02:13<34:48:57, 22.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 7/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0046781301498413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 7/5680 [02:34<34:10:28, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 8/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9948047995567322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 8/5680 [02:56<34:23:31, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 9/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0093085765838623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 9/5680 [03:17<33:50:51, 21.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 10/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9903345704078674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 10/5680 [03:43<36:11:34, 22.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 11/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.013751745223999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 11/5680 [04:05<35:54:30, 22.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 12/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0103548765182495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 12/5680 [04:27<35:06:30, 22.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 13/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0081123113632202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 13/5680 [04:49<35:18:42, 22.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 14/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0194768905639648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 14/5680 [05:10<34:34:10, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 15/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9930764436721802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 15/5680 [05:32<34:40:35, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 16/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9765567779541016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 16/5680 [05:54<34:15:40, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 17/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0171525478363037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 17/5680 [06:16<34:30:55, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 18/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9849004149436951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 18/5680 [06:37<33:58:40, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 19/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9857592582702637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 19/5680 [06:59<34:19:30, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 20/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.999238908290863\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 20/5680 [07:20<33:59:32, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 21/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9821340441703796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 21/5680 [07:42<34:04:40, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 22/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9797205328941345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 22/5680 [08:04<34:17:24, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 23/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9724532961845398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 23/5680 [08:25<33:53:23, 21.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 24/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.000063180923462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 24/5680 [08:47<34:08:34, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 25/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9530729651451111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 25/5680 [09:08<33:45:51, 21.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 26/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9896901249885559\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 26/5680 [09:31<34:08:12, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 27/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9801082015037537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 27/5680 [09:51<33:44:25, 21.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 28/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9975807666778564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   0%|          | 28/5680 [10:14<34:10:19, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 29/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0008317232131958\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 29/5680 [10:35<33:53:23, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 30/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9667218923568726\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 30/5680 [10:57<34:10:35, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 31/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9521063566207886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 31/5680 [11:18<33:51:24, 21.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 32/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9653090834617615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 32/5680 [11:41<34:10:11, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 33/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9507534503936768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 33/5680 [12:02<34:02:55, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 34/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9551435112953186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 34/5680 [12:24<34:01:17, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 35/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.035882830619812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 35/5680 [12:45<33:57:54, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 36/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9482079744338989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 36/5680 [13:07<33:44:58, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 37/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9597234725952148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 37/5680 [13:29<34:06:06, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 38/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9485320448875427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 38/5680 [13:50<33:44:55, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 39/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9943030476570129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 39/5680 [14:12<34:04:50, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 40/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9880566000938416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 40/5680 [14:33<33:40:08, 21.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 41/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9780979752540588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 41/5680 [14:55<34:01:45, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 42/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9692570567131042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 42/5680 [15:16<33:39:21, 21.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 43/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9552075266838074\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 43/5680 [15:38<33:57:30, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 44/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9264540672302246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 44/5680 [16:00<33:44:26, 21.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 45/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9471526741981506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 45/5680 [16:22<34:09:26, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 46/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0003350973129272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 46/5680 [16:43<33:54:40, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 47/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9324210286140442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 47/5680 [17:05<33:57:11, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 48/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.952163577079773\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 48/5680 [17:27<33:55:29, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 49/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.980903685092926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 49/5680 [17:48<33:37:46, 21.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 50/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9487895369529724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 50/5680 [18:10<34:03:33, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 51/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9228098392486572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 51/5680 [18:31<33:38:40, 21.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 52/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9178342223167419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 52/5680 [18:54<33:58:34, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 53/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9891015291213989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 53/5680 [19:14<33:33:05, 21.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 54/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9198601841926575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 54/5680 [19:37<33:52:42, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 55/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9261701107025146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 55/5680 [19:58<33:42:04, 21.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 56/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9346335530281067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 56/5680 [20:20<34:02:34, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 57/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9444065093994141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 57/5680 [20:41<33:45:46, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 58/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9203993082046509\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 58/5680 [21:04<34:07:22, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 59/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0080493688583374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 59/5680 [21:25<33:55:10, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 60/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0330564975738525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 60/5680 [21:47<33:57:04, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 61/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9508023262023926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 61/5680 [22:09<34:12:24, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 62/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9420185089111328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 62/5680 [22:30<33:50:32, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 63/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9948996305465698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 63/5680 [22:53<34:07:32, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 64/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.032515287399292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 64/5680 [23:14<33:43:56, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 65/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9296214580535889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 65/5680 [23:36<34:00:59, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 66/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9095075130462646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 66/5680 [23:57<33:49:49, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 67/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9495982527732849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 67/5680 [24:20<34:10:36, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 68/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9024916291236877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 68/5680 [24:41<33:46:19, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 69/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9918668866157532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 69/5680 [25:03<34:02:34, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 70/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9099285006523132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|          | 70/5680 [25:25<33:56:40, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 71/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9338691830635071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 71/5680 [25:46<33:49:14, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 72/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.883647084236145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 72/5680 [26:09<34:11:21, 21.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 73/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9137545228004456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 73/5680 [26:30<33:44:27, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 74/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9334558248519897\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 74/5680 [26:52<34:06:17, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 75/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9071978330612183\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 75/5680 [27:13<33:41:12, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 76/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9032378792762756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 76/5680 [27:36<33:57:07, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 77/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.874416172504425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 77/5680 [27:57<33:44:58, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 78/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9364174604415894\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 78/5680 [28:19<34:04:51, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 79/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9980915784835815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 79/5680 [28:41<33:51:33, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 80/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8950353264808655\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 80/5680 [29:03<33:57:06, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 81/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8571258187294006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 81/5680 [29:25<33:57:18, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 82/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9651418328285217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 82/5680 [29:46<33:40:03, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 83/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8732959628105164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 83/5680 [30:08<34:03:49, 21.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 84/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9033029079437256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 84/5680 [30:29<33:36:28, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 85/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9490482807159424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   1%|         | 85/5680 [30:52<33:58:51, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 86/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8420613408088684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 86/5680 [31:13<33:34:09, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 87/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8566706776618958\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 87/5680 [31:35<33:53:54, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 88/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9911085367202759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 88/5680 [31:56<33:33:46, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 89/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8820538520812988\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 89/5680 [32:18<33:49:07, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 90/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8682439923286438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 90/5680 [32:40<33:32:25, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 91/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8748950362205505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 91/5680 [33:02<33:47:52, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 92/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8526207804679871\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 92/5680 [33:23<33:40:25, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 93/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8817650079727173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 93/5680 [33:45<33:32:58, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 94/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8432872891426086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 94/5680 [34:07<33:47:35, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 95/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8918802738189697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 95/5680 [34:28<33:26:46, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 96/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8432487845420837\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 96/5680 [34:50<33:45:05, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 97/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8327198624610901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 97/5680 [35:11<33:23:14, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 98/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8722348213195801\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 98/5680 [35:33<33:42:59, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 99/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9873930811882019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 99/5680 [35:54<33:23:13, 21.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 100/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8301800489425659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 100/5680 [36:17<33:39:41, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 101/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8273051977157593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 101/5680 [36:38<33:18:07, 21.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 102/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8401370048522949\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 102/5680 [37:00<33:43:12, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 103/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9729903936386108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 103/5680 [37:21<33:17:14, 21.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 104/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8433173894882202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 104/5680 [37:43<33:28:44, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 105/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8448005318641663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 105/5680 [38:04<33:25:53, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 106/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8703160285949707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 106/5680 [38:26<33:25:29, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 107/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8453643918037415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 107/5680 [38:48<33:32:01, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 108/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9140517115592957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 108/5680 [39:09<33:14:05, 21.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 109/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8106304407119751\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 109/5680 [39:31<33:38:40, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 110/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.827776312828064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 110/5680 [39:52<33:17:34, 21.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 111/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7999908328056335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 111/5680 [40:14<33:40:18, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 112/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8712761998176575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 112/5680 [40:35<33:18:26, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 113/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8058862686157227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 113/5680 [40:58<33:39:15, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 114/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8311898112297058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 114/5680 [41:19<33:20:14, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 115/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8321754932403564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 115/5680 [41:41<33:42:46, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 116/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7988194227218628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 116/5680 [42:02<33:23:24, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 117/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8125925660133362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 117/5680 [42:24<33:37:12, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 118/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7827553153038025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 118/5680 [42:46<33:26:22, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 119/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7780492305755615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 119/5680 [43:07<33:21:21, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 120/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7754107713699341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 120/5680 [43:29<33:35:27, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 121/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8477756381034851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 121/5680 [43:50<33:11:51, 21.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 122/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8055909872055054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 122/5680 [44:12<33:29:50, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 123/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8521647453308105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 123/5680 [44:33<33:09:14, 21.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 124/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8087751269340515\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 124/5680 [44:55<33:26:51, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 125/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7622804641723633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 125/5680 [45:17<33:11:01, 21.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 126/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.864057183265686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 126/5680 [45:39<33:29:13, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 127/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8834661841392517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 127/5680 [46:00<33:16:16, 21.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 128/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8791274428367615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 128/5680 [46:22<33:35:12, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 129/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7612830996513367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 129/5680 [46:44<33:26:14, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 130/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8146936297416687\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 130/5680 [47:06<33:27:28, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 131/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.755581259727478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 131/5680 [47:28<33:37:35, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 132/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7611016631126404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 132/5680 [47:49<33:18:21, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 133/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9169661998748779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 133/5680 [48:11<33:36:02, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 134/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.727563738822937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 134/5680 [48:32<33:09:29, 21.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 135/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7779136300086975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 135/5680 [48:54<33:29:06, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 136/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7987850904464722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 136/5680 [49:15<33:04:58, 21.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 137/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8089743852615356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 137/5680 [49:37<33:26:50, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 138/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8465964198112488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 138/5680 [49:58<33:12:00, 21.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 139/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.828044593334198\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 139/5680 [50:21<33:28:14, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 140/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8071304559707642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 140/5680 [50:42<33:07:48, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 141/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8197280168533325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 141/5680 [51:04<33:32:31, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 142/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.00152587890625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   2%|         | 142/5680 [51:25<33:11:51, 21.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 143/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7426822781562805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 143/5680 [51:47<33:23:07, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 144/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.922909140586853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 144/5680 [52:09<33:32:40, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 145/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.718802809715271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 145/5680 [52:30<33:13:48, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 146/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7147679328918457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 146/5680 [52:53<33:28:47, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 147/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9338834881782532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 147/5680 [53:13<33:04:15, 21.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 148/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7010403871536255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 148/5680 [53:36<33:21:50, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 149/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0256319046020508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 149/5680 [53:57<33:05:35, 21.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 150/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7259597778320312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 150/5680 [54:19<33:25:44, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 151/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7101733684539795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 151/5680 [54:40<33:10:18, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 152/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7067279815673828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 152/5680 [55:02<33:23:54, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 153/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.699510395526886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 153/5680 [55:23<33:04:24, 21.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 154/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7055210471153259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 154/5680 [55:46<33:24:30, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 155/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6799590587615967\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 155/5680 [56:07<33:09:11, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 156/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7122490406036377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 156/5680 [56:29<33:20:11, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 157/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.949158787727356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 157/5680 [56:51<33:28:29, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 158/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6904449462890625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 158/5680 [57:12<33:03:57, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 159/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8932921290397644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 159/5680 [57:34<33:27:32, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 160/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9115382432937622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 160/5680 [57:55<33:06:26, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 161/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.897833526134491\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 161/5680 [58:18<33:26:10, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 162/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7397810220718384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 162/5680 [58:39<33:07:23, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 163/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9438093900680542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 163/5680 [59:01<33:27:51, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 164/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6607493162155151\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 164/5680 [59:22<33:06:58, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 165/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.902549147605896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 165/5680 [59:45<33:28:38, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 166/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6562877893447876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 166/5680 [1:00:06<33:19:57, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 167/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6767470240592957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 167/5680 [1:00:28<33:22:35, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 168/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7813467383384705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 168/5680 [1:00:50<33:24:51, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 169/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6572627425193787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 169/5680 [1:01:11<33:05:56, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 170/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6715947389602661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 170/5680 [1:01:34<33:25:54, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 171/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6740336418151855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 171/5680 [1:01:55<33:02:21, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 172/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6897129416465759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 172/5680 [1:02:17<33:23:51, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 173/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6252249479293823\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 173/5680 [1:02:38<33:02:04, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 174/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8789944648742676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 174/5680 [1:03:00<33:20:32, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 175/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6382516026496887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 175/5680 [1:03:21<33:02:42, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 176/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6386626958847046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 176/5680 [1:03:44<33:22:27, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 177/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.791951060295105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 177/5680 [1:04:05<33:05:50, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 178/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6212067604064941\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 178/5680 [1:04:27<33:23:13, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 179/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6437190175056458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 179/5680 [1:04:49<33:21:21, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 180/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8273017406463623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 180/5680 [1:05:10<33:06:29, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 181/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9080275893211365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 181/5680 [1:05:33<33:25:27, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 182/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8300772309303284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 182/5680 [1:05:54<33:03:22, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 183/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0107088088989258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 183/5680 [1:06:16<33:22:56, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 184/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9056440591812134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 184/5680 [1:06:37<32:59:44, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 185/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9500229954719543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 185/5680 [1:07:00<33:20:36, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 186/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6423363089561462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 186/5680 [1:07:21<33:04:45, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 187/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.932767927646637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 187/5680 [1:07:43<33:23:53, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 188/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6366046667098999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 188/5680 [1:08:05<33:08:05, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 189/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6893437504768372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 189/5680 [1:08:27<33:20:45, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 190/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6453093886375427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 190/5680 [1:08:49<33:15:38, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 191/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6170741319656372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 191/5680 [1:09:10<33:04:27, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 192/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7219305634498596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 192/5680 [1:09:32<33:26:01, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 193/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.961249828338623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 193/5680 [1:09:54<33:02:10, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 194/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7011813521385193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 194/5680 [1:10:16<33:22:23, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 195/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7602555751800537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 195/5680 [1:10:37<33:03:55, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 196/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6606771349906921\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 196/5680 [1:10:59<33:20:34, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 197/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6481676697731018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 197/5680 [1:11:21<32:59:52, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 198/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6377983093261719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   3%|         | 198/5680 [1:11:43<33:20:49, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 199/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6666826009750366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 199/5680 [1:12:05<33:14:17, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 200/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.703864336013794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 200/5680 [1:12:27<33:14:50, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 201/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6030898094177246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 201/5680 [1:12:49<33:23:32, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 202/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5921798348426819\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 202/5680 [1:13:10<32:57:54, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 203/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6083749532699585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 203/5680 [1:13:32<33:16:27, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 204/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8030290007591248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 204/5680 [1:13:53<32:56:32, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 205/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6288220286369324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 205/5680 [1:14:16<33:11:45, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 206/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5960052609443665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 206/5680 [1:14:37<32:55:41, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 207/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8373295068740845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 207/5680 [1:14:59<33:13:13, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 208/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5801689028739929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 208/5680 [1:15:20<32:56:58, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 209/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5923794507980347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 209/5680 [1:15:43<33:17:17, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 210/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6720933318138123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 210/5680 [1:16:04<33:08:20, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 211/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6761579513549805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 211/5680 [1:16:26<33:06:09, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 212/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7472823858261108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 212/5680 [1:16:48<33:10:28, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 213/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5825192332267761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 213/5680 [1:17:09<32:45:32, 21.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 214/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6054588556289673\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 214/5680 [1:17:31<33:06:00, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 215/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6782596707344055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 215/5680 [1:17:52<32:40:08, 21.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 216/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8826178312301636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 216/5680 [1:18:15<33:01:42, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 217/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8759638071060181\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 217/5680 [1:18:36<32:47:18, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 218/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6745875477790833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 218/5680 [1:18:58<33:08:28, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 219/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.557746171951294\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 219/5680 [1:19:19<32:50:12, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 220/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8534396290779114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 220/5680 [1:19:42<33:08:42, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 221/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6980065107345581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 221/5680 [1:20:03<32:52:43, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 222/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.631144106388092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 222/5680 [1:20:25<33:01:05, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 223/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.540234386920929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 223/5680 [1:20:47<33:05:30, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 224/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5472036004066467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 224/5680 [1:21:08<32:48:22, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 225/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5646430850028992\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 225/5680 [1:21:31<33:07:45, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 226/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6136066913604736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 226/5680 [1:21:52<32:43:08, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 227/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7329639196395874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 227/5680 [1:22:14<33:04:14, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 228/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5338618159294128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 228/5680 [1:22:35<32:44:54, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 229/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6039988398551941\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 229/5680 [1:22:57<33:03:10, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 230/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5355167388916016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 230/5680 [1:23:19<32:43:58, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 231/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5839695334434509\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 231/5680 [1:23:41<33:03:08, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 232/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5787850618362427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 232/5680 [1:24:02<32:53:24, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 233/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6847694516181946\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 233/5680 [1:24:24<32:57:18, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 234/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7331389784812927\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 234/5680 [1:24:46<32:59:57, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 235/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5287871956825256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 235/5680 [1:25:07<32:43:32, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 236/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5241568088531494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 236/5680 [1:25:30<33:04:16, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 237/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5445302128791809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 237/5680 [1:25:51<32:33:45, 21.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 238/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5804065465927124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 238/5680 [1:26:13<32:57:36, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 239/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8555901646614075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 239/5680 [1:26:34<32:37:46, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 240/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5349752902984619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 240/5680 [1:26:56<32:57:32, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 241/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5560889840126038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 241/5680 [1:27:17<32:37:23, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 242/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5231744050979614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 242/5680 [1:27:40<32:56:12, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 243/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7459129095077515\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 243/5680 [1:28:01<32:38:24, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 244/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5191289186477661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 244/5680 [1:28:23<32:57:19, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 245/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6979650259017944\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 245/5680 [1:28:45<32:49:53, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 246/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5749766826629639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 246/5680 [1:29:06<32:44:47, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 247/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5270084142684937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 247/5680 [1:29:28<32:48:34, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 248/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6098309755325317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 248/5680 [1:29:49<32:33:34, 21.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 249/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4793994724750519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 249/5680 [1:30:12<32:52:53, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 250/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5179524421691895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 250/5680 [1:30:33<32:30:17, 21.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 251/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4907151758670807\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 251/5680 [1:30:55<32:50:06, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 252/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5090770721435547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 252/5680 [1:31:16<32:29:05, 21.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 253/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5863445401191711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 253/5680 [1:31:38<32:50:14, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 254/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5917221307754517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 254/5680 [1:32:00<32:38:10, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 255/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6807495355606079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   4%|         | 255/5680 [1:32:22<32:58:40, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 256/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5264755487442017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 256/5680 [1:32:43<32:31:21, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 257/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5936943292617798\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 257/5680 [1:33:05<32:46:06, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 258/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4637826979160309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 258/5680 [1:33:27<32:43:15, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 259/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.48262614011764526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 259/5680 [1:33:48<32:36:46, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 260/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7732040286064148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 260/5680 [1:34:11<32:56:03, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 261/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6447793841362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 261/5680 [1:34:31<32:24:56, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 262/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.48704105615615845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 262/5680 [1:34:54<32:50:06, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 263/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9835833311080933\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 263/5680 [1:35:15<32:26:24, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 264/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4943973422050476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 264/5680 [1:35:37<32:44:15, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 265/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8502985239028931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 265/5680 [1:35:58<32:31:32, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 266/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5154467225074768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 266/5680 [1:36:21<32:51:10, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 267/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4485778212547302\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 267/5680 [1:36:42<32:27:46, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 268/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8208436369895935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 268/5680 [1:37:04<32:46:48, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 269/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5036846995353699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 269/5680 [1:37:26<32:37:10, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 270/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7272104024887085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 270/5680 [1:37:47<32:34:16, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 271/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8485208749771118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 271/5680 [1:38:09<32:46:35, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 272/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.524206280708313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 272/5680 [1:38:30<32:26:47, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 273/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4438004493713379\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 273/5680 [1:38:53<32:42:44, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 274/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6623488664627075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 274/5680 [1:39:14<32:20:12, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 275/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.47747042775154114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 275/5680 [1:39:36<32:40:35, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 276/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9464658498764038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 276/5680 [1:39:57<32:24:06, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 277/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0001221895217896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 277/5680 [1:40:19<32:41:27, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 278/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4369836449623108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 278/5680 [1:40:40<32:23:18, 21.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 279/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.45248374342918396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 279/5680 [1:41:03<32:45:17, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 280/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4789738655090332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 280/5680 [1:41:24<32:28:04, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 281/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6064603328704834\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 281/5680 [1:41:46<32:37:54, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 282/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5042999982833862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 282/5680 [1:42:08<32:41:47, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 283/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6570360064506531\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 283/5680 [1:42:29<32:24:50, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 284/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4599565267562866\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 284/5680 [1:42:51<32:43:20, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 285/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.49002572894096375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 285/5680 [1:43:12<32:16:37, 21.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 286/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6712660193443298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 286/5680 [1:43:35<32:38:39, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 287/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6458577513694763\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 287/5680 [1:43:56<32:18:22, 21.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 288/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6781820058822632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 288/5680 [1:44:18<32:37:40, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 289/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4300200343132019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 289/5680 [1:44:39<32:21:21, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 290/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4190353453159332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 290/5680 [1:45:02<32:42:26, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 291/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.46247121691703796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 291/5680 [1:45:23<32:23:17, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 292/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4785846769809723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 292/5680 [1:45:45<32:37:02, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 293/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.43102654814720154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 293/5680 [1:46:07<32:37:54, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 294/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3989282250404358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 294/5680 [1:46:28<32:28:11, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 295/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4679056704044342\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 295/5680 [1:46:50<32:43:46, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 296/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4815010130405426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 296/5680 [1:47:11<32:19:10, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 297/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4544936418533325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 297/5680 [1:47:34<32:38:11, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 298/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.46879810094833374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 298/5680 [1:47:55<32:18:56, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 299/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5850716233253479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 299/5680 [1:48:17<32:37:13, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 300/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5923325419425964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 300/5680 [1:48:38<32:19:57, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 301/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6211153864860535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 301/5680 [1:49:01<32:34:24, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 302/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5324507355690002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 302/5680 [1:49:21<32:07:06, 21.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 303/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4059312045574188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 303/5680 [1:49:44<32:30:49, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 304/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.407583087682724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 304/5680 [1:50:05<32:26:26, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 305/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4565689265727997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 305/5680 [1:50:27<32:26:16, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 306/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5199109315872192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 306/5680 [1:50:49<32:28:18, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 307/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5721908807754517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 307/5680 [1:51:10<32:14:42, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 308/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.40285226702690125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 308/5680 [1:51:33<32:38:13, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 309/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5573896765708923\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 309/5680 [1:51:54<32:17:48, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 310/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5865753293037415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 310/5680 [1:52:16<32:34:44, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 311/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.40457290410995483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 311/5680 [1:52:38<32:21:41, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 312/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.42635002732276917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   5%|         | 312/5680 [1:53:00<32:46:44, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 313/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5233358144760132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 313/5680 [1:53:22<32:32:34, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 314/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.40076297521591187\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 314/5680 [1:53:44<32:44:54, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 315/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7761018872261047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 315/5680 [1:54:06<32:52:33, 22.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 316/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5378651022911072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 316/5680 [1:54:28<32:35:08, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 317/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3582572638988495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 317/5680 [1:54:50<32:54:08, 22.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 318/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4969632029533386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 318/5680 [1:55:11<32:27:20, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 319/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.460647851228714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 319/5680 [1:55:34<32:43:48, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 320/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7206172943115234\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 320/5680 [1:55:55<32:28:59, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 321/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.43886905908584595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 321/5680 [1:56:18<32:47:03, 22.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 322/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5945945382118225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 322/5680 [1:56:39<32:24:55, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 323/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5074833631515503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 323/5680 [1:57:01<32:41:19, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 324/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8805930614471436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 324/5680 [1:57:23<32:43:10, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 325/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3835906982421875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 325/5680 [1:57:45<32:23:43, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 326/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4082581400871277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 326/5680 [1:58:07<32:47:21, 22.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 327/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.37793102860450745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 327/5680 [1:58:29<32:24:48, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 328/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6316237449645996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 328/5680 [1:58:51<32:36:23, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 329/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.37862011790275574\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 329/5680 [1:59:12<32:16:22, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 330/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5907600522041321\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 330/5680 [1:59:34<32:36:19, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 331/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3595849275588989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 331/5680 [1:59:56<32:20:23, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 332/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5835270881652832\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 332/5680 [2:00:18<32:41:53, 22.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 333/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5316725969314575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 333/5680 [2:00:40<32:43:02, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 334/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9778770208358765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 334/5680 [2:01:02<32:26:55, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 335/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7237182259559631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 335/5680 [2:01:24<32:39:29, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 336/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.41389888525009155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 336/5680 [2:01:45<32:16:49, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 337/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6710547208786011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 337/5680 [2:02:08<32:41:23, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 338/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4087144136428833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 338/5680 [2:02:29<32:22:18, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 339/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7515076398849487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 339/5680 [2:02:52<32:39:13, 22.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 340/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.556664228439331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 340/5680 [2:03:13<32:18:26, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 341/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.35056009888648987\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 341/5680 [2:03:36<32:36:48, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 342/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.428803414106369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 342/5680 [2:03:57<32:29:58, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 343/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4545172452926636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 343/5680 [2:04:19<32:19:09, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 344/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.35969245433807373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 344/5680 [2:04:41<32:38:53, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 345/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7402709126472473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 345/5680 [2:05:03<32:13:57, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 346/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3288927972316742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 346/5680 [2:05:25<32:31:37, 21.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 347/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5668787956237793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 347/5680 [2:05:46<32:10:28, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 348/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.36851394176483154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 348/5680 [2:06:09<32:29:00, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 349/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4002871513366699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 349/5680 [2:06:30<32:11:54, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 350/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.35678809881210327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 350/5680 [2:06:52<32:30:03, 21.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 351/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.320437490940094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 351/5680 [2:07:13<32:10:15, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 352/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3706008791923523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 352/5680 [2:07:36<32:22:59, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 353/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4980817437171936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 353/5680 [2:07:58<32:20:59, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 354/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5512747168540955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 354/5680 [2:08:19<32:07:09, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 355/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3136175572872162\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 355/5680 [2:08:41<32:29:52, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 356/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.43275195360183716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 356/5680 [2:09:03<32:08:52, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 357/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6081244945526123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 357/5680 [2:09:25<32:22:39, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 358/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5579610466957092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 358/5680 [2:09:46<32:00:55, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 359/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3339606523513794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 359/5680 [2:10:09<32:26:46, 21.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 360/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.33327335119247437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 360/5680 [2:10:30<32:10:39, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 361/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3994961977005005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 361/5680 [2:10:52<32:26:23, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 362/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3832632303237915\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 362/5680 [2:11:14<32:20:36, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 363/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3282968997955322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 363/5680 [2:11:36<32:15:42, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 364/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.30214637517929077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 364/5680 [2:11:58<32:24:09, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 365/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.347521036863327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 365/5680 [2:12:19<32:04:00, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 366/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3074777126312256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 366/5680 [2:12:42<32:27:19, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 367/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.36915814876556396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 367/5680 [2:13:03<32:02:22, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 368/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.43919312953948975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 368/5680 [2:13:25<32:17:56, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 369/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5300917625427246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   6%|         | 369/5680 [2:13:47<32:03:26, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 370/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.35501933097839355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 370/5680 [2:14:09<32:24:29, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 371/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.43497228622436523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 371/5680 [2:14:31<32:10:04, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 372/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.35436028242111206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 372/5680 [2:14:53<32:20:23, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 373/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3369831442832947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 373/5680 [2:15:15<32:22:10, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 374/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.34126758575439453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 374/5680 [2:15:36<32:09:37, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 375/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9002498388290405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 375/5680 [2:15:59<32:31:46, 22.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 376/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3843235671520233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 376/5680 [2:16:20<32:10:36, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 377/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.364808052778244\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 377/5680 [2:16:43<32:27:28, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 378/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2862616777420044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 378/5680 [2:17:04<32:06:09, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 379/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2904300093650818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 379/5680 [2:17:27<32:25:14, 22.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 380/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4975922107696533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 380/5680 [2:17:48<32:09:08, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 381/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2870476245880127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 381/5680 [2:18:11<32:30:31, 22.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 382/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7143220901489258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 382/5680 [2:18:33<32:28:46, 22.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 383/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.48671621084213257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 383/5680 [2:18:54<32:09:10, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 384/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3020954728126526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 384/5680 [2:19:16<32:20:10, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 385/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.33241674304008484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 385/5680 [2:19:37<31:54:28, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 386/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.33841848373413086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 386/5680 [2:20:00<32:14:40, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 387/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.30571451783180237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 387/5680 [2:20:21<31:52:32, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 388/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5848740339279175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 388/5680 [2:20:43<32:06:48, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 389/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2924026548862457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 389/5680 [2:21:04<31:48:58, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 390/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3306640684604645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 390/5680 [2:21:27<32:10:19, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 391/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.624183177947998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 391/5680 [2:21:48<31:56:28, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 392/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3539128601551056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 392/5680 [2:22:10<32:09:17, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 393/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.29028183221817017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 393/5680 [2:22:32<32:11:44, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 394/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6992501020431519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 394/5680 [2:22:54<31:53:35, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 395/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5693199634552002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 395/5680 [2:23:16<32:08:46, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 396/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.38306891918182373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 396/5680 [2:23:37<31:45:04, 21.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 397/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.27371707558631897\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 397/5680 [2:23:59<32:05:30, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 398/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6903332471847534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 398/5680 [2:24:20<31:44:55, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 399/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4543309807777405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 399/5680 [2:24:43<32:04:57, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 400/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.35180628299713135\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 400/5680 [2:25:04<31:44:26, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 401/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.40533366799354553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 401/5680 [2:25:26<32:03:54, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 402/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2659929096698761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 402/5680 [2:25:48<31:50:30, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 403/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.29552626609802246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 403/5680 [2:26:10<31:58:27, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 404/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2910727560520172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 404/5680 [2:26:32<31:57:27, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 405/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.367715448141098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 405/5680 [2:26:53<31:38:50, 21.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 406/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3000560998916626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 406/5680 [2:27:15<31:59:06, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 407/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.777368426322937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 407/5680 [2:27:36<31:36:15, 21.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 408/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2572760283946991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 408/5680 [2:27:59<32:01:38, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 409/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5752502083778381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 409/5680 [2:28:20<31:39:17, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 410/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4387357532978058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 410/5680 [2:28:42<31:58:38, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 411/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.24721436202526093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 411/5680 [2:29:03<31:43:25, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 412/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.24951282143592834\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 412/5680 [2:29:26<31:58:49, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 413/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.26872754096984863\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 413/5680 [2:29:47<31:42:07, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 414/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6089677810668945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 414/5680 [2:30:09<31:54:43, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 415/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8875277042388916\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 415/5680 [2:30:31<31:56:33, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 416/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.313766211271286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 416/5680 [2:30:52<31:37:36, 21.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 417/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.46387171745300293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 417/5680 [2:31:14<31:54:34, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 418/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2663150429725647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 418/5680 [2:31:35<31:28:05, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 419/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4298485815525055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 419/5680 [2:31:58<31:52:55, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 420/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.31851157546043396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 420/5680 [2:32:19<31:33:06, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 421/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.25731220841407776\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 421/5680 [2:32:41<31:52:07, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 422/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.49344903230667114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 422/5680 [2:33:02<31:38:24, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 423/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2844461500644684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 423/5680 [2:33:25<31:59:00, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 424/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2440957874059677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 424/5680 [2:33:46<31:40:04, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 425/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8273128271102905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   7%|         | 425/5680 [2:34:08<31:51:51, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 426/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8762698173522949\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 426/5680 [2:34:30<31:51:19, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 427/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2547606825828552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 427/5680 [2:34:51<31:35:14, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 428/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.26074111461639404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 428/5680 [2:35:13<31:50:45, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 429/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3233414888381958\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 429/5680 [2:35:34<31:26:39, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 430/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23975780606269836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 430/5680 [2:35:57<31:46:05, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 431/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4071466624736786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 431/5680 [2:36:18<31:25:19, 21.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 432/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4155983030796051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 432/5680 [2:36:40<31:41:16, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 433/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3020339608192444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 433/5680 [2:37:01<31:21:16, 21.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 434/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7255657911300659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 434/5680 [2:37:23<31:39:07, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 435/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22985565662384033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 435/5680 [2:37:44<31:21:49, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 436/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6363674998283386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 436/5680 [2:38:06<31:42:34, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 437/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3051716685295105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 437/5680 [2:38:28<31:24:23, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 438/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.30245286226272583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 438/5680 [2:38:49<31:34:18, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 439/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23461830615997314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 439/5680 [2:39:11<31:36:53, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 440/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.371694952249527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 440/5680 [2:39:33<31:25:31, 21.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 441/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6948171257972717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 441/5680 [2:39:55<31:44:23, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 442/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6280380487442017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 442/5680 [2:40:16<31:17:01, 21.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 443/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2340071052312851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 443/5680 [2:40:38<31:37:09, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 444/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8881476521492004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 444/5680 [2:40:59<31:16:32, 21.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 445/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.38405442237854004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 445/5680 [2:41:21<31:33:17, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 446/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.010310173034668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 446/5680 [2:41:42<31:16:53, 21.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 447/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2497256100177765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 447/5680 [2:42:05<31:41:49, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 448/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2618277072906494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 448/5680 [2:42:26<31:24:13, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 449/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.21518872678279877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 449/5680 [2:42:48<31:36:22, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 450/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7737061381340027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 450/5680 [2:43:09<31:29:36, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 451/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22368378937244415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 451/5680 [2:43:31<31:19:58, 21.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 452/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2662004828453064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 452/5680 [2:43:53<31:37:27, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 453/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3000568449497223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 453/5680 [2:44:14<31:14:50, 21.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 454/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4970596432685852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 454/5680 [2:44:36<31:33:53, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 455/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2254011332988739\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 455/5680 [2:44:57<31:14:49, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 456/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.25375673174858093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 456/5680 [2:45:19<31:33:15, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 457/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2277582287788391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 457/5680 [2:45:41<31:16:41, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 458/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3499366044998169\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 458/5680 [2:46:03<31:39:28, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 459/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9554305076599121\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 459/5680 [2:46:24<31:13:33, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 460/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22256618738174438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 460/5680 [2:46:46<31:32:54, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 461/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2513541281223297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 461/5680 [2:47:08<31:29:36, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 462/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2334827333688736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 462/5680 [2:47:29<31:21:15, 21.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 463/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4236045479774475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 463/5680 [2:47:51<31:30:54, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 464/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23765617609024048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 464/5680 [2:48:12<31:10:21, 21.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 465/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.28766682744026184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 465/5680 [2:48:34<31:29:21, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 466/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3131321668624878\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 466/5680 [2:48:55<31:09:30, 21.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 467/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2417023926973343\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 467/5680 [2:49:18<31:24:36, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 468/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.24376243352890015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 468/5680 [2:49:39<31:10:38, 21.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 469/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3252319097518921\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 469/5680 [2:50:01<31:32:32, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 470/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3265816271305084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 470/5680 [2:50:22<31:12:05, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 471/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.25882768630981445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 471/5680 [2:50:44<31:31:46, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 472/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4590805172920227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 472/5680 [2:51:06<31:27:35, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 473/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2746070921421051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 473/5680 [2:51:27<31:17:56, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 474/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3079874515533447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 474/5680 [2:51:50<31:37:51, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 475/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2060677409172058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 475/5680 [2:52:11<31:15:53, 21.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 476/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.20742031931877136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 476/5680 [2:52:33<31:34:16, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 477/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3732653856277466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 477/5680 [2:52:54<31:11:21, 21.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 478/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.20365111529827118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 478/5680 [2:53:16<31:23:12, 21.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 479/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2525768280029297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 479/5680 [2:53:38<31:08:58, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 480/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19244489073753357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 480/5680 [2:54:00<31:29:19, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 481/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22728124260902405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 481/5680 [2:54:21<31:17:47, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 482/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22552791237831116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   8%|         | 482/5680 [2:54:43<31:25:47, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 483/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.261929988861084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 483/5680 [2:55:05<31:27:12, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 484/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3318736255168915\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 484/5680 [2:55:26<31:11:05, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 485/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4603784680366516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 485/5680 [2:55:49<31:30:06, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 486/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22706292569637299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 486/5680 [2:56:10<31:10:43, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 487/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2675849199295044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 487/5680 [2:56:32<31:29:28, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 488/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.35171234607696533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 488/5680 [2:56:53<31:09:53, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 489/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22091630101203918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 489/5680 [2:57:15<31:26:01, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 490/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1894005388021469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 490/5680 [2:57:37<31:09:01, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 491/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3358651101589203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 491/5680 [2:57:59<31:29:27, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 492/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18627122044563293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 492/5680 [2:58:21<31:23:36, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 493/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3682253062725067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 493/5680 [2:58:42<31:18:49, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 494/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1921669989824295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 494/5680 [2:59:04<31:29:43, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 495/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.39179226756095886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 495/5680 [2:59:25<31:07:35, 21.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 496/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22109150886535645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 496/5680 [2:59:48<31:23:34, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 497/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2125719040632248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 497/5680 [3:00:10<31:40:12, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 498/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22268718481063843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 498/5680 [3:00:33<32:08:59, 22.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 499/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8928933143615723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 499/5680 [3:00:54<31:39:43, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 500/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.24361634254455566\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 500/5680 [3:01:17<31:51:08, 22.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 501/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.467180997133255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 501/5680 [3:01:39<31:42:36, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 502/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18927444517612457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 502/5680 [3:02:00<31:27:19, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 503/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3859238624572754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 503/5680 [3:02:22<31:36:38, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 504/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4876096546649933\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 504/5680 [3:02:43<31:10:03, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 505/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18221570551395416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 505/5680 [3:03:06<31:28:56, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 506/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19185695052146912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 506/5680 [3:03:27<31:07:39, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 507/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1788402944803238\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 507/5680 [3:03:49<31:24:32, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 508/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2973729074001312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 508/5680 [3:04:10<31:08:42, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 509/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2389647513628006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 509/5680 [3:04:33<31:29:36, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 510/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8550016283988953\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 510/5680 [3:04:55<31:22:02, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 511/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22993555665016174\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 511/5680 [3:05:16<31:18:47, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 512/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17429932951927185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 512/5680 [3:05:39<31:32:15, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 513/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.25802066922187805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 513/5680 [3:06:00<31:11:20, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 514/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.21980728209018707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 514/5680 [3:06:22<31:29:18, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 515/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2604660987854004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 515/5680 [3:06:44<31:10:43, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 516/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2995128035545349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 516/5680 [3:07:06<31:32:31, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 517/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2873654365539551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 517/5680 [3:07:28<31:17:23, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 518/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17708249390125275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 518/5680 [3:07:50<31:39:03, 22.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 519/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2600919008255005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 519/5680 [3:08:12<31:34:33, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 520/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.21527604758739471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 520/5680 [3:08:34<31:19:23, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 521/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17443212866783142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 521/5680 [3:08:56<31:33:15, 22.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 522/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.32341820001602173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 522/5680 [3:09:17<31:11:25, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 523/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2038600593805313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 523/5680 [3:09:40<31:29:25, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 524/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2909198999404907\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 524/5680 [3:10:01<31:10:58, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 525/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17444641888141632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 525/5680 [3:10:23<31:28:53, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 526/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19062933325767517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 526/5680 [3:10:45<31:10:19, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 527/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5315525531768799\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 527/5680 [3:11:07<31:27:41, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 528/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17219150066375732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 528/5680 [3:11:29<31:15:25, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 529/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19722217321395874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 529/5680 [3:11:50<31:09:44, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 530/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3953562378883362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 530/5680 [3:12:13<31:24:19, 21.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 531/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.20505475997924805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 531/5680 [3:12:34<30:57:38, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 532/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18230792880058289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 532/5680 [3:12:56<31:14:28, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 533/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.44330739974975586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 533/5680 [3:13:17<30:58:25, 21.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 534/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16701048612594604\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 534/5680 [3:13:40<31:18:26, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 535/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4887866675853729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 535/5680 [3:14:01<31:04:26, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 536/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.27640393376350403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 536/5680 [3:14:24<31:23:37, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 537/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.24725370109081268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 537/5680 [3:14:45<31:14:30, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 538/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3654002845287323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 538/5680 [3:15:07<31:10:33, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 539/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1966555118560791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":   9%|         | 539/5680 [3:15:29<31:21:41, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 540/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5546685457229614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 540/5680 [3:15:50<30:57:29, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 541/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.21681173145771027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 541/5680 [3:16:13<31:19:02, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 542/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18130692839622498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 542/5680 [3:16:34<30:58:34, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 543/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15027526021003723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 543/5680 [3:16:56<31:17:12, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 544/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.330743670463562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 544/5680 [3:17:18<31:00:45, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 545/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2487439662218094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 545/5680 [3:17:40<31:23:47, 22.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 546/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17796210944652557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 546/5680 [3:18:02<31:20:15, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 547/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19910961389541626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 547/5680 [3:18:24<31:18:17, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 548/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.21023662388324738\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 548/5680 [3:18:47<31:34:04, 22.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 549/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2889360189437866\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 549/5680 [3:19:08<31:05:29, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 550/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19615055620670319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 550/5680 [3:19:30<31:24:00, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 551/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17727968096733093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 551/5680 [3:19:52<31:07:25, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 552/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.44548720121383667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 552/5680 [3:20:14<31:24:45, 22.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 553/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23161153495311737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 553/5680 [3:20:35<31:03:56, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 554/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9845749139785767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 554/5680 [3:20:58<31:22:24, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 555/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9427202343940735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 555/5680 [3:21:20<31:19:59, 22.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 556/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4270079731941223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 556/5680 [3:21:42<31:09:48, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 557/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.723092794418335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 557/5680 [3:22:04<31:27:40, 22.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 558/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2927395701408386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 558/5680 [3:22:25<31:01:36, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 559/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.27796846628189087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 559/5680 [3:22:48<31:15:22, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 560/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18167836964130402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 560/5680 [3:23:09<30:58:05, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 561/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9513945579528809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 561/5680 [3:23:31<31:16:25, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 562/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16186437010765076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 562/5680 [3:23:53<30:59:17, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 563/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16159892082214355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 563/5680 [3:24:15<31:20:04, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 564/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16277414560317993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 564/5680 [3:24:37<31:18:22, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 565/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18465971946716309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 565/5680 [3:24:59<31:03:16, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 566/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17730110883712769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 566/5680 [3:25:21<31:14:46, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 567/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2563045024871826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 567/5680 [3:25:42<30:52:50, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 568/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17151892185211182\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 568/5680 [3:26:05<31:11:18, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 569/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18074661493301392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 569/5680 [3:26:26<30:52:57, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 570/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.6731767058372498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 570/5680 [3:26:49<31:10:40, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 571/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1604304164648056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 571/5680 [3:27:10<30:52:16, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 572/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14959651231765747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 572/5680 [3:27:32<31:12:08, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 573/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.37688446044921875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 573/5680 [3:27:54<31:05:45, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 574/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3362923860549927\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 574/5680 [3:28:16<31:02:48, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 575/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18008220195770264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 575/5680 [3:28:39<31:20:56, 22.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 576/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15851126611232758\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 576/5680 [3:29:00<30:53:41, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 577/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15857148170471191\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 577/5680 [3:29:22<31:12:42, 22.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 578/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14119933545589447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 578/5680 [3:29:43<30:54:17, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 579/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 1.0157266855239868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 579/5680 [3:30:06<31:13:23, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 580/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13933709263801575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 580/5680 [3:30:27<30:55:54, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 581/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.28985080122947693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 581/5680 [3:30:50<31:14:41, 22.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 582/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1945870816707611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 582/5680 [3:31:12<31:11:21, 22.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 583/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2509210705757141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 583/5680 [3:31:33<30:57:04, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 584/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.182430237531662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 584/5680 [3:31:56<31:17:14, 22.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 585/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17171019315719604\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 585/5680 [3:32:17<30:52:20, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 586/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7811892032623291\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 586/5680 [3:32:40<31:10:37, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 587/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1487913578748703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 587/5680 [3:33:01<30:53:25, 21.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 588/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23177386820316315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 588/5680 [3:33:24<31:09:34, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 589/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.20888301730155945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 589/5680 [3:33:45<30:54:44, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 590/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1544104963541031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 590/5680 [3:34:08<31:10:34, 22.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 591/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1539684683084488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 591/5680 [3:34:30<31:14:39, 22.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 592/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15119627118110657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 592/5680 [3:34:51<30:56:41, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 593/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14541354775428772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 593/5680 [3:35:14<31:15:03, 22.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 594/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.25387445092201233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 594/5680 [3:35:35<30:51:12, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 595/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17235928773880005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 595/5680 [3:35:58<31:09:54, 22.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 596/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14008499681949615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  10%|         | 596/5680 [3:36:19<30:54:13, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 597/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.38273540139198303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 597/5680 [3:36:42<31:11:45, 22.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 598/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4614243507385254\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 598/5680 [3:37:03<30:56:20, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 599/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2995842397212982\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 599/5680 [3:37:25<30:58:16, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 600/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.345483660697937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 600/5680 [3:37:47<31:06:09, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 601/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15672072768211365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 601/5680 [3:38:09<30:43:17, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 602/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1379702240228653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 602/5680 [3:38:31<30:59:02, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 603/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5292666554450989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 603/5680 [3:38:52<30:41:21, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 604/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14699000120162964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 604/5680 [3:39:15<30:58:13, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 605/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14908157289028168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 605/5680 [3:39:36<30:42:42, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 606/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16985686123371124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 606/5680 [3:39:59<31:04:06, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 607/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.486299991607666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 607/5680 [3:40:20<30:53:59, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 608/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17256426811218262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 608/5680 [3:40:42<30:54:34, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 609/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13707435131072998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 609/5680 [3:41:04<30:58:13, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 610/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1581580489873886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 610/5680 [3:41:26<30:41:02, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 611/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4257473349571228\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 611/5680 [3:41:48<31:01:42, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 612/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19371607899665833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 612/5680 [3:42:10<30:38:34, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 613/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16549208760261536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 613/5680 [3:42:32<30:56:50, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 614/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15059229731559753\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 614/5680 [3:42:53<30:37:20, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 615/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13292160630226135\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 615/5680 [3:43:16<30:56:56, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 616/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.4910249412059784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 616/5680 [3:43:37<30:40:22, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 617/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12822799384593964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 617/5680 [3:44:00<30:54:20, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 618/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22667717933654785\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 618/5680 [3:44:22<31:00:45, 22.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 619/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.715648889541626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 619/5680 [3:44:43<30:39:18, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 620/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13146236538887024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 620/5680 [3:45:06<30:58:03, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 621/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7188636660575867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 621/5680 [3:45:27<30:37:20, 21.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 622/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1392149031162262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 622/5680 [3:45:49<30:52:52, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 623/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3841266334056854\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 623/5680 [3:46:11<30:41:54, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 624/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12415385991334915\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 624/5680 [3:46:33<31:00:24, 22.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 625/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1303173005580902\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 625/5680 [3:46:55<30:43:44, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 626/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12585429847240448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 626/5680 [3:47:17<30:52:35, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 627/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23712512850761414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 627/5680 [3:47:39<30:49:15, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 628/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12574982643127441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 628/5680 [3:48:00<30:37:29, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 629/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14988696575164795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 629/5680 [3:48:23<30:54:09, 22.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 630/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.5659611821174622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 630/5680 [3:48:44<30:33:27, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 631/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14982226490974426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 631/5680 [3:49:06<30:46:12, 21.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 632/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14254824817180634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 632/5680 [3:49:28<30:25:07, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 633/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.22013694047927856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 633/5680 [3:49:50<30:48:46, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 634/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1423492282629013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 634/5680 [3:50:11<30:30:18, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 635/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.3622840940952301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 635/5680 [3:50:34<30:50:18, 22.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 636/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1396675854921341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 636/5680 [3:50:56<30:45:34, 21.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 637/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2155936062335968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 637/5680 [3:51:18<30:37:24, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 638/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17219173908233643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|         | 638/5680 [3:51:40<30:47:05, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 639/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1551673710346222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 639/5680 [3:52:01<30:30:07, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 640/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12336932122707367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 640/5680 [3:52:24<30:49:30, 22.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 641/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12912273406982422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 641/5680 [3:52:45<30:25:29, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 642/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8464815020561218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 642/5680 [3:53:07<30:40:18, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 643/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.17829880118370056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 643/5680 [3:53:29<30:28:32, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 644/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12583020329475403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 644/5680 [3:53:51<30:46:46, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 645/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1688726842403412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 645/5680 [3:54:13<30:38:39, 21.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 646/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19668523967266083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 646/5680 [3:54:35<30:41:58, 21.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 647/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.19167256355285645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 647/5680 [3:54:57<30:58:23, 22.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 648/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.21629296243190765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 648/5680 [3:55:19<30:33:36, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 649/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16661052405834198\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 649/5680 [3:55:41<30:49:26, 22.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 650/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.24274513125419617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 650/5680 [3:56:03<30:32:53, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 651/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.139885812997818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 651/5680 [3:56:25<30:50:02, 22.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 652/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23638305068016052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 652/5680 [3:56:46<30:30:44, 21.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 653/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12763944268226624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  11%|        | 653/5680 [3:57:09<30:46:19, 22.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 654/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9452928900718689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 654/5680 [3:57:31<30:41:19, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 655/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12202463299036026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 655/5680 [3:57:52<30:32:10, 21.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 656/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1242133378982544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 656/5680 [3:58:15<30:47:53, 22.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 657/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12281782925128937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 657/5680 [3:58:36<30:22:00, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 658/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.160654217004776\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 658/5680 [3:58:58<30:35:49, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 659/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15375278890132904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 659/5680 [3:59:19<30:15:06, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 660/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1669178009033203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 660/5680 [3:59:42<30:31:41, 21.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 661/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1373743712902069\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 661/5680 [4:00:03<30:20:18, 21.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 662/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1435905396938324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 662/5680 [4:00:26<30:39:57, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 663/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.7957813739776611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 663/5680 [4:00:47<30:25:46, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 664/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.11658986657857895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 664/5680 [4:01:09<30:31:11, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 665/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12298166006803513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 665/5680 [4:01:31<30:36:21, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 666/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12847240269184113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 666/5680 [4:01:53<30:19:20, 21.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 667/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.15182103216648102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 667/5680 [4:02:15<30:36:51, 21.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 668/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.23238614201545715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 668/5680 [4:02:36<30:15:57, 21.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 669/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13853004574775696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 669/5680 [4:03:00<31:00:19, 22.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 670/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14247269928455353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 670/5680 [4:03:21<30:29:58, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 671/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13663867115974426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 671/5680 [4:03:43<30:41:16, 22.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 672/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1332777738571167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 672/5680 [4:04:05<30:22:44, 21.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 673/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12366253137588501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 673/5680 [4:04:27<30:41:27, 22.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 674/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12211020290851593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 674/5680 [4:04:49<30:19:47, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 675/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1543760597705841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 675/5680 [4:05:11<30:29:15, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 676/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.16122642159461975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 676/5680 [4:05:33<30:28:39, 21.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 677/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.27305346727371216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 677/5680 [4:05:54<30:11:48, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 678/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1317920982837677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 678/5680 [4:06:16<30:27:07, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 679/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.1392725110054016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 679/5680 [4:06:37<30:03:54, 21.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 680/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13239696621894836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 680/5680 [4:06:59<30:17:54, 21.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 681/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12608584761619568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 681/5680 [4:07:21<30:05:10, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 682/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12268943339586258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 682/5680 [4:07:43<30:20:35, 21.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 683/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2511084973812103\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 683/5680 [4:08:05<30:09:30, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 684/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.13704723119735718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 684/5680 [4:08:27<30:28:20, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 685/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.14620497822761536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 685/5680 [4:08:49<30:22:50, 21.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 686/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.8352418541908264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 686/5680 [4:09:10<30:08:21, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 687/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.9965914487838745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 687/5680 [4:09:33<30:27:27, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 688/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.2518707513809204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 688/5680 [4:09:54<30:09:44, 21.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 689/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.12357264757156372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 689/5680 [4:10:16<30:28:29, 21.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 690/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n",
            "[Log] Loss: 0.18529285490512848\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/1\n",
            ":  12%|        | 690/5680 [4:10:38<30:11:18, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] \n",
            "Processing batch 691/5680...\n",
            "[Log] Batch shape: torch.Size([1, 4, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "CHECKPOINT_DIR = \"../checkpoints\"\n",
        "num_epochs = 100\n",
        "\n",
        "print(f\"Training for only {num_epochs} epochs!\")\n",
        "\n",
        "def main():\n",
        "    train(\n",
        "        data_dir=\"../healthy\",\n",
        "        num_time_steps=1000,\n",
        "        num_epochs=num_epochs,\n",
        "        ema_decay=0.9999,\n",
        "        batch_size=2,\n",
        "        checkpoint_path=None,\n",
        "        lr=1e-4,\n",
        "    )\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FdlH2yWJtlL",
        "outputId": "4c06b0f6-5a2c-4649-87bf-7454751dc5c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Dataset length: 5680\n",
            "[DEBUG] First batch loaded: torch.Size([2, 4, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "# Debug dataset loading\n",
        "train_dataset = BRATSDataset(directory=\"/content/data/healthy\")\n",
        "print(\"[DEBUG] Dataset length:\", len(train_dataset))\n",
        "\n",
        "# Try loading a single batch\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True, num_workers=0)  # Reduce num_workers\n",
        "x = next(iter(train_loader))  # Try fetching one batch\n",
        "x = x.to(device).float()  # Move batch to GPU\n",
        "print(\"[DEBUG] First batch loaded:\", x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyJd5_HD_oI4",
        "outputId": "e33158e8-1c9a-4bd3-e115-1cdfafaa8502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Model initialized successfully.\n"
          ]
        }
      ],
      "source": [
        "scheduler = DDPM_Scheduler(num_time_steps=1000)\n",
        "\n",
        "# Move model to GPU\n",
        "model = UNET(\n",
        "          input_channels=4,\n",
        "          output_channels=4,\n",
        "          Channels=[64, 128, 256, 512, 512, 384]\n",
        "      ).to(device)  # Move model to GPU\n",
        "\n",
        "print(\"[DEBUG] Model initialized successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev3ogbisbvlo",
        "outputId": "4aea0cb4-9ca1-45c1-80f9-8ffcd490b5c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Running model forward pass...\n",
            "[DEBUG] Forward pass successful, output shape: torch.Size([2, 4, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "# Load a batch and move to GPU\n",
        "x = next(iter(train_loader)).to(device).float()\n",
        "t = torch.randint(0, 500, (x.shape[0],)).to(device)\n",
        "\n",
        "print(\"[DEBUG] Running model forward pass...\")\n",
        "# output = model(x, t)  # Forward pass\n",
        "print(\"[DEBUG] Forward pass successful, output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Forward Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forward_process(image, t, scheduler, device):\n",
        "    \"\"\"Applies forward diffusion to an image at time step t.\"\"\"\n",
        "    image = normalize_images(image).to(device)\n",
        "    a = scheduler.alpha[t-1].view(1, 1, 1, 1).to(device)\n",
        "    e = torch.randn_like(image, device=device)  # Sample noise\n",
        "    noisy_image = torch.sqrt(a) * image + torch.sqrt(1 - a) * e\n",
        "    return noisy_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reverse Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reverse_process(x_noisy, start_t, scheduler, model, device):\n",
        "    \"\"\"Performs reverse diffusion (denoising) from a noisy image.\"\"\"\n",
        "    x = x_noisy.clone().to(device)\n",
        "    \n",
        "    # Perform reverse diffusion process\n",
        "    for t in range(start_t, 0, -1):\n",
        "        t_tensor = torch.tensor([t], device=device)\n",
        "        noise_pred = model(x, t_tensor)\n",
        "\n",
        "        a = scheduler.alpha[t-1].view(1, 1, 1, 1).to(device)\n",
        "        beta_t = scheduler.beta[t-1].view(1, 1, 1, 1).to(device)\n",
        "\n",
        "        # reverse step\n",
        "        x = (x - (beta_t / torch.sqrt(1 - a)) * noise_pred) / torch.sqrt(1 - beta_t)\n",
        "\n",
        "        # Add noise for stochasticity\n",
        "        if t > 0:  \n",
        "            noise = torch.randn_like(x, device=device)\n",
        "            x = x + noise * torch.sqrt(beta_t)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sample and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, scheduler, num_time_steps):\n",
        "    dice_scores, auroc_scores = [], []\n",
        "    all_results = []  # Store results for each data item\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (image, ground_truth_seg) in enumerate(tqdm(dataloader, desc=\"Evaluating\")):\n",
        "            try:\n",
        "                image = image.to(device)\n",
        "                \n",
        "                # Forward diffusion\n",
        "                noisy_image = forward_process(image=image, t=num_time_steps, scheduler=scheduler, device=device)\n",
        "                \n",
        "                # Reverse diffusion (denoising)\n",
        "                output = reverse_process(x_noisy=noisy_image, start_t=num_time_steps, scheduler=scheduler, model=model, device=device)\n",
        "\n",
        "                anomaly_map = torch.abs(normalize_images(image) - normalize_images(output)).sum(dim=0)\n",
        "        \n",
        "                binary_mask = apply_otsu_thresholding(anomaly_map)\n",
        "                ground_truth_mask = (ground_truth_seg > 0).float()\n",
        "\n",
        "                # Compute Dice score\n",
        "                dice = dice_score(binary_mask.cpu(), ground_truth_mask.cpu())\n",
        "                \n",
        "                pixel_wise_cls = normalize_images(np.array(torch.tensor(anomaly_map).reshape(1, -1))[0, :])\n",
        "                pixel_wise_gt = normalize_images(np.array(torch.tensor(ground_truth_mask).reshape(1, -1))[0, :])\n",
        "\n",
        "                auroc = roc_auc_score(pixel_wise_gt, pixel_wise_cls)\n",
        "\n",
        "                # Save individual result\n",
        "                all_results.append({\"sample_idx\": idx,\"dice\": dice, \"auroc\": auroc})\n",
        "                \n",
        "                dice_scores.append(dice)\n",
        "                auroc_scores.append(auroc)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing batch {idx}: {e}\")\n",
        "                continue\n",
        "\n",
        "    if not dice_scores:\n",
        "        return 0.0, 0.0, []\n",
        "        \n",
        "    return np.mean(dice_scores), np.mean(auroc_scores), all_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validate Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "model = UNET(\n",
        "    output_channels=4,\n",
        "    input_channels=4,\n",
        "    Channels=[64, 128, 256, 512, 512, 384],\n",
        "    time_steps=500\n",
        ").to(device)\n",
        "\n",
        "def test_checkpoints(val_data_path, checkpoint_dir, batch_numbers, scheduler, num_time_steps):\n",
        "    val_dataset = BRATSDataset(directory=val_data_path, test_flag=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "    \n",
        "    log_file = open(\"checkpoint_scores.log\", \"w\")\n",
        "    detailed_log_file = open(\"detailed_checkpoint_scores.log\", \"w\")\n",
        "    best_checkpoint, best_dice = None, 0\n",
        "\n",
        "    try:\n",
        "        for batch_number in batch_numbers:\n",
        "            for checkpoint in sorted(os.listdir(checkpoint_dir)):\n",
        "                if f\"batch_{batch_number}\" in checkpoint:\n",
        "                    print(f\"\\nTesting {checkpoint}\")\n",
        "\n",
        "                    checkpoint_path = os.path.join(checkpoint_dir, checkpoint)\n",
        "                    checkpoint_data = torch.load(checkpoint_path, map_location=device)\n",
        "                    model.load_state_dict(checkpoint_data[\"weights\"])\n",
        "                    model.eval()\n",
        "\n",
        "                    avg_dice, avg_auroc, all_results = evaluate(model, val_loader, scheduler, num_time_steps=num_time_steps)\n",
        "\n",
        "                    # Log summary stats\n",
        "                    log_entry = f\"Checkpoint: {checkpoint} | Dice: {avg_dice:.4f} | AUROC: {avg_auroc:.4f}\\n\"\n",
        "                    print(log_entry)\n",
        "                    log_file.write(log_entry)\n",
        "                    \n",
        "                    # Log detailed results\n",
        "                    detailed_log_file.write(f\"\\n========== Checkpoint: {checkpoint} ==========\\n\")\n",
        "                    detailed_log_file.write(\"Sample_idx, Dice, AUROC\\n\")\n",
        "                    for result in all_results:\n",
        "                        detailed_log_file.write(f\"{result['sample_idx']}, {result['dice']:.4f}, {result['auroc']:.4f}\\n\")\n",
        "                    detailed_log_file.write(f\"AVERAGE, {avg_dice:.4f}, {avg_auroc:.4f}\\n\")\n",
        "                    detailed_log_file.write(\"=========================================\\n\")\n",
        "\n",
        "                    if avg_dice > best_dice:\n",
        "                        best_dice = avg_dice\n",
        "                        best_checkpoint = checkpoint\n",
        "\n",
        "                    torch.cuda.empty_cache()\n",
        "    finally:\n",
        "        log_file.close()\n",
        "        detailed_log_file.close()\n",
        "        print(f\"\\nBest Checkpoint: {best_checkpoint} with Dice: {best_dice:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Log] Using 100 time steps.\n",
            "\n",
            "Testing brats_ddpm_checkpoint_epoch_1_batch_5.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 1/1 [18:58<00:00, 1138.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint: brats_ddpm_checkpoint_epoch_1_batch_5.pth | Dice: 0.0526 | AUROC: 0.4530\n",
            "\n",
            "\n",
            "Best Checkpoint: brats_ddpm_checkpoint_epoch_1_batch_5.pth with Dice: 0.0526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "num_time_steps = 100\n",
        "val_data_path = \"val-test/val\"\n",
        "checkpoint_dir = \"checkpoints\"\n",
        "scheduler = DDPM_Scheduler(num_time_steps=num_time_steps).to(device)\n",
        "batch_numbers = [5]\n",
        "test_checkpoints(val_data_path, checkpoint_dir, batch_numbers, scheduler, num_time_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_nii(nii_path, slice_idx=None):\n",
        "    \"\"\"\n",
        "    Plots a given slice of a single-channel NIfTI (.nii or .nii.gz) image.\n",
        "\n",
        "    Args:\n",
        "        nii_path (str): Path to the .nii or .nii.gz file.\n",
        "        slice_idx (int, optional): Index of the slice to display. Defaults to the middle slice.\n",
        "    \"\"\"\n",
        "    nii_img = nib.load(nii_path)\n",
        "    img_data = nii_img.get_fdata()  # Convert to numpy array\n",
        "\n",
        "    # Get slice index\n",
        "    if slice_idx is None:\n",
        "        slice_idx = img_data.shape[-1] // 2  # Use last axis for slicing\n",
        "\n",
        "    # Plot the selected slice\n",
        "    plt.imshow(img_data[:, :], cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Slice {slice_idx}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_nii(\"val-test/val/000324/BraTS20_Training_368_t2_109.nii\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "gJzfe3HOz4KD",
        "_9ORVCc1z7DR",
        "VGXiQiWnz_Po",
        "SxpENE6MJtlI",
        "zQFnsdN9JtlJ",
        "NIMWqvt-JtlJ",
        "kfFBhAhgJtlK",
        "r8fn_3uy0Ffv",
        "bViuRDbY0PFk",
        "-eroMMFH0R9c"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30887,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "fyp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
